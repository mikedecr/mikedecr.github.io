---
title: Getting Started with R
description: "Getting R up and running. READ BEFORE CLASS."
author: "Michael DeCrescenzo"
date: '2017-12-01'
slug: 811-basics
categories: ["R", "ps811", "Teaching"]
tags: []
---

# What is on this web page

Please guide yourself through this web page *before our first in-class R lesson*. It would be best if you walked through this document in enough advance of class that you can ask me questions about any confusing parts in enough advance of class. I just want to use our class time as effectively as possible!

This document describes how to get started with R and do some basic (but often useful) tricks. We discuss installing R, running simple commands, indexing, some elementary programming logic, and functions. We close with some slight discussion of how R and Stata differ, though we will be returning to that topic throughout the course.

**Note:** This lesson is a little "abstract" in that in demonstrates R's *general* behavior rather than a concrete application of R workflow. We get much more concrete in the following lesson on data manipulation. Take this slowly; mess around with some of the code if it helps you understand what it's doing. If you encounter material that does not make sense, please take note of it so we can review it in class before progressing too far.

Thanks, and I'll see you in class!


# How to read this page

This page contains code snippets that you can paste into R. 

```
Code appears in blocks like this. You can paste this text into R.
```

```{r, echo = FALSE}
"Results appear with two ## signs"
```



# Installing R

If you have not set up R already, click [here](https://mirror.las.iastate.edu/CRAN/) to download R for your operating system (if you haven't already). 

A little bit about what's going on here: R is open source and is distributed from various ["mirrors"](https://en.wikipedia.org/wiki/Mirror_website), which are clone websites that contain essentially identical information. The CRAN (Comprehensive R Archive Network) hosts these mirrors [all over the world](https://cran.r-project.org/mirrors.html). It is generally recommended that you install R (and related software like R packages) using mirrors in nearby locations. Any mirror in the U.S. should be fine for our purposes. The link at the top of this section uses the Iowa State University mirror.

Once R is downloaded, make sure that it is fully installed. You can run R using the GUI app (`R.app` on OSX or `Rgui.exe` on Windows), as a terminal program (which I do for advanced reasons), or using the Rstudio application. Rstudio is discussed below.



# Using R

The most essential part of using R is the *console*. This is where results of all commands are displayed. There is a prompt at the bottom of the console where commands can be submitted directly. Yours won't be the same colors as mine, but it looks sort of like this:

<center>
  <br>
  <img src="img/r-console.png"  alt="R console" style="width: 80%">
</center>
<br>

Although you can type commands directly into the console, most commands should be written in a *script file*. Script files serve the same purpose as they do in Stata; they provide a record of all commands you want to run in your analysis. This lets you replicate your analysis the next day, the next week, the next year, or whenever (presuming your code does not become obsolete with future package versions, for example).



# Open a script file

Use whatever program you desire to open a script file. The basic R GUI application has a script editor that can be accessed using the `File` menu or a keyboard shortcut. Many R users prefer to manage R projects using [Rstudio](https://www.rstudio.com/products/rstudio/), an [IDE](https://en.wikipedia.org/wiki/Integrated_development_environment) that provides several tools for interacting with R. Windows users may find Notepad++ or TextMate to be useful text editors. Advanced programmers may use Emacs or Vim with some package (such as ESS for Emacs) to speak to the R console. I would recommend any external editor that can send commands to the R console and, as you become more comfortable with R, that contains some keyboard shortcuts for creating fast R code. Rstudio comes standard with many such shortcuts.

Personally, I prefer to edit R script using the [Sublime Text](https://www.sublimetext.com/) editor and the [R-Box package](https://packagecontrol.io/packages/R-Box).^[Package control does not come default with Sublime Text, but it is a universal component of any Sublime user's experience. Instructions for installing and using Package Control can be found [here](https://packagecontrol.io/installation).] Sublime has a nice system for editing custom keyboard macros for any language you frequently use, which I use liberally.^[Individuals who are already comfortable with Sublime should feel free to raid my custom settings, which can be obtained through my [Github page](https://github.com/mikedecr/sublime-user-folder).]

Script files should begin with some description of the script. You can include comments (text that will not be executed as R commands) after the `#` symbol. For example, your script file for this lesson might contain some comments at the top like...

```{r}
# ------------------------------------------------------------
#  PS 811: statistical computing for political science
#  Lesson 1: Basics of R
# ------------------------------------------------------------
```

Comments are great for describing what code is doing, planning an analysis, writing notes to yourself. Comments are also great for *pseudocode*, which are notes to yourself that "translate" what code is doing into English. We will see some examples of this as the course progresses.

At the top of my script files, I typically include some code that sets up my project:

- create subdirectories for storing output (we will talk about this in future lessons)
- load relevant packages
- set project-wide options (graphics themes, graphics colors, any other things I want to store)

Although a script file can be imperfect while a project is being developed, a well-written script file for a finished project should be organized, easy to read, and run from top to bottom without any errors. This is important for ensuring that you can retrace the steps of your analysis.

Save this file. In your `ps811` folder on your computer (which you should have...), create a section for R containing a "lessons" folder. Save this document in `ps811/R/lessons/`.^[This notation signifies a folder directory pathway. Slashes indicate folders.] 




# Executing commands

Just like Stata, the R interface is 
a REPL---that is, Read-Evaluate-Print Loop. That means R processes commands one at a time without the need to pre-compile any code (compilation essentially happens during execution).^[Interestingly, this makes R slower than languages that require pre-compilation---such as C++, which is the basis of the Stan language for writing Bayesian models. Much of Bayesian analysis is waiting for models to compile (and then waiting for the sampler to run...lots of waiting in Bayes).]

Just to demonstrate some basic R behavior, let's run a few commands.

First, R works as a calculator. It can handle mathematical expressions. Paste or type the following lines of code DIRECTLY into the console.

```{r, eval = FALSE}
1 + 1
2 + 2
100 * 2
500 / 4
```

You will notice that the results of each calculation will print beside a little `[1]`. Ignore this for now; we will explain it later.

Now take the above block of code and paste the commands into your script file. Try to run the commands from the script file using a keyboard shortcut. Most computers and interfaces use `super + enter`, where `super` refers to `Ctrl` on PCs or `Cmd` on Macs. Windows machines may use a different shortcut, such as `Ctrl + R`. Take this opportunity to look up the appropriate keyboard shortcut on your own, *before coming to lecture!* :-)



# Everything is an Object

We don't usually manipulate mathematical expressions this atomically in R. Instead we treat data as variables. Before we jump into that, we should explain how R treats variables. 

In R, everything is an object. I can store an arbitrary value as a variable, which is an object. A text string can be an object. An entire dataset. A variable within a dataset can be thought of as an object within another object. It's all objects. This makes R very flexible, although some object manipulations are obviously out of bounds (can't add `4 + "fish"`, for example).



# Variables

We can store and manipulate variables in R. Just as how in math the expression $x + 4$ can take different values depending on the value of $x$, we can do similar things with R. 

First, we'll "assign" a value to a variable using the assignment operator `<-`. The `<-` is a combination of a less-than sign `<` and a hyphen `-`.

For example,

```{r}
x <- 5
```

Now the variable `x` has the value of `5`, which is to say, `x` and `5` now mean the same thing! 

We can display the contents of any object by simply typing the object name. Print out `x`...

```{r}
x
```

...and we get back a `5`.

Do some math with `x`...

```{r}
x + 4
```

You can read the `<-` operator as "gets." So in the above example, `x` "gets" the value of 5. For simple expressions, `<-` can mean "equals," but as we begin working with more complex objects (such as the results of a statistical model), saying "equals" in your head becomes a little more difficult to justify.


# More variables: vectors

We can assign a series of values to a variable. One way to do this in R is the `c()` function. The `c()` function will bind several elements into one variable, as long as the elements can be coerced to be the same data type (numeric, factor, string, etc). We will return to the concept of *data types* later.

```{r}
y <- c(2, 4, 6)
y
```

If you wrap an assignment inside of parentheses, the result will print at the same time that values are assigned.

```{r}
(y <- c(2, 4, 6))
```

We can use multi-element variables to do math on the entire variable at once. Just as we could do real math...

$\begin{align} 2 \cdot \begin{bmatrix} 2 \\ 4 \\ 6 \end{bmatrix} = \begin{bmatrix} 4 \\ 8 \\ 12 \end{bmatrix} \end{align}$

we can also do similar things with vectors in R.

```{r}
2 * y
y * y
```


# Indexing

It is possible to access the elements of a variable using *indexing* notation. R uses square brackets to select a given element in a variable. Using the variable `y` from above, what are the first, second, and third elements?

```{r}
y
y[1]
y[2]
y[3]
```

Indexing notation is why the console prints a little `[1]` next to all results. It is indicating that the adjacent element is the first element. This becomes clearer if we were to print a long vector with many more elements---for example, 100 repetitions of the same data.

```{r}
rep("hello", 100)
```

We could have two (or higher) dimensional objects. Let's make some simple two-dimensional objects:

```{r}
tall_m <- rbind(c(1, 2), 
                c(3, 4), 
                c(5, 6))
tall_m
```

(Notice how `rbind()` binds vectors together as rows.)

```{r}
wide_m <- cbind(c(1, 2), 
                c(3, 4), 
                c(5, 6))
wide_m
```

(And `cbind()` binds vectors as columns.)

We can still use indexing notation to access the data within these objects. We use the notation `object[a, b]`, where `a` indicates the row number and `b` indicates the column number.

```{r}
tall_m[2, 2]
wide_m[1, 3]
```

If we don't specify a row, R grabs every row. Here we leave the row unspecified but grab the second column.

```{r}
tall_m
tall_m[ , 2]
```

And if we don't specify a column, R returns every column. Here we specify the row but leave the column unspecified.

```{r}
wide_m[1, ]
```

**Note:** Although some languages are "zero-indexed" (meaning the first element of a variable is index position 0), R is "one-indexed." This makes more sense for statistical purposes, but may be different from other languages you have seen (for example C). Calling the 0'th element of a variable does not throw an error, however. Go figure.

```{r}
y[0]
```

**Another important note:** Indexing isn't something you will use much in the tidyverse, but it is important to be familiar with it for a few reasons. First, it has useful mathematical parallels, where $y_{i}$ is analogous to `y[i]`. This sometimes comes in handy for dealing with the results from statistical models. Additionally, you will encounter it when searching through message boards for R help, especially when you see someone do some kind of *logical selection*. What does "logical selection" mean, exactly? Well...


# Logic

Logic as a concept in programming is less daunting than it sounds. At it's core, what we're doing is dealing with `TRUE`s and `FALSE`s. An example to illustrate what I mean. We'll make a vector.

```{r}
(g <- 1:10)
```

We can ask R about things that are true and false about the values in the vector. For example, are the values greater than 5?

```{r}
g > 5
```

What happened here? The statement `g > 5` is a "logical," meaning that its underlying meaning is fundamentally `TRUE` or `FALSE`. R asks if `g` is greater than 5 for each element in `g`, and R returns an entire vector of logicals, each element corresponding to the original elements in `g`. 

We can do this kind of thing with several operators. Let's see them in practice.

```{r}
# g "is equal to" 5
g == 5

# g "is greater than" 5
g > 5

# g "is less than" 5
g < 5

# g "is greater than or equal to" 5
g >= 5

# g "is less than or equal to" 5
g <= 5
```

Relating this back to index notation, you will probably see R users online using indexing and logical evaluation to select observations from a dataset. For example, let's say I want to multiply `g` by 10.

```{r}
g * 10
```

And now let's say that I only want to do this for values of `g` less than 4. First I can limit my selection of `g` to the values I want...

```{r}
g[g < 4]
```

...and then do the operation I want.

```{r}
g[g < 4] * 10
```

This seems a little abstract right now, but here's how you may see others do this online. Let's say that I have a dataset of World Health Organization data, and I want to look only at the European data. You might see someone online limit the data like so.

```{r, eval = FALSE}
who[region == "Europe", ]
```

This block of code would be read as, "print the `who` object keeping only the observations (rows) from the Europe region, keeping every column". The `tidyverse` uses other tools to do this kind of thing, which I find to be easier.



# Data types

There are a few different types of data in R. 

- Logical: `TRUE`s and `FALSE`s.
- Numeric: including integers and doubles
- Strings: text strings that are contained in `"quotes"`. R calls these "character" type variables.
- Factors: ordered categories with text labels

Factors require some explanation, because they are somewhat like numbers, but also somewhat like text strings. They are like text strings because they have text labels and you can't do math with them. But they are like numbers because you can put them in order. Put another way, factors are *ordered categories* that have textual metadata. You can interact with them as text strings, but they are stored in the computer as numbers to conserve memory. As a result, factors are really only good for variables with finite categories, such as a 1-to-5 Likert scale.

You can coerce data from type to another, and they follow some intuitive rules (with certain trade-offs). Here we coerce numbers to characters.

```{r}
1:3
as.character(1:3)
```

Numbers to factors, notice the creation of the metadata---i.e. the factor "levels."

```{r}
as.factor(1:3)
```

Character to factor. Notice how levels are assigned alphabetically by default. You can modify this with the `levels = ` argument in the `factor()` function.

```{r}
# This object comes with R, originally a character variable
state.abb
as.factor(state.abb)
factor(state.abb, levels = state.abb) # custom levels
```

You can go from text to numeric, but only by way of factors. This is because `as.factor()` coerces text strings into ordered categories, and then `as.numeric()` interprets the ordering as numeric values.

```{r}
as.numeric(as.factor(state.abb))
```

Note: data types are different from *object classes*. There are many classes of objects that can have different attributes. We'll see these more in future lessons (but examples include matrices, data frames, tables, lists, tibbles, lm objects, and so on).


# Missing data

Vectors might contain missing data. The missing data code in R is `NA`, without quotes. 

Missing data take the same data type as the vector in which they are located.^[In fact, all elements in a vector must be the same data type. If you try to combine numbers and strings in the same vector, R coerces the vector to be the more inclusive data type, which is a string (so the number becomes the string-version of the number, i.e. `1` becomes `"1"`).] For example:

```{r}
h <- c(1, 2, NA, 4)
# what data type is h?
str(h)
```

By placing `NA` inside a numeric vector, what we've told R is that we know that the missing data is numeric, we just don't know what the number is. As a result, a rule that applies to any number applies also to a missing numeric value, for example...

```{r}
h^0
```

Any number raised to the 0 is 1, even if we don't know what the number is!

If the value of the number matters, however, some functions fail. For example, we don't know the mean of `h`. Try the following.

```{r}
mean(h)
```

We get a missing value, which is to say, we know that there *should* be a numeric mean, we just don't know what it is because we don't know all of `h`. When we want to calculate this value irrespective of the missing values, we often need to tell R to skip over missing values.

```{r}
mean(h, na.rm = TRUE)
```

# Functions

Although you can perform simple operations on data in R (adding, multiplying, and so on), these get tedious for complex tasks. Sequences of operations can be simplified as functions. We have already seen some examples of functions, such as `c()` for making vectors. 

There are three things you need to use a function.

1. The function name itself. Self-explanatory
2. Parentheses. This tells R that the object name is meant to be a function.
3. Arguments inside the parentheses. Technically these can be optional, depending on the function and its default behaviors. Arguments can be data that you pass to the function (as inputs), settings that you modify, and so on.

Here are some common, helpful functions. 

```{r}
# create normally distributed random noise
(x <- rnorm(n = 100, mean = 0, sd = 1)) 

sum(x) 
# number of elements in an object
length(x) 
# calculating an average by hand
sum(x) / length(x)  
# equivalent
mean(x) 

# variance
var(x) 
# variance by hand
sum((x - mean(x))^2) / (length(x) - 1) 

# standard deviation
sd(x)
sqrt(sum((x - mean(x))^2) / (length(x) - 1))
```

Some common issues with functions.

1. As mentioned above, some functions don't work as intended when you have missing values, so you may need to coerce R to skip over missing values.
2. Some functions require multiple variables from one dataset. Because R can contain multiple datasets at once, these functions want you to tell R which dataset you want to use. This is often done with a `data =` argument inside the function. For example, a linear model would work like `lm(y ~ x, data = dataset_name)`. This tells R and that the `y` and `x` variables can be found in the dataset called `dataset_name`. We'll see more of this in future lessons.
3. In math, we learn that if we give a function the same input, it returns the same output every time. (You may recall the "vertical line test.") Statistics pushes on this definition a little bit: a function may return "random" results if they represent stochastic processes (such as coin flips). This works in the computer also (e.g. the `rnorm()` function, which simulates randomly distributed noise. There are other distribution sampling functions as well). Technically speaking though, they are only pseudorandom and can be made nonrandom by specifying a seed using the `set.seed()` function.


# Packages (for non-base functions)

Base R only contains a small number of functions. Most analyses require more complicated tools that are not standard with R. For these tasks, there are hundreds of packages available for download. 

Official R packages are hosted on CRAN and can be installed with code. For example, the following code will install the `tidyverse` package. Because the package depends on other packages, all packages will be downloaded if not already on your system. As a result, this command would take a while to execute (but you should execute it...we will use this package in class).

```{r, eval = FALSE}
install.packages("tidyverse")
```



# User-defined functions

This section is a little complicated, so it's okay if it doesn't make perfect sense at first.

In R, it is easy to write your own functions. Here is an example of a function that calculates a mean. 

```{r}
my_mean <- function(z) {

  sum_z <- sum(z)
  n <- length(z)
  the_mean <- sum_z / n
  
  return(the_mean)

}
```

Here's how this works. 

First, we pick a name for the function. Here, we chose `my_mean`. If you don't know if there are any existing functions with the same name, you can check the R help files. 

```{r}
?my_mean
??my_mean
```

Looks like we're all clear to use the name `my_mean`. Now that we have a good name, we need to *define* what the function does. We do this by *assigning* a definition to the name `my_mean`. That's what the `my_mean <- function(z) {...}` means. (Yes, in R, even functions are objects). 

We must decide which *arguments* this function should have. An argument is information that gets *passed* to the function. That's what the `function(z)` is doing---the function takes one argument called `z`. We could have written `function(banana)` if we wanted, and then manipulated the `banana` object inside the function. The `z` (or `banana`) object name is just a stand-in for information that we are going to manipulate inside the function definition. 

What manipulation takes place? That's what the remainder of the definition lays out. If we passed some variable to `my_mean()`, what the function does is calculate the sum, find the length, and then divide the sum by the length. Finally, we ask the function to *return* the calculated value, meaning that when we pass in some `z` data, we get out some value that is the result of `the_mean`.

For example, let's make some data. 

```{r}
(some_data <- seq(0, 10, 2))
```

(Notice that the `seq(a, b, c)` function creates a sequence of values from `a` to `b` with a skip interval of `c`.) And then we will find the mean of this variable using our new mean function.

```{r}
my_mean(some_data)
```

There is one potentially-confusing point I need to make about custom functions. The variables that are manipulated inside the function definition are called *local variables*. This means they only exist in the world of that function. Although the function manipulates variables called `z`, `sum_z`, and so on, those variables only exist to that function and are not accessible to you in the rest of R's memory. They exist only to make the function work. To demonstrate the point, print out all of the objects in R's memory using the `ls()` function.

```{r}
ls()
```

You will notice that none of the objects created by `my_mean()` are there. This is by design, because you don't want any function you create to get confused about whether the object you want to manipulate is local or global. 

Let's give this an example. If I have a variable called `abc` in R memory, and I manipulate a local variable called `abc` inside a function, have I manipulated the original `abc`? The answer is No. 

Let's see how. We make some object...

```{r}
(abc <- 150)
```

and then write the following function...

```{r}
zero_out <- function(abc) {
  abc <- 0
  return(abc)
} 
``` 

And we pass `abc` to the function, which returns a 0.

```{r}
zero_out(abc)
```

The question is, have we overwritten the original `abc` to zero? No, we haven't.

```{r}
abc
```

That's because the `abc` inside the function definition is a *local variable*, so it has no bearing on other objects in R memory. For this reason, it is important that the objects you manipulate within a function are either (a) *passed to the function as arguments* or (b) *created within the function*. 





# R vs Stata

As we continue these lessons, you will see more about how these languages are similar and different. There are definitely *some* similarities. The REPL interface (commands are evaluated instantly and results displayed in a console) is a big one. This means you don't have to compile an entire file of code before you can run it. Yay! 

The differences between R and Stata have benefits and drawbacks. Here is some rapid-fire accounting of some differences. 

R is free and open source. 

- Pro: When you lose your university access license to Stata (which you will, eventually), you can still use R.
- Con: Some of the stuff in R may lower quality than the stuff in Stata. Granted, most of the stuff in R you use works just as well as Stata, but there is really nothing stopping some ding dong from writing some crappy code and putting it out there. Wisdom of the crowds generally holds though: if an R tool is popular, you can count on it to be reliable. There are *lots* of smart people using and constantly improving R!

R is a fully formed programming language.

- Pro: R makes it very easy to directly access data as vectors, matrices, and dataframes with intuitive programming syntax such as indexing.
- Pro: R operates with *functions* rather than commands. In R, if I had the functions `f()`, `g()`, and `h()`, I could write `f(g(h(x)))` in one line of code and it just works. Not so in Stata. 
- Con: This makes R a little tougher to learn at first for those with less computing experience.


R is object-oriented.

- Pro: this lets R be very flexible.
- Pro: You can load and manipulate multiple datasets at once without being confined to one data table. 
- Con: This makes accessing variables within datasets more difficult, because you have to specify *which* dataset to look inside of. We will cover this in the future. Luckily, the `tidyverse` provides tools for making this easier.
- Con: This also makes R slower than Stata, generally speaking. This is because R has to check to make sure that the commands you want to run make sense (checking data types, sizes of objects, and so on). You generally won't notice this unless you work with larger datasets. When your dataset is truly massive, there are ways to use R as a front-end to interact with other programming languages, such as `RSQL` to talk to SQL from R.


R's interface is less graphical than Stata. It's all about the code.

- Pro: This makes replication easier (or, harder to mess up) in R, because there is less dependence on pointing-and-clicking to create analysis and graphics. 
- Con: For newcomers who are used to seeing their data in front of them as a spreadsheet, this makes R more psychologically difficult to pick up than Stata.
- Con: R syntax is more "programmy" and less English-seeming. The drawback of this is that it is complicated *at first*. The benefit of this is that it is simpler in the long run, because the rules of the syntax create long-run structure and coherence in the R language.



# Moving on

If you have made it this far, take a break! 

I want to remind you that future lessons will be far less abstract than this one. Many concepts in this lesson are *important* in the sense that you will see them again during your R career, but they are not all *essential* for surviving this course. Future lessons will be far more concrete and dataset-driven.

Continue with the next lesson: [Data Manipulation](811/811-data)








