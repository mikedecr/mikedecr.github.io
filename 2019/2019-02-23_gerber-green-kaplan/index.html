<!DOCTYPE html>
<html lang="en-us">
  <head>

  

  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noodp"/>
  <meta name="author" content="Michael DeCrescenzo">
  <meta name="description" content="Ph.D. Candidate, Political Science, University of Wisconsin–Madison">
  <meta name="keywords" content="political science, university of wisconsin madison, uw madison">
  
  <link rel="prev" href="/2018/2018-10-19-partialling-out/" />
  <link rel="next" href="/2019/2019-06-19_bayesian-causal-mediation/" />
  <link rel="canonical" href="/2019/2019-02-23_gerber-green-kaplan/" />
  <link rel="apple-touch-icon" sizes="180x180" href="/images/site/apple-touch-icon.png">
  <link rel="icon" href="/images/site/favicon-area-chart.ico" type="image/x-icon" />
  <link rel="shortcut icon" href="/images/site/favicon-area-chart.ico" type="image/x-icon">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <title>
       
       
           Experimentalists Agree! When Flat Priors Lead to Worse Learning | Michael DeCrescenzo
       
  </title>
  <meta name="title" content="Experimentalists Agree! When Flat Priors Lead to Worse Learning | Michael DeCrescenzo">
    

  <link rel="stylesheet" href="/font/iconfont.css">
  <link rel="stylesheet" href="/css/main.min.css">


  
  
 

<script type="application/ld+json">
 "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "/"
    },
    "articleSection" : "posts",
    "name" : "Experimentalists Agree! When Flat Priors Lead to Worse Learning",
    "headline" : "Experimentalists Agree! When Flat Priors Lead to Worse Learning",
    "description" : "A Quick Comment on Gerber, Green, and Kaplan (2002)",
    "inLanguage" : "en-us",
    "author" : "Mike DeCrescenzo",
    "creator" : "Mike DeCrescenzo",
    "publisher": "Mike DeCrescenzo",
    "accountablePerson" : "Mike DeCrescenzo",
    "copyrightHolder" : "Mike DeCrescenzo",
    "copyrightYear" : "2019",
    "datePublished": "2019-02-23 00:00:00 &#43;0000 UTC",
    "dateModified" : "2019-02-23 00:00:00 &#43;0000 UTC",
    "url" : "/2019/2019-02-23_gerber-green-kaplan/",
    "wordCount" : "944",
    "keywords" : [ "Experiments","Bayesian statistics", "Michael DeCrescenzo"]
}
</script>

  <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
  
<script type="text/javascript">
var sc_project=11382424; 
var sc_invisible=1; 
var sc_security="647b3843"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - StatCounter" href="http://statcounter.com/"
target="_blank"><img class="statcounter"
src="//c.statcounter.com/11382424/0/647b3843/1/" alt="Web
Analytics Made Easy - StatCounter"></a></div></noscript>


</head>

  


  <body class="">
    <div class="wrapper">
        

<nav class="navbar">
    <div class="container">
        <div class="navbar-header header-logo">
         <a href="/">Home</a>
        </div>
        <div class="menu navbar-right">
                
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                <a class="menu-item" href="/research/" title="">Research</a>
                
                <a class="menu-item" href="/teaching/" title="">Teaching</a>
                
                <a class="menu-item" href="/code/" title="">Code</a>
                
                <a class="menu-item" href="/contact/" title="">Contact</a>
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
        </div>
    </div>
</nav>
<nav class="navbar-mobile" id="nav-mobile" style="display: none">
     <div class="container">
        <div class="navbar-header">
            <div>  <a href="/">Michael DeCrescenzo</a></div>
            <div class="menu-toggle">
                <span></span><span></span><span></span>
            </div>
        </div>
     
          <div class="menu" id="mobile-menu">
                
                
                <a class="menu-item" href="/about/" title="">About</a>
                
                <a class="menu-item" href="/research/" title="">Research</a>
                
                <a class="menu-item" href="/teaching/" title="">Teaching</a>
                
                <a class="menu-item" href="/code/" title="">Code</a>
                
                <a class="menu-item" href="/contact/" title="">Contact</a>
                
                <a class="menu-item" href="/posts/" title="">Blog</a>
                
        </div>
    </div>
</nav>


    	 <main class="main">
          <div class="container">
      		
<article class="post-warp" itemscope itemtype="http://schema.org/Article">
    <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Experimentalists Agree! When Flat Priors Lead to Worse Learning</h1>
        <div class="post-meta">
                Written by <a itemprop="name" href="/" rel="author">Mike DeCrescenzo</a>
                <span class="post-time">
                on <time datetime=2019-02-23 itemprop="datePublished">February 23, 2019</time>
                </span>
                in
                <i class="iconfont icon-folder"></i>
                <span class="post-category">
                        <a href="/categories/methods/"> Methods </a>
                        
                </span>
        </div>
    </header>
    <div class="post-content">
        

        

        
        
     
          
          
          

          
          
          

          <p>I’ve been reading about Bayesian causal inference for a paper I’m hoping to write, and this has led me to dig into the work by <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=RDueAgAAQBAJ&amp;oi=fnd&amp;pg=PA9&amp;dq=gerber+green+kaplan&amp;ots=0I3f6Jfn33&amp;sig=wVKOfRF39mkiT4vnMe8YecMMpeY#v=onepage&amp;q=gerber%20green%20kaplan&amp;f=false">Gerber, Green, and Kaplan</a> about the “Illusion of Learning from Observational Research.” In it, they put forth a model to describe how much you “update” your information about causal effects from experimental vs observational research.</p>
<p>The intuition of the model is to suppose that we want to learn about some causal effect <span class="math inline">\(M\)</span>. When we conduct a study, our estimate <span class="math inline">\(\hat{M}\)</span> reflects the true effect <span class="math inline">\(M\)</span>, plus bias <span class="math inline">\(b\)</span>, plus error <span class="math inline">\(u\)</span>:
<span class="math display">\[\begin{align*}
  \hat{M} &amp;= M + b + u,
\end{align*}\]</span></p>
<p>The authors show that if we want to update our priors about <span class="math inline">\(M\)</span>, the amount of updating we do from the study depends on our priors about the degree of bias. If our study is experimental, where we can assume <em>a priori</em> that the bias <span class="math inline">\(b\)</span> is either zero or very small, our posterior uncertainty about the causal effect is greatly reduced, and we learn a lot about <span class="math inline">\(M\)</span>. When we are in an observational study and have more diffuse priors about the size of the uncorrected bias <span class="math inline">\(b\)</span> (and the data don’t allow us any way to update our prior about <span class="math inline">\(b\)</span>) then we don’t know exactly what we’ve learned about <span class="math inline">\(M\)</span> having looked at the data.</p>
<p>I think the intuition of this model is very good. It makes perfect sense that when you are less certain about the biases in a study, you are less certain about its findings. Fair!</p>
<div id="but" class="section level1">
<h1>But</h1>
<p>The namesake of the theoretical endeavor, the <strong>Illusion of Learning from Observational Research</strong>, comes from a result where we have <em>flat priors</em> about the bias <span class="math inline">\(b\)</span> and thus we learn <em>nothing</em> from having conducted an observational study.</p>
<p>What I want to assert is that this is a degenerate case that does not accurately characterize observational research and never really occurs in real life.</p>
<p>Suppose we conduct an observational study and detect an effect of size <span class="math inline">\(1.0\)</span>. If we are concerned about uncorrected bias in the study design, practically speaking we are mainly concerned with the possibility that the effect is over-estimated.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>
Chances are we think that the true effect is between 0 and the uncorrected observational effect, so we actually have pretty specific priors about the bias! Do we put much probability on the possibility that the true effect is <em>double</em> the estimated effect, or greater? Probably not, since we tend to worry that observational findings are primarily inflated by unobserved confounders and biased self-selection into treatment (though it is not impossible that the bias attenuates the estimate). Do we think the true effect is just as big as the estimated effect but in the exact opposite direction? Again, probably not, if careful theorizing and hypothesizing are underlying our expectations for the study in the first place.</p>
<p>Rearranging terms, your prior about the size of <span class="math inline">\(b\)</span> is the distribution of differences between your priors for the true and estimated effects. Setting <span class="math inline">\(u\)</span> to <span class="math inline">\(0\)</span> for a moment…
<span class="math display">\[\begin{align*}
  b &amp;= \hat{M} - M
\end{align*}\]</span>
If you have some expectation about the true and estimated effects, you actually have reasonably clear priors about the size of the bias in observational studies. So the <strong>Illusion</strong> of learning from observational studies is a bit of an overstatement.</p>
<p>Confronting the fact that our priors are never flat, I low-key worry how many people have read the original piece and come away with the impression that flat priors about <span class="math inline">\(b\)</span> is a fair or accurate representation of observational research. I don’t mean this as a defense of biased research, so much as a criticism of flat priors. I don’t know if Gerber et al. intended for the flat priors case to be interpreted as “realistic”—on the one hand, the flat-priors result is the namesake of the piece, but their numerical example uses a non-flat prior for the bias term—but if a reader isn’t already thinking hard about their priors, then it’s easy to see how they might not catch this.</p>
</div>
<div id="zooming-out" class="section level1">
<h1>Zooming out</h1>
<p>There are a few mid-level lessons we could reinforce by thinking about our priors about bias in observational studies.</p>
<p>First, there’s never a bad time to remember that (improper) flat priors are unrealistic. If data are strong enough, obviously, inferences given flat priors can look like inferences given informed priors, but we should worry about any exercise where some theoretical result <em>necessarily depends</em> on an assumption of flat priors. In thought experiments and in real data analysis, you can always do better than a flat prior.</p>
<p>Relatedly, Bayesians are keen to highlight areas where informed priors provide important stability to some result that would have looked like nonsense under flat priors. This is one of those cases. Flat priors lead you in an unstable direction assessing the information conveyed by research. It’s only in a case where you have more informed priors about the terms in the Gerber et al. model where the results conform to how we actually think about research findings.</p>
<p>Lastly, I am increasingly preoccupied by the way Bayes’ theorem is routinely used in theoretical models to convey important intuitions about causal inference and yet there is nearly zero formal incorporation of Bayesian priors in applied data analysis of causal inference designs (in political science at least; other fields mix these things much more). I’m trying to write a paper about doing applied Bayesian analysis in causal inference, and I hope the causal inference crowd can be convinced to legalize it!</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>
Critics may be concerned that an effect is under-estimated but the prevailing emphasis on null-hypothesis testing strongly redirects critical attention away from this possibility.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>

    </div>

    <div class="post-copyright">
             
            <p class="copyright-item">
                <span>Author:</span>
                <span>Michael DeCrescenzo </span>
                </p>
            
           
             
            <p class="copyright-item">
                    <span>Link:</span>
                    <a href=/2019/2019-02-23_gerber-green-kaplan/>/2019/2019-02-23_gerber-green-kaplan/</span>
            </p>
            
            
    </div>

  
    <div class="post-tags">
        
            <section>
            <i class="iconfont icon-tag"></i>Tag(s): 
            
            <span class="tag"><a href="/tags/experiments/">
                    #Experiments</a></span>
            
            <span class="tag"><a href="/tags/bayesian-statistics/">
                    #Bayesian statistics</a></span>
            
            </section>
        
        <section>
                <a href="javascript:window.history.back();">back</a></span> · 
                <span><a href="/">home</a></span>
        </section>
    </div>

    <div class="post-nav">
        
        <a href="/2018/2018-10-19-partialling-out/" class="prev" rel="prev" title="A Visualization of Partial Effects in Multiple Regression"><i class="iconfont icon-left"></i>&nbsp;A Visualization of Partial Effects in Multiple Regression</a>
         
        
        <a href="/2019/2019-06-19_bayesian-causal-mediation/" class="next" rel="next" title="Causal Mediation, Bayesianly (with Stan)">Causal Mediation, Bayesianly (with Stan)&nbsp;<i class="iconfont icon-right"></i></a>
        
    </div>

    <div class="post-comment">
          
                 
          
    </div>
</article>
          </div>
		   </main>
      <footer class="footer">
    <div class="copyright">
        &copy;
        
        <span itemprop="copyrightYear">2016–2019</span>
        
         
            <span class="author" itemprop="copyrightHolder"><a href="/">Michael DeCrescenzo</a> | </span> 
         

         
    <span>Powered by <a href="https://gohugo.io/" target="_blank" rel="external nofollow">Hugo</a> & <a href="https://github.com/liuzc/leaveit" target="_blank" rel="external nofollow">LeaveIt</a></span> 
    </div>
</footer>












    
    
    <script src="/js/vendor_no_gallery.min.js" async=""></script>
    
  



     </div>
  </body>
</html>
