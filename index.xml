<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Michael DeCrescenzo on Michael DeCrescenzo</title>
    <link>/</link>
    <description>Recent content in Michael DeCrescenzo on Michael DeCrescenzo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 Sep 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Great Hugo themes (that I did not pick)</title>
      <link>/2018/2018-09-23-hugo-themes/</link>
      <pubDate>Sun, 23 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/2018-09-23-hugo-themes/</guid>
      <description>&lt;p&gt;I just finished a major website overhaul. While it took only about one day of work, I’ve had my eyes open for a new &lt;a href=&#34;https://themes.gohugo.io/&#34;&gt;theme&lt;/a&gt; for &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; for a while.&lt;/p&gt;
&lt;p&gt;I mean, a &lt;em&gt;while&lt;/em&gt;. I would download a theme, give it a 15-minute test run offline, and decide that it wasn’t for me. I did that maybe a dozen times.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;But this is mainly my fault. I am a bad combination of &lt;em&gt;picky&lt;/em&gt; and &lt;em&gt;unskilled&lt;/em&gt; with websites and web design, which made me a fickle chooser throughout the process. So to make up for that fickleness, I wanted to acknowledge and promote some of the Hugo themes that I really liked, but ultimately did not choose for my site.&lt;/p&gt;
&lt;div id=&#34;goa&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goa&lt;/h2&gt;
&lt;p&gt;I previously used &lt;a href=&#34;https://themes.gohugo.io/hugo-goa&#34;&gt;Goa&lt;/a&gt; for my site. It is simple, sensible, and easy to modify.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;One of two themes by &lt;a href=&#34;https://vickylai.com/&#34;&gt;Vicky Lai&lt;/a&gt; that I will promote. &lt;a href=&#34;https://themes.gohugo.io/hugo-theme-introduction/&#34;&gt;Indroduction&lt;/a&gt; has a bold design and a layout that is focused on the landing page, which I enjoyed. I especially loved the “About” section.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;call-me-sam&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Call Me Sam&lt;/h2&gt;
&lt;p&gt;The other Vicky Lai theme. If “Introduction” was bold, I would say that &lt;a href=&#34;https://themes.gohugo.io/hugo-theme-sam/&#34;&gt;Call Me Sam&lt;/a&gt; is &lt;em&gt;brave&lt;/em&gt;. I don’t trust that my description will do it justice; better to &lt;a href=&#34;http://vickylai.com/call-me-sam&#34;&gt;see for yourself&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cocoa-enhanced&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cocoa Enhanced&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://themes.gohugo.io/cocoa-eh-hugo-theme/&#34;&gt;Cocoa Enhanced&lt;/a&gt; is crisp and clean. Its type design is opinionated but flexible. I was most tempted to use this theme.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;coder&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Coder&lt;/h2&gt;
&lt;p&gt;I must include &lt;a href=&#34;https://themes.gohugo.io/hugo-coder/&#34;&gt;Coder&lt;/a&gt; because it is the inspiration for the theme I ultimately chose. Why do I like it? The simple landing page. The navigation bar is out of the way but present. The backend tension between “section” pages and “post” archives (one of the more difficult aspects for a newbie working with Hugo) is easily to navigate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;let-me-know-about-your-theme-that-you-really-like&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Let me know about your theme that you really like&lt;/h1&gt;
&lt;p&gt;Perhaps on &lt;a href=&#34;https://twitter.com/mikedecr&#34;&gt;Twitter&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;The only way I was able to test themes so efficiently was thanks to the amazing &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;blogdown&lt;/a&gt; package for R.&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Packages &amp; Reproducibility: Install what you need, attach what you want</title>
      <link>/2018/2018-05-26-reproducible-packages/</link>
      <pubDate>Wed, 30 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/2018-05-26-reproducible-packages/</guid>
      <description>&lt;p&gt;&lt;em&gt;(Note: An earlier version of this post referred to “loading” packages when I really meant “attaching.” Thanks to &lt;a href=&#34;https://twitter.com/thosjleeper/status/1001859564113924096&#34;&gt;Thomas Leeper&lt;/a&gt; for the clarification.)&lt;/em&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;When we distribute R code (for publication/replication archives, on Github, through blog posts, etc), we like the code to run smoothly on someone else’s machine. Packages present a nominal problem because different users have different packages installed on their computer. Ideally the script we are distributing should install dependencies without the redundancy of re-installing packages that a user already has installed.&lt;/p&gt;
&lt;p&gt;To solve this, many users conditionally install packages using &lt;code&gt;require()&lt;/code&gt;; if a package fails to attach, it is installed. Supposing that we want to use a package called &lt;code&gt;pkg&lt;/code&gt;…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# if require() succeeds, package is attached
# if require() fails, package is installed
if (require(&amp;quot;pkg&amp;quot;) == FALSE) {
  install.packages(&amp;quot;pkg&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see often see this in (for example) package ReadMe files on Github. But for distributing bigger projects, the approach has two shortcomings.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Sometimes we require a package, but we don’t want to attach it fully. We may only need it for a function or two, or we want to prevent &lt;a href=&#34;https://github.com/r-lib/conflicted&#34;&gt;clashing function names&lt;/a&gt; in projects that use many packages, and so we prefer to use the &lt;code&gt;pkg::function()&lt;/code&gt; grammar instead of attaching every package with &lt;code&gt;library()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If we require several packages for a large project (like a replication archive for a published journal article), including code to install all packages ends up unsightly and repetitive (but functional, to be fair).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This post discusses a straightforward strategy for addressing this.&lt;/p&gt;
&lt;div id=&#34;check-for-installed-packages-without-attaching-them&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Check for installed packages without attaching them&lt;/h2&gt;
&lt;p&gt;Rather than use &lt;code&gt;require()&lt;/code&gt;, which has the side-effect of attaching an installed package, we can look for installed packages using the output from &lt;code&gt;installed.packages()&lt;/code&gt;. In particular, the function should return an array whose rownames contain the names of our installed packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(rownames(installed.packages()))
## [1] &amp;quot;abind&amp;quot;     &amp;quot;acepack&amp;quot;   &amp;quot;AER&amp;quot;       &amp;quot;Amelia&amp;quot;    &amp;quot;animation&amp;quot; &amp;quot;arm&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using these rownames, we can check for installed packages without attaching those packages incidentally. Just create a character vector of required packages and cross-reference those names with the list of installed packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;c(&amp;quot;ggplot2&amp;quot;, &amp;quot;beepr&amp;quot;, &amp;quot;some_other_package&amp;quot;) %in% rownames(installed.packages())
## [1]  TRUE  TRUE FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;install-what-we-need-attach-what-we-want&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Install what we need, attach what we want&lt;/h2&gt;
&lt;p&gt;The structure laid out above can be augmented to install missing packages. Just use a little bit of indexing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# vector of requirements 
requires &amp;lt;- c(&amp;quot;pkg_1&amp;quot;, &amp;quot;pkg_2&amp;quot;)

# evaluates to TRUE if not already installed
to_install &amp;lt;- (requires %in% rownames(installed.packages()) == FALSE)

# install missing packages
cloud_url &amp;lt;- &amp;quot;https://cloud.r-project.org/&amp;quot;
install.packages(requires[to_install], repos = cloud_url)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because we never call &lt;code&gt;require()&lt;/code&gt;, we can attach (or not attach) whichever packages we want with subsequent &lt;code&gt;library()&lt;/code&gt; commands. (We could have also used &lt;code&gt;requireNamespace()&lt;/code&gt; to check for packages.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;coda-on-the-use-of-library-vs-require&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Coda: on the use of &lt;code&gt;library()&lt;/code&gt; vs &lt;code&gt;require()&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Thinking back to this &lt;a href=&#34;https://yihui.name/en/2014/07/library-vs-require/&#34;&gt;oft-cited post by Yihui Xie&lt;/a&gt;, the takeaway was that we should only be using &lt;code&gt;require()&lt;/code&gt; to…&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;conditionally install packages, or&lt;/li&gt;
&lt;li&gt;implement “bonus-features” that may enhance a package or function but that aren’t strictly necessary&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In reference to [1], I think we can (and should) flatly avoid &lt;code&gt;require()&lt;/code&gt; in any situation where we need a package but don’t want to attach it. For me, this is basically all of my research projects, and I think many other users will find themselves in a similar boat. As long as &lt;code&gt;require&lt;/code&gt; attaches a package in the process of checking for it, &lt;code&gt;require&lt;/code&gt; gives unintended and unnecessary side-effects.&lt;/p&gt;
&lt;p&gt;In reference to [2], it’s a little funny that we got to a point where we would only use a function called &lt;code&gt;require&lt;/code&gt; for features that are strictly not required. It’s quite the contradiction. In a parallel universe we might have named the function something squishier like &lt;code&gt;suppose()&lt;/code&gt;. At any rate, the chief reason to use &lt;code&gt;require&lt;/code&gt; in this case—it returns logical output—isn’t necessary either, since &lt;code&gt;library()&lt;/code&gt; has a &lt;code&gt;logical.return&lt;/code&gt; argument that achieves the same objective.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;thanks-for-reading&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Thanks for reading&lt;/h1&gt;
&lt;p&gt;Feel free to &lt;a href=&#34;https://www.twitter.com/mikedecr&#34;&gt;get in touch&lt;/a&gt; with comments, links to related posts by others, packages that implement similar features, and so on.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Code</title>
      <link>/code/</link>
      <pubDate>Mon, 23 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/code/</guid>
      <description>&lt;div id=&#34;templates-for-mathrmlatex-and-r-markdown&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Templates for &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt; and R Markdown&lt;/h2&gt;
&lt;p&gt;Document styles, not too complicated, but with a personal touch. Now &lt;a href=&#34;https://github.com/mikedecr/document-templates&#34;&gt;available on Github&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt; article (&lt;code&gt;pdflatex&lt;/code&gt;). &lt;a href=&#34;https://github.com/mikedecr/document-templates/blob/master/tex/pdflatex/article/pdflatex-article.pdf&#34;&gt;View example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R Markdown article (&lt;code&gt;pdflatex&lt;/code&gt;). &lt;a href=&#34;https://github.com/mikedecr/document-templates/blob/master/rmd/pdflatex/rmd-pdflatex-article.pdf&#34;&gt;View example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TBD: &lt;code&gt;memoir&lt;/code&gt;-class documents (e.g. for dissertations).&lt;/li&gt;
&lt;li&gt;TBD: &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt; and R Markdown documents built with &lt;code&gt;xelatex&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Templates use Minion and Myriad typeface packages, which won’t be set up for &lt;code&gt;pdflatex&lt;/code&gt; unless you have &lt;a href=&#34;https://github.com/sebschub/FontPro&#34;&gt;done the work&lt;/a&gt; for that. If you want the quick route to enabling those typefaces, build your document with &lt;code&gt;xelatex&lt;/code&gt; instead of &lt;code&gt;pdflatex&lt;/code&gt; (but N.B. &lt;code&gt;xelatex&lt;/code&gt;’s typography isn’t as strong). If you don’t want either, change the typeface package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;workshops-math-camp-and-mathrmlatex&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Workshops: Math Camp and &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Materials for these workshops are all open source and available on Github:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/mikedecr/math-camp-2018&#34;&gt;Math camp&lt;/a&gt; for political science graduate students.&lt;/strong&gt; Introduces important concepts in algebra/pre-calculus, basic linear algebra, set notation and theory, derivative and integral calculus, and probability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/mikedecr/latex-workshop-2018&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt;&lt;/a&gt; workshop.&lt;/strong&gt; What is &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt;, example documents, bibliographies, beamer, workflow integration with statistical software, R Markdown, and Xaringan&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;sublime-text-user-settings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sublime Text User Settings&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.sublimetext.com/&#34;&gt;Sublime Text&lt;/a&gt; editor is a great mix of &lt;a href=&#34;https://packagecontrol.io/&#34;&gt;extensibility&lt;/a&gt; and usability for social science, but its &lt;a href=&#34;http://docs.sublimetext.info/en/latest/customization/settings.html&#34;&gt;text-based settings&lt;/a&gt; can be daunting for the uninitialized and a rabbit hole for the detail-obsessed.&lt;/p&gt;
&lt;p&gt;My settings can be viewed and pilfered at will from &lt;a href=&#34;https://github.com/mikedecr/sublime-user-settings&#34;&gt;Github&lt;/a&gt;. Highlights include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Keybindings (primarily for R and &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt;) and associated macro files.&lt;/li&gt;
&lt;li&gt;Code snippets for various languages—mainly R and &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt;, but some for Stan, Stata, HTML, and Markdown.&lt;/li&gt;
&lt;li&gt;Modified &lt;code&gt;solarized&lt;/code&gt; color schemes, available in light, dark, and lastly “gray,” which is a weird hybrid of a few color schemes.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;github&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Github&lt;/h2&gt;
&lt;p&gt;This website is continuously undergoing revisions, and some useful code may have no home on this page. Feel free to dig around in my &lt;a href=&#34;https://github.com/mikedecr&#34;&gt;Github repositories&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 3: Analysis</title>
      <link>/811/811-analysis/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/811/811-analysis/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::opts_chunk$set(cache = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;schedule&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Schedule&lt;/h1&gt;
&lt;p&gt;Read this before our final lecture, after the &lt;a href=&#34;811/811-graphics&#34;&gt;graphics lesson&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-follow-along&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to follow along&lt;/h1&gt;
&lt;p&gt;A script file walking through some of these commands is available &lt;a href=&#34;https://uwmadison.box.com/s/r224nk4rjll638dhndigeksvhwjuaq3q&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;objectives&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Objectives&lt;/h1&gt;
&lt;p&gt;In this lesson, we will introduce how to do statistical analysis using R. Topics that you should cover to prepare for the take-home exercise include…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Means, confidence intervals, and simple significance tests&lt;/li&gt;
&lt;li&gt;Estimating regression models&lt;/li&gt;
&lt;li&gt;Generating model output&lt;/li&gt;
&lt;li&gt;Model diagnostics and fit statistics&lt;/li&gt;
&lt;li&gt;Post-estimation graphics (model predictions)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This page also contains some content on more advanced topics, but these won’t be necessary for the take-home exercise. These include…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;intermediate R tools and routines&lt;/li&gt;
&lt;li&gt;lists&lt;/li&gt;
&lt;li&gt;&lt;code&gt;apply()&lt;/code&gt; functions&lt;/li&gt;
&lt;li&gt;mapping functions to nested data frames&lt;/li&gt;
&lt;li&gt;custom functions&lt;/li&gt;
&lt;li&gt;type coercion&lt;/li&gt;
&lt;li&gt;a reference list of tools for advanced analysis&lt;/li&gt;
&lt;li&gt;time series&lt;/li&gt;
&lt;li&gt;panel models&lt;/li&gt;
&lt;li&gt;multilevel models&lt;/li&gt;
&lt;li&gt;Bayesian models&lt;/li&gt;
&lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since we should be getting used to R, I will sprinkle some more interesting data manipulation tricks into the analysis. Pay careful attention, as some of these tricks may come in handy in the future! As always, I recommend you run pipe chains chunk by chunk so you can see how each function in the chain contributes to the final result.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-and-packages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data and packages&lt;/h1&gt;
&lt;p&gt;Load packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;Rmisc&amp;quot;)
library(&amp;quot;magrittr&amp;quot;)
library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;ggplot2&amp;quot;)
library(&amp;quot;broom&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Set the default &lt;code&gt;ggplot&lt;/code&gt; theme.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_set(theme_bw())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Set your directory and read data from that we saved at the end of the previous lesson.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;setwd(&amp;quot;~/path/to/wherever&amp;quot;)
anes &amp;lt;- readRDS(&amp;quot;data/anes-modified-2.RDS&amp;quot;) %&amp;gt;% print()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;non-regression-analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Non-regression analysis&lt;/h1&gt;
&lt;p&gt;Previous lessons covered two major types of non-statistical analysis. We saw how to create some simple tables of variables in your data (using either the &lt;code&gt;table()&lt;/code&gt; function or the &lt;code&gt;count()&lt;/code&gt; function). We also saw how to create graphics, which are a major arena of non-statistical analysis.&lt;/p&gt;
&lt;div id=&#34;estimates-and-confidence-intervals&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Estimates and confidence intervals&lt;/h2&gt;
&lt;p&gt;When we generate estimates from data, we are usually interested in the point estimate and the uncertainty in that estimate.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Rmisc&lt;/code&gt; package has &lt;code&gt;CI&lt;/code&gt; and &lt;code&gt;group.CI&lt;/code&gt; functions for estimating means with confidence intervals. The &lt;code&gt;group.CI()&lt;/code&gt; function is better than &lt;code&gt;CI()&lt;/code&gt; for several reasons, so we’ll use for subgroup estimates and ungrouped estimates.&lt;/p&gt;
&lt;p&gt;For ungrouped estimates, we use the following syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# CIs for no groups
#   place a `1` where you&amp;#39;d otherwise put a group variable
group.CI(libcon_self ~ 1, data = anes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   libcon_self.upper libcon_self.mean libcon_self.lower
## 1          4.254325         4.238207          4.222089&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remember that every confidence interval has associated assumptions. This interval assumes that the sampling distribution of the mean is normally distributed. This is often a fine assumption, but the fact that we have only seven valid values makes this variable slightly problematic. (You would probably not get pushback for doing this though, because most people don’t think about these assumptions).&lt;/p&gt;
&lt;p&gt;You can add a grouping variable like so. We’ll estimate the mean ideological self-placement within each party ID on the 7-point partisanship index.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;group.CI(libcon_self ~ pid7, data = anes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   pid7 libcon_self.upper libcon_self.mean libcon_self.lower
## 1    1          3.475202         3.435936          3.396670
## 2    2          3.887528         3.854468          3.821408
## 3    3          3.669637         3.630272          3.590906
## 4    4          4.231836         4.190113          4.148389
## 5    5          4.779278         4.740784          4.702289
## 6    6          4.804295         4.771926          4.739557
## 7    7          5.502972         5.468599          5.434226&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;group.CI()&lt;/code&gt; function returns a data frame, so you could plot this pretty easily. We’ll add a dividing line at “moderate.”&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# calculate mean self-placement, by party ID
# since 2000 only

mean_ideo &amp;lt;- anes %&amp;gt;%
  filter(cycle &amp;gt;= 2000) %&amp;gt;% 
  group.CI(libcon_self ~ pid7, data = .) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   pid7 libcon_self.upper libcon_self.mean libcon_self.lower
## 1    1          3.289021         3.227399          3.165776
## 2    2          3.703974         3.641940          3.579906
## 3    3          3.625136         3.561119          3.497103
## 4    4          4.247556         4.181102          4.114649
## 5    5          4.963396         4.895777          4.828159
## 6    6          5.002320         4.943096          4.883872
## 7    7          5.759156         5.706492          5.653827&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot self-placement over party ID
# modifying axis scales
# confidence intervals are there, just small

ggplot(mean_ideo, aes(x = as.factor(pid7), y = libcon_self.mean)) + 
  geom_hline(yintercept = 4, color = &amp;quot;gray50&amp;quot;) +
  geom_pointrange(aes(ymin = libcon_self.lower, ymax = libcon_self.upper)) +
  labs(y = &amp;quot;Ideological Self-Placement&amp;quot;,
       x = &amp;quot;Party ID&amp;quot;) +
  scale_x_discrete(labels = c(&amp;quot;Strong\nDem&amp;quot;, &amp;quot;Weak\nDem&amp;quot;, &amp;quot;Lean\nDem&amp;quot;, &amp;quot;Independent&amp;quot;, &amp;quot;Lean\nRep&amp;quot;, &amp;quot;Weak\nRep&amp;quot;, &amp;quot;Strong\nRep&amp;quot;)) +
  scale_y_continuous(breaks = 1:7,
                     labels = c(&amp;quot;Very Lib&amp;quot;, &amp;quot;Lib&amp;quot;, &amp;quot;Slight Lib&amp;quot;, 
                                &amp;quot;Moderate&amp;quot;, 
                                &amp;quot;Slight Con&amp;quot;, &amp;quot;Con&amp;quot;, &amp;quot;Very Con&amp;quot;)) +
  coord_cartesian(ylim = c(1, 7)) +
  theme(panel.grid.minor = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-05-analysis_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Be warned. Because the &lt;code&gt;group.CI()&lt;/code&gt; function returns a data frame and not just a single value, it will make &lt;code&gt;dplyr::summarize()&lt;/code&gt; upset if you try to group a data frame and estimate that way. We can show an advanced way of dealing with this later (nesting and mapping).&lt;/p&gt;
&lt;p&gt;Let’s do one more example where we try to detect some evidence of ideological polarization/sorting over time. We’ll track how the mean ideology among Democrats and Republicans changes over time. We use the &lt;code&gt;as_data_frame()&lt;/code&gt; function to convert the table to a tibble (for nicer printing).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# collapse party into Ds and Rs, else NA
# Find mean self-placement in each party, in each cycle
# convert to data_frame for prettier printing

sorting &amp;lt;- anes %&amp;gt;%
  mutate(party = case_when(pid7 %in% 1:3 ~ &amp;quot;Democrat&amp;quot;,
                           pid7 %in% 5:7 ~ &amp;quot;Republicans&amp;quot;)) %&amp;gt;%
  group.CI(libcon_self ~ party + cycle, data = .) %&amp;gt;%
  as_data_frame() %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 38 x 5
##    party       cycle libcon_self.upper libcon_self.mean libcon_self.lower
##    &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;             &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;             &amp;lt;dbl&amp;gt;
##  1 Democrat     1972              3.86             3.77              3.68
##  2 Republicans  1972              4.73             4.64              4.55
##  3 Democrat     1974              3.84             3.73              3.63
##  4 Republicans  1974              4.85             4.74              4.62
##  5 Democrat     1976              3.89             3.79              3.70
##  6 Republicans  1976              4.98             4.88              4.79
##  7 Democrat     1978              3.85             3.76              3.67
##  8 Republicans  1978              4.96             4.86              4.76
##  9 Democrat     1980              3.95             3.83              3.70
## 10 Republicans  1980              5.09             4.98              4.86
## # ... with 28 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot ideological self-placement
# Democrats and Republicans across time

ggplot(sorting, aes(x = cycle, y = libcon_self.mean, color = party)) +
  geom_line(show.legend = FALSE) +
  geom_point(show.legend = FALSE) +
  geom_ribbon(aes(ymin = libcon_self.lower, ymax = libcon_self.upper, 
                  fill = party),
              alpha = 0.3,
              color = NA,
              show.legend = FALSE) +
  coord_cartesian(ylim = c(1, 7)) +
  annotate(&amp;quot;text&amp;quot;, x = 2000, y = 2.5, label = &amp;quot;Democrats&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x = 2000, y = 6.25, label = &amp;quot;Republicans&amp;quot;) +
  scale_y_continuous(breaks = 1:7,
                     labels = c(&amp;quot;Very\nLiberal&amp;quot;, &amp;quot;Liberal&amp;quot;, &amp;quot;Slightly\nLiberal&amp;quot;, 
                                &amp;quot;Moderate&amp;quot;, 
                                &amp;quot;Slightly\nConservative&amp;quot;, &amp;quot;Conservative&amp;quot;, &amp;quot;Very\nConservative&amp;quot;)) +
  scale_x_continuous(breaks = seq(1972, 2012, 8)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  labs(x = &amp;quot;Election Cycle&amp;quot;,
       y = &amp;quot;Mean Ideological Self-Placement&amp;quot;,
       color = NULL, fill = NULL) +
  theme(panel.grid.minor = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-05-analysis_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;proportions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Proportions&lt;/h2&gt;
&lt;p&gt;For proportions, one could use &lt;code&gt;prop.test()&lt;/code&gt; for the normal approximation method (which most people learn in school), or &lt;code&gt;binom.test()&lt;/code&gt; for “exact” Clopper-Pearson intervals, which have better boundary assumptions and small-sample properties (they are estimated using quantiles of the beta distribution), but they can be conservative (a little wide, more than 95% coverage in some cases). They both work in R basically the same way though.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# find the number of democratic voters in 2012, say. Sum the TRUEs
dem_voters &amp;lt;- anes %&amp;gt;%
  filter(cycle == 2012) %$% 
  sum(vote == &amp;quot;Democratic Candidate&amp;quot;, na.rm = TRUE) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2496&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# find the num. of major party voters in 2012
twoparty_voters &amp;lt;- anes %&amp;gt;%
  filter(cycle == 2012) %$% 
  sum(vote %in% c(&amp;quot;Democratic Candidate&amp;quot;, &amp;quot;Republican Candidate&amp;quot;), 
      na.rm = TRUE) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4188&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# estimate demvoters / majorparty voters, with CI
results &amp;lt;- anes %$% 
  prop.test(dem_voters, twoparty_voters)

# view results
results&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  1-sample proportions test with continuity correction
## 
## data:  dem_voters out of twoparty_voters, null probability 0.5
## X-squared = 153.97, df = 1, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.5809257 0.6108740
## sample estimates:
##         p 
## 0.5959885&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# this is a complex object. See what&amp;#39;s inside of it
attributes(results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $names
## [1] &amp;quot;statistic&amp;quot;   &amp;quot;parameter&amp;quot;   &amp;quot;p.value&amp;quot;     &amp;quot;estimate&amp;quot;    &amp;quot;null.value&amp;quot; 
## [6] &amp;quot;conf.int&amp;quot;    &amp;quot;alternative&amp;quot; &amp;quot;method&amp;quot;      &amp;quot;data.name&amp;quot;  
## 
## $class
## [1] &amp;quot;htest&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# let&amp;#39;s grab the point estimate. 
# We can use $ to go &amp;quot;inside&amp;quot; this object
results$estimate&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         p 
## 0.5959885&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# grab the confidence interval in the same way
# it is a two-element vector (with some metadata)
results$conf.int&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5809257 0.6108740
## attr(,&amp;quot;conf.level&amp;quot;)
## [1] 0.95&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, these old hypothesis testing functions produce weird objects as output, making them feel ancient and complex. It gets tougher to organize mentally if you need to estimate proportions for multiple groups. I’ll show you how, but it’s a little complicated.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Objective
# a numerator and a denominator in every row
# group the data and apply the test function to each row

# groups = party ID
# find num of dem voters (numerator) and major party voters (denominator)

# In this chain, we take the sum of a logical variable
#   in arithmetic, logical variables are like dummy variables
#   (TRUE is treated as a 1, FALSE as a 0)

grp_raw &amp;lt;- anes %&amp;gt;%
  filter(cycle == 2012) %&amp;gt;%
  filter(!is.na(pid7)) %&amp;gt;% 
  group_by(pid7) %&amp;gt;%
  summarize(dem_voters = 
              sum(vote == &amp;quot;Democratic Candidate&amp;quot;, na.rm = TRUE),
            twoparty_voters = 
              sum(vote %in% c(&amp;quot;Democratic Candidate&amp;quot;, &amp;quot;Republican Candidate&amp;quot;),
                  na.rm = TRUE)) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 3
##    pid7 dem_voters twoparty_voters
##   &amp;lt;dbl&amp;gt;      &amp;lt;int&amp;gt;           &amp;lt;int&amp;gt;
## 1     1       1219            1234
## 2     2        519             605
## 3     3        451             486
## 4     4        174             331
## 5     5         47             428
## 6     6         61             448
## 7     7         18             645&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# think of binom.test() as being run separately for each row (group)
# since each row is a group in this case
# separately save mean, lower and upper bounds
grp_prop &amp;lt;- grp_raw %&amp;gt;%
  group_by(pid7) %&amp;gt;%  
  mutate(prop = binom.test(dem_voters, twoparty_voters)$estimate,
         lower = binom.test(dem_voters, twoparty_voters)$conf.int[1],
         upper = binom.test(dem_voters, twoparty_voters)$conf.int[2]) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 6
## # Groups:   pid7 [7]
##    pid7 dem_voters twoparty_voters   prop  lower  upper
##   &amp;lt;dbl&amp;gt;      &amp;lt;int&amp;gt;           &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     1       1219            1234 0.988  0.980  0.993 
## 2     2        519             605 0.858  0.827  0.885 
## 3     3        451             486 0.928  0.901  0.949 
## 4     4        174             331 0.526  0.470  0.581 
## 5     5         47             428 0.110  0.0818 0.143 
## 6     6         61             448 0.136  0.106  0.171 
## 7     7         18             645 0.0279 0.0166 0.0437&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot estimates with CIs as pointranges (points plus error bars)

ggplot(grp_prop, aes(x = as.factor(pid7), y = prop)) +
  geom_pointrange(aes(ymin = lower, ymax = upper)) +
  labs(x = &amp;quot;Party ID&amp;quot;,
       y = &amp;quot;Democratic share of two-party vote&amp;quot;,
       caption = &amp;quot;ANES 2012 data&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-05-analysis_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Some people have developed tools to make it easier to work with these old functions. The &lt;code&gt;broom&lt;/code&gt; package is amazing one. Let’s use the &lt;code&gt;broom::tidy&lt;/code&gt; function to clean up the output from the &lt;code&gt;prop.test()&lt;/code&gt; function from above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# results object from before
results &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  1-sample proportions test with continuity correction
## 
## data:  dem_voters out of twoparty_voters, null probability 0.5
## X-squared = 153.97, df = 1, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.5809257 0.6108740
## sample estimates:
##         p 
## 0.5959885&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# tidy results
tidy(results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    estimate statistic      p.value parameter  conf.low conf.high
## 1 0.5959885  153.9659 2.356085e-35         1 0.5809257  0.610874
##                                                 method alternative
## 1 1-sample proportions test with continuity correction   two.sided&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;tidy()&lt;/code&gt; function returns a tidy frame with columns for estimates, test statistics, &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values, confidence interval bounds, and so on. You could run &lt;code&gt;tidy()&lt;/code&gt; on lots of different proportions tests, stack them into one data frame, and then plot the results in cool ways. We’ll do something like that later when we cover regression models.&lt;/p&gt;
&lt;p&gt;For formal hypothesis testing of means, the &lt;code&gt;t.test()&lt;/code&gt; function works a lot like &lt;code&gt;prop.test()&lt;/code&gt; and &lt;code&gt;binom.test()&lt;/code&gt;. I won’t beat this lesson to death though.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;regression&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Regression&lt;/h1&gt;
&lt;p&gt;And now, the good stuff.&lt;/p&gt;
&lt;p&gt;R has functions for linear and generalized linear models. They work pretty similarly, with some important exceptions. First, we’ll review regression in general.&lt;/p&gt;
&lt;p&gt;A linear model estimates a “predicted value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;” (that is, the &lt;em&gt;mean of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, conditional on &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;&lt;/em&gt;) assuming that the observed data are the conditional mean plus a (normally distributed) residual. We could write that a few ways, but let’s start with a familiar way from PS-813.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} y_{i} &amp;amp;= \alpha + \beta x_{i} + \varepsilon_{i} \\[6pt] \varepsilon_{i} &amp;amp;\sim \mathrm{Normal} \left( 0, \, \sigma \right) \end{align}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Each predicted value of the dependent variable (&lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_{i}\)&lt;/span&gt;) is a regression on a set of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; variables and coefficients &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; and a constant &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, and residuals are normally distributed with mean of &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and some estimated standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Here’s how we estimate regression equations in R, generically, using the &lt;code&gt;lm()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# this is an example with multiple x variables
# to show that you use the `+` to specify the additive equation form
model_results &amp;lt;- lm(y ~ x1 + x2 + x3, data = dataset_name)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The syntax can read that &lt;code&gt;y&lt;/code&gt; is a function of &lt;code&gt;x1&lt;/code&gt;, &lt;code&gt;x2&lt;/code&gt;, and so on. We also must specify the data set where these data come from with &lt;code&gt;data =&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;After estimating, we usually look at detailed results using the &lt;code&gt;summary()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(model_results)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s a real example, predicting relative thermometer ratings (&lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;) using ideological self-placement (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;), with data from the 2000 election only (note the use of &lt;code&gt;filter()&lt;/code&gt; in the &lt;code&gt;data =&lt;/code&gt; argument). It seems reasonable that individuals who are more conservative are more likely to feel warmer toward the Republican candidate than they are toward the Democratic candidate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# relative feeling thermometer as a function of ideology

therm_mod &amp;lt;- lm(reltherm_cand ~ libcon_self, 
                data = filter(anes, cycle == 2000))

# regression summary

summary(therm_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = reltherm_cand ~ libcon_self, data = filter(anes, 
##     cycle == 2000))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -104.115  -22.115    0.922   20.922   75.922 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) -56.1059     4.2143  -13.31   &amp;lt;2e-16 ***
## libcon_self  13.0368     0.9446   13.80   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 32.24 on 598 degrees of freedom
##   (1207 observations deleted due to missingness)
## Multiple R-squared:  0.2416, Adjusted R-squared:  0.2403 
## F-statistic: 190.5 on 1 and 598 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;summary&lt;/code&gt; function shows us the estimated coefficients (for the intercept and predictor), standard errors, test statistics, p-values, and significance levels. We also get some information about the F test and explained variance.&lt;/p&gt;
&lt;div id=&#34;regression-tricks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Regression tricks&lt;/h2&gt;
&lt;p&gt;Let’s do a multiple regression example. How about we just do this ideological scale as a series of dummy variables instead of as a continuous predictor. We can coerce any variable to series of dummy variables by inputting the variable as a factor in the regression equation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# &amp;quot;dummy mod&amp;quot;: ideology as a set of dummies using as.factor()

dummy_mod &amp;lt;- lm(reltherm_cand ~ as.factor(libcon_self), 
                data = filter(anes, cycle == 2000))

# each effect is an offset relative to the constant

summary(dummy_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = reltherm_cand ~ as.factor(libcon_self), data = filter(anes, 
##     cycle == 2000))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -106.992  -22.320    0.462   20.462   77.462 
## 
## Coefficients:
##                         Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)              -33.583      9.292  -3.614 0.000327 ***
## as.factor(libcon_self)2    6.888     10.067   0.684 0.494140    
## as.factor(libcon_self)3   13.122      9.981   1.315 0.189122    
## as.factor(libcon_self)4   26.888      9.566   2.811 0.005107 ** 
## as.factor(libcon_self)5   45.276      9.813   4.614 4.85e-06 ***
## as.factor(libcon_self)6   58.575      9.745   6.011 3.23e-09 ***
## as.factor(libcon_self)7   60.289     12.136   4.968 8.87e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 32.19 on 593 degrees of freedom
##   (1207 observations deleted due to missingness)
## Multiple R-squared:  0.2504, Adjusted R-squared:  0.2428 
## F-statistic: 33.01 on 6 and 593 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;as.factor()&lt;/code&gt; coerced the &lt;code&gt;libcon_self&lt;/code&gt; variable, which is originally numeric (integers), to be treated as a factor variable. Whenever &lt;code&gt;lm()&lt;/code&gt; encounters a factor as an independent variable, R interprets the factor as a set of dummy variables automatically, treating the “first” level as the omitted category. It’s important to remember that when we have dummy variables, each coefficient should be interpret as an &lt;em&gt;offset&lt;/em&gt; relative to the intercept. Ordinarily you want to take great care to specify which category should be omitted, because significance testing for the dummy variables will be relative to that baseline category.&lt;/p&gt;
&lt;p&gt;If we want, we could rewrite this model by suppressing the intercept entirely with &lt;code&gt;-1&lt;/code&gt;. In that case, we would have no omitted category, so each estimated coefficient would essentially represent the mean for each group.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# all-intercepts model (no omitted category =&amp;gt; no constant)

int_mod &amp;lt;- lm(reltherm_cand ~ -1 + as.factor(libcon_self), 
                data = filter(anes, cycle == 2000))

# each estimate is a group mean

summary(int_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = reltherm_cand ~ -1 + as.factor(libcon_self), data = filter(anes, 
##     cycle == 2000))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -106.992  -22.320    0.462   20.462   77.462 
## 
## Coefficients:
##                         Estimate Std. Error t value Pr(&amp;gt;|t|)    
## as.factor(libcon_self)1  -33.583      9.292  -3.614 0.000327 ***
## as.factor(libcon_self)2  -26.696      3.875  -6.889 1.43e-11 ***
## as.factor(libcon_self)3  -20.462      3.645  -5.614 3.03e-08 ***
## as.factor(libcon_self)4   -6.695      2.276  -2.942 0.003393 ** 
## as.factor(libcon_self)5   11.692      3.156   3.705 0.000232 ***
## as.factor(libcon_self)6   24.992      2.938   8.505  &amp;lt; 2e-16 ***
## as.factor(libcon_self)7   26.706      7.807   3.421 0.000667 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 32.19 on 593 degrees of freedom
##   (1207 observations deleted due to missingness)
## Multiple R-squared:  0.2508, Adjusted R-squared:  0.2419 
## F-statistic: 28.35 on 7 and 593 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This model makes a great deal of sense just looking at it. Each intercept is the estimated mean response for each level of party ID. When respondents are more liberal, they like the Democratic candidate more than the Republican candidate, and vice versa for more conservative respondents. Watch out for significance testing though: right now, p-values are only testing against the null hypothesis that each coefficient is different from zero. You’d have to do some extra work to determine whether one intercept is statistically different from another.&lt;/p&gt;
&lt;p&gt;We could, if we want, estimate an intercept-only model (no predictors) of the following form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} y_{i} &amp;amp;= \alpha + \varepsilon_{i} \end{align}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;by writing the formula as &lt;code&gt;y ~ 1&lt;/code&gt;. This is also how we used the &lt;code&gt;group.CI()&lt;/code&gt; to estimate means without any groups.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# intercept-only model

alpha_mod &amp;lt;- lm(reltherm_cand ~ 1, 
                data = filter(anes, cycle == 2000))

# this makes sense in the math, if you think about it
# the right hand data is a &amp;quot;1&amp;quot;
# y = alpha*1 is equivalent to y = alpha

# (if you&amp;#39;ve seen regression in matrix before, 
#  this is why the first column in the X matrix is a set of 1s)

summary(alpha_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = reltherm_cand ~ 1, data = filter(anes, cycle == 
##     2000))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -94.366 -28.366   1.634  26.634  97.634 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)  
## (Intercept)  -1.6339     0.9131  -1.789   0.0738 .
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 36.47 on 1594 degrees of freedom
##   (212 observations deleted due to missingness)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-output-tables&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model output: tables&lt;/h1&gt;
&lt;p&gt;Like Stata, R can produce regression tables for you to insert into your writing. You should use these functions.&lt;/p&gt;
&lt;p&gt;In fact, my advice is that you should never, never, &lt;strong&gt;&lt;em&gt;NEVER&lt;/em&gt;&lt;/strong&gt; write up a regression table by hand. Not in &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt;, not in Word, not ever.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You are likely to make some kind of transcription error by hand-typing numbers into the table&lt;/li&gt;
&lt;li&gt;If your analysis ever changes, even slightly, you need to modify your table or create a brand-new one&lt;/li&gt;
&lt;li&gt;Spend your time researching and doing stats, not punching tables into the computer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;R provides several packages for formatting the output of an analysis into tables. This output could be formatted as &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt; code, as HTML code, as plain text, and so on. We’ll play with some table packages using the models we just estimated.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;stargazer&lt;/code&gt; package is solid and highly customizable. Its tables look good, but I find that it requires a lot of customization to make the tables look &lt;em&gt;great&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;stargazer&amp;quot;)
# latex by default
stargazer(therm_mod, dummy_mod, int_mod)
# as plain text
stargazer(therm_mod, dummy_mod, int_mod, type = &amp;quot;text&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I think I like &lt;code&gt;texreg&lt;/code&gt; a little better. I’m fairly sure it supports more model types than &lt;code&gt;stargazer&lt;/code&gt;, and its defaults are a bit more sensible than &lt;code&gt;stargazer&lt;/code&gt;’s are, at least for my uses (your uses may be different).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;texreg&amp;quot;)
texreg(list(therm_mod, dummy_mod, int_mod))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I love &lt;code&gt;xtable&lt;/code&gt; for &lt;em&gt;non-regression tables&lt;/em&gt; such as marginals and summary statistics. The tables are clean, slick, and you can get them to do what you want. (See the tables at the end of &lt;a href=&#34;https://elections.wisc.edu/news/Voter-ID-Study/Voter-ID-Study-Supporting-Info.pdf&#34;&gt;this document&lt;/a&gt;, for example.) However, &lt;code&gt;xtable&lt;/code&gt; is weirder for regression, and it’s strange in general because it often requires you to place more arguments into the &lt;code&gt;print()&lt;/code&gt; function, which is counter-intuitive. But these tables look great when you can make it work.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;xtable&amp;quot;)
print(xtable(therm_mod))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These aren’t the only tools for making tables in R. Check &lt;a href=&#34;https://stackoverflow.com/questions/5465314/tools-for-making-latex-tables-in-r&#34;&gt;here&lt;/a&gt; for more info.&lt;/p&gt;
&lt;p&gt;My general practice is to rely &lt;em&gt;only&lt;/em&gt; on code to make tables. This ensures that you don’t make any transcription errors. It also ensures that when you export these tables to an external file (next section), any update to the model in R is automatically updated in your paper (if using &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;Here’s how I advise you learn about tables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Experiment with the packages to figure out which package you like best&lt;/li&gt;
&lt;li&gt;Figure out which modifications to the default tables you tend to use the most&lt;/li&gt;
&lt;li&gt;Save these modifications somewhere (in a file, or as a keyboard shortcut), to save yourself some time whenever you write regression tables into a paper&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;exporting-regression-tables&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Exporting regression tables&lt;/h1&gt;
&lt;p&gt;This is not that difficult, but it requires some thinking about your project directory.&lt;/p&gt;
&lt;p&gt;Whenever you have some project, your directory should contain separate folders for &lt;code&gt;R/&lt;/code&gt;, &lt;code&gt;data/&lt;/code&gt;, and your writing (which I call &lt;code&gt;tex/&lt;/code&gt; or &lt;code&gt;paper/&lt;/code&gt;). Let’s assume that we’re writing a &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt; document inside a folder called &lt;code&gt;tex/&lt;/code&gt;, and we want to save a regression table from R. We should also assume that our directory in R is set to the &lt;em&gt;project root&lt;/em&gt;, i.e. the top of the project folder (for example, &lt;code&gt;&amp;quot;users/michaeldecrescenzo/box sync/research/thesis&amp;quot;&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;We can use R to create a subfolder inside of the &lt;code&gt;tex/&lt;/code&gt; folder dedicated to tables, if we don’t already have one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# makes a &amp;quot;tex&amp;quot; folder
dir.create(&amp;quot;tex&amp;quot;)


# make a tables/ folder inside of tex/
# requires a tex/ folder to exist already

dir.create(&amp;quot;tex/tables&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then save model output as a &lt;code&gt;.tex&lt;/code&gt; file in this folder location. Table-creating functions allow to you specify where you want the table to save. Specify the name of the &lt;code&gt;.tex&lt;/code&gt; file you want to save. (You can also save tables as plain text and HTML files, depending on the package, but you get the most direct utility by learning to use &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt; and saving tables as &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\TeX}\)&lt;/span&gt; files).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# save texreg table (with caption) as a .tex file, in specified location

texreg(list(therm_mod, dummy_mod, int_mod),
       caption = &amp;quot;Estimated regression results, various specifications&amp;quot;,
       file = &amp;quot;tex/tables/reg-table.tex&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then in your &lt;code&gt;research-paper.tex&lt;/code&gt; file, you can include a code to insert code from another &lt;code&gt;.tex&lt;/code&gt; file somewhere else.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;... blah blah blah. See the regression table for results.

\input{tables/reg-table}

The regression table shows that...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-output-graphics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model output: graphics&lt;/h1&gt;
&lt;p&gt;New tools in R make it very easy to produce graphical model output.&lt;/p&gt;
&lt;p&gt;We’ll talk about the &lt;code&gt;broom&lt;/code&gt; package, which we’ve already introduced somewhat. We can turn model output into a tidy data frame using &lt;code&gt;tidy()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Tidy the all-intercepts model
# separate columns for variable names, coefficients, std err, p-val...

tidy(int_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                      term  estimate std.error statistic      p.value
## 1 as.factor(libcon_self)1 -33.58333  9.291709 -3.614333 3.267050e-04
## 2 as.factor(libcon_self)2 -26.69565  3.874911 -6.889360 1.434794e-11
## 3 as.factor(libcon_self)3 -20.46154  3.644508 -5.614348 3.033553e-08
## 4 as.factor(libcon_self)4  -6.69500  2.275995 -2.941571 3.392997e-03
## 5 as.factor(libcon_self)5  11.69231  3.156237  3.704509 2.316008e-04
## 6 as.factor(libcon_self)6  24.99167  2.938296  8.505495 1.475278e-16
## 7 as.factor(libcon_self)7  26.70588  7.806597  3.420938 6.669782e-04&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Combine tidy model data frames using &lt;code&gt;bind_rows()&lt;/code&gt;, which binds data frame rows together. We do this while also adding a variable for the model name (using &lt;code&gt;mutate()&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mods &amp;lt;- bind_rows(mutate(tidy(therm_mod, conf.int = TRUE), 
                           model = &amp;quot;Continuous Predictor&amp;quot;), 
                  mutate(tidy(dummy_mod, conf.int = TRUE), 
                           model = &amp;quot;Constant and Dummies&amp;quot;), 
                  mutate(tidy(int_mod, conf.int = TRUE), 
                           model = &amp;quot;All Intercepts&amp;quot;)) %&amp;gt;%
  as_data_frame() %&amp;gt;%
  print() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 16 x 8
##    term    estimate std.error statistic  p.value conf.low conf.high model 
##    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
##  1 (Inter…   -56.1      4.21    -13.3   1.33e-35   -64.4     -47.8  Conti…
##  2 libcon…    13.0      0.945    13.8   8.18e-38    11.2      14.9  Conti…
##  3 (Inter…   -33.6      9.29     -3.61  3.27e- 4   -51.8     -15.3  Const…
##  4 as.fac…     6.89    10.1       0.684 4.94e- 1   -12.9      26.7  Const…
##  5 as.fac…    13.1      9.98      1.31  1.89e- 1    -6.48     32.7  Const…
##  6 as.fac…    26.9      9.57      2.81  5.11e- 3     8.10     45.7  Const…
##  7 as.fac…    45.3      9.81      4.61  4.85e- 6    26.0      64.5  Const…
##  8 as.fac…    58.6      9.75      6.01  3.23e- 9    39.4      77.7  Const…
##  9 as.fac…    60.3     12.1       4.97  8.87e- 7    36.5      84.1  Const…
## 10 as.fac…   -33.6      9.29     -3.61  3.27e- 4   -51.8     -15.3  All I…
## 11 as.fac…   -26.7      3.87     -6.89  1.43e-11   -34.3     -19.1  All I…
## 12 as.fac…   -20.5      3.64     -5.61  3.03e- 8   -27.6     -13.3  All I…
## 13 as.fac…    -6.69     2.28     -2.94  3.39e- 3   -11.2      -2.23 All I…
## 14 as.fac…    11.7      3.16      3.70  2.32e- 4     5.49     17.9  All I…
## 15 as.fac…    25.0      2.94      8.51  1.48e-16    19.2      30.8  All I…
## 16 as.fac…    26.7      7.81      3.42  6.67e- 4    11.4      42.0  All I…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then plot coefficients straight away. Use the variable name as the &lt;code&gt;x&lt;/code&gt; and the coefficient as the &lt;code&gt;y&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# we flip the x and y coordinates 
#   to imitate the typical look of a coefficient plot
# Notice how not every model has the same variable names...

ggplot(mods, aes(x = term, y = estimate)) +
  geom_hline(yintercept = 0, color = &amp;quot;gray50&amp;quot;) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high,
                      color = model),
                  position = position_dodge(width = -1)) +
  scale_color_brewer(palette = &amp;quot;Set2&amp;quot;) +
  coord_flip() +
  labs(x = NULL, y = &amp;quot;Estimated Coefficient&amp;quot;, color = &amp;quot;Specification&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: position_dodge requires non-overlapping x intervals&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-05-analysis_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So easy! You could then save this plot…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# creates a graphics folder, if one doesn&amp;#39;t already exist
dir.create(&amp;quot;tex/graphics&amp;quot;)

# save the plot in the graphics folder, setting height and width
# saves as PDF
ggsave(&amp;quot;tex/graphics/coefplot.pdf&amp;quot;, height = 5, width = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some other tools create these sorts of plots for you. Some folks enjoy using &lt;a href=&#34;http://www.strengejacke.de/sjPlot/sjp.lm/&#34;&gt;&lt;code&gt;sjPlot&lt;/code&gt;&lt;/a&gt;, but I have never bothered to use it. (I ordinarily don’t like packages to make plots for me. I prefer to create &lt;em&gt;data&lt;/em&gt; and decide for myself how they should be plotted. This is my personal preference, though—you do you.)&lt;/p&gt;
&lt;div id=&#34;related-saving-other-quantities-from-r-to-mathrmlatex&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Related: saving other quantities (from R to &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt;)&lt;/h2&gt;
&lt;p&gt;Just like with tables, you can save many other quantities to &lt;code&gt;tex&lt;/code&gt; files. This way, the quantities in your paper reflect quantities in the analysis &lt;em&gt;perfectly&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;For example, let’s calculate the mean GOP candidate thermometer in (say) 2012, and save it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a subdirectory for referenced values from R
# I call this folder location &amp;quot;refs&amp;quot; but you can call it whatever you want
dir.create(&amp;quot;tex/refs&amp;quot;)

# in the 2012 cycle, 
# what is the mean thermometer rating of GOP candidate?
# round it to the nearest whole number
# print the value to see what it looks like
# save the value in a .tex file for later use

anes %&amp;gt;% 
  filter(cycle == 2012) %$% # &amp;lt;--- note the pipe!
  mean(therm_gopcand, na.rm = TRUE) %&amp;gt;%
  round() %&amp;gt;%
  print() %&amp;gt;% 
  write(&amp;quot;tex/refs/mean-gop-therm-2012.tex&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, in your &lt;code&gt;.tex&lt;/code&gt; file, import this quantity directly from file…&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;...the mean rating for Mitt Romney was $\input{refs/mean-gop-therm}$&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;…which would automatically grab the contents of that saved &lt;code&gt;tex&lt;/code&gt; file and place it into your paper when you compile the &lt;code&gt;tex&lt;/code&gt; document! This practice cuts down human error, saves time (you no longer have to update everything in your &lt;code&gt;.tex&lt;/code&gt; file by hand every time you slightly change an analysis), and enhances the &lt;em&gt;reproducibility&lt;/em&gt; of your work. I highly recommend it!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;predicted-values&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Predicted values&lt;/h1&gt;
&lt;p&gt;You can generate predicted values from the data used to model using &lt;code&gt;predict()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# try it out
predict(therm_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also use &lt;code&gt;predict()&lt;/code&gt; to generate predictions for new datasets. This is good for visualizing the effect of one variable, holding others constant. You can do this by creating a “counterfactual dataset” and generating model predicts for the observations in the counterfactual data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# we only need one variable
# be sure it has the same name as the regression variable

id_frame &amp;lt;- data_frame(libcon_self = 1:7)

# use the estimated model to predict for the new data

predict(therm_mod, newdata = id_frame)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          1          2          3          4          5          6 
## -43.069118 -30.032334 -16.995550  -3.958767   9.078017  22.114801 
##          7 
##  35.151584&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also add intervals of various kinds (confidence intervals for means, prediction intervals, and so on). Let’s generate predictions for the linear model and the “all intercepts” model, and then plot them side by side for comparison.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# predictions from linear model, using the new id_frame data

lin_preds &amp;lt;- 
  predict(therm_mod, newdata = id_frame, interval = &amp;quot;confidence&amp;quot;) %&amp;gt;%
  as_data_frame() %&amp;gt;%
  print() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 3
##      fit    lwr    upr
##    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 -43.1  -49.6  -36.5 
## 2 -30.0  -34.9  -25.1 
## 3 -17.0  -20.5  -13.5 
## 4  -3.96  -6.58  -1.34
## 5   9.08   6.13  12.0 
## 6  22.1   17.9   26.3 
## 7  35.2   29.4   40.9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# predictions from intercepts model
# predict() is smart enough to factorize your predictor variable
#   if you factorized it in the model

int_preds &amp;lt;- 
  predict(int_mod, newdata = id_frame, interval = &amp;quot;confidence&amp;quot;) %&amp;gt;%
  as_data_frame() %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 7 x 3
##      fit    lwr    upr
##    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 -33.6  -51.8  -15.3 
## 2 -26.7  -34.3  -19.1 
## 3 -20.5  -27.6  -13.3 
## 4  -6.69 -11.2   -2.23
## 5  11.7    5.49  17.9 
## 6  25.0   19.2   30.8 
## 7  26.7   11.4   42.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# combine!
compare_mods &amp;lt;- 
  bind_rows(mutate(lin_preds, libcon_self = id_frame$libcon_self, 
                              mod = &amp;quot;linear&amp;quot;), 
            mutate(int_preds, libcon_self = id_frame$libcon_self, 
                              mod = &amp;quot;intercepts&amp;quot;)) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 14 x 5
##       fit    lwr    upr libcon_self mod       
##     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;       &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;     
##  1 -43.1  -49.6  -36.5            1 linear    
##  2 -30.0  -34.9  -25.1            2 linear    
##  3 -17.0  -20.5  -13.5            3 linear    
##  4  -3.96  -6.58  -1.34           4 linear    
##  5   9.08   6.13  12.0            5 linear    
##  6  22.1   17.9   26.3            6 linear    
##  7  35.2   29.4   40.9            7 linear    
##  8 -33.6  -51.8  -15.3            1 intercepts
##  9 -26.7  -34.3  -19.1            2 intercepts
## 10 -20.5  -27.6  -13.3            3 intercepts
## 11  -6.69 -11.2   -2.23           4 intercepts
## 12  11.7    5.49  17.9            5 intercepts
## 13  25.0   19.2   30.8            6 intercepts
## 14  26.7   11.4   42.0            7 intercepts&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you have these predictions as a data frame, you could plot!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot points with dodging
# suppress minor grid

ggplot(data = compare_mods, aes(x = libcon_self, y = fit)) +
  geom_hline(yintercept = 0) +
  geom_pointrange(aes(ymin = lwr, ymax = upr, shape = mod),
                  position = position_dodge(width = 0.25),
                  fill = &amp;quot;white&amp;quot;) +
  scale_x_continuous(breaks = 1:7) +
  scale_shape_manual(values = c(16, 21)) +
  coord_cartesian(ylim = c(-50, 50)) +
  labs(x = &amp;quot;Ideological Self-Placement&amp;quot;,
       y = &amp;quot;Relative Candidate Thermometer\n(Republican minus Democrat)&amp;quot;,
       shape = &amp;quot;Model&amp;quot;) +
  theme(panel.grid.minor = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-05-analysis_files/figure-html/unnamed-chunk-32-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I’ll leave it to you to interpret these models and assess the pros and cons of each.&lt;/p&gt;
&lt;div id=&#34;packages-for-model-predictions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Packages for model predictions&lt;/h2&gt;
&lt;p&gt;For more complex post-estimation graphics (e.g. first differences, marginal effects), there are some packages that make your job a little easier. I won’t cover them all (because not everyone engages in these types of predictions), but I’ll lay some out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;broom&lt;/code&gt; package (where &lt;code&gt;tidy()&lt;/code&gt; comes from) provides the &lt;code&gt;augment&lt;/code&gt; function, for augmenting a data frame with predictions from an accompanying model. This works a bit like &lt;code&gt;predict()&lt;/code&gt;, but it returns tidy data frames. &lt;code&gt;augment&lt;/code&gt; gives you a “standard error of the fit” variable rather than separate variables for upper and lower boundaries, but you can use the standard error to calculate however wide a confidence interval you desire.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;margins&lt;/code&gt; package by Thomas Leeper is meant to imitate the workflow of Stata’s &lt;code&gt;margins&lt;/code&gt; and &lt;code&gt;marginsplot&lt;/code&gt; workflow.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sjPlot&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Zelig&lt;/code&gt;, a Gary King project, tries to standardize model evaluation and visualization across model types&lt;/li&gt;
&lt;li&gt;&lt;code&gt;effects&lt;/code&gt;, which is a little older but still commonly advocated&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I prefer using &lt;code&gt;broom&lt;/code&gt; because it is meant to work in a “tidy” workflow, but you have to do the work to generate your own critical value for generating a confidence interval. I don’t find this to be an onerous task, since I believe you should be actively thinking about your critical values anyway. I don’t use this kind of stuff much, however, because I tend to do uncertainty by simulation or with a Bayesian model. Needless to say, however, there are plenty of documents and examples on the web for these packages.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;generalized-linear-models&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Generalized linear models&lt;/h1&gt;
&lt;p&gt;Generalized linear models (GLMs, such as logit, poisson regression, negative binomial regression, and so on) are similar to linear models, but they are designed for nonlinear relationships. GLMs and LMs are similar, but the following key differences distinguish the two.&lt;/p&gt;
&lt;div id=&#34;distribution-of-the-dependent-variable&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Distribution of the dependent variable&lt;/h2&gt;
&lt;p&gt;In a linear model, residuals are assumed to be normally distributed. Another way to write this is that &lt;span class=&#34;math inline&#34;&gt;\(y_{i}\)&lt;/span&gt; itself is normally distributed around the expected value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, conditional on &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Call this conditional mean &lt;span class=&#34;math inline&#34;&gt;\(\mu_{i}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} y_{i} &amp;amp;\sim \mathrm{Normal}\left( \mu_{i}, \sigma \right) \\[6pt] \mu_{i} &amp;amp;= \alpha + \beta x_{i} \end{align}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is how you write a linear model as a normally distributed &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. For generalized linear models, it’s the same basic idea, except the outcome distribution is non-normal (we’ll use &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; to indicate a dispersion parameter).&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} y_{i} &amp;amp;\sim \mathrm{Some \, Distribution}\left( \mu_{i}, \tau \right) \end{align}\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linearity&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linearity&lt;/h2&gt;
&lt;p&gt;The other component that sets GLMS apart is the linearity of the relationship between &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y.\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In a linear model: &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is assumed to have a linear effect on &lt;span class=&#34;math inline&#34;&gt;\(\mu_{i}\)&lt;/span&gt;. Coefficients describe how &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; impacts &lt;span class=&#34;math inline&#34;&gt;\(\mu_{i}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;In a GLM: &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; has a linear impact on a &lt;em&gt;transformation&lt;/em&gt; of &lt;span class=&#34;math inline&#34;&gt;\(\mu_{i}\)&lt;/span&gt;, which implies that &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is non-linearly related to &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. Coefficients describe how &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; impacts the transformed &lt;span class=&#34;math inline&#34;&gt;\(\mu_{i}\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So the full GLM is like the Normal model, but we use a different distribution, and &lt;span class=&#34;math inline&#34;&gt;\(\mu_{i}\)&lt;/span&gt; isn’t linearly related to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} y_{i} &amp;amp;\sim \mathrm{Some \, Distribution}\left( \mu_{i}, \tau \right) \\[6pt] \mathcal{f}\left( \mu_{i} \right) &amp;amp;= \alpha + \beta x_{i} \\[6pt] \mu_{i} &amp;amp;= f^{-1}\left( \alpha + \beta x_{i} \right) \end{align}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The transformation of &lt;span class=&#34;math inline&#34;&gt;\(\mu_{i}\)&lt;/span&gt; is called a &lt;em&gt;link function&lt;/em&gt;. We call these “generalized linear models” because there &lt;em&gt;is&lt;/em&gt; a linear component, but it’s a linear relationship between &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{link}(\mu_{i})\)&lt;/span&gt;. And it’s &lt;em&gt;generalized&lt;/em&gt; because a linear model fits into this framework as well, but the link function is simply &lt;span class=&#34;math inline&#34;&gt;\(1 \times \mu_{i}\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-example-using-logit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An example using logit&lt;/h2&gt;
&lt;p&gt;We’ll use logistic regression to predict a vote for the Republican presidential candidate using ideological self-placement and gender as covariates.&lt;/p&gt;
&lt;p&gt;Fitting this into the GLM framework…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The outcome distribution is Bernoulli. The dependent variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is a 1 or a 0, “success” or “failure”.&lt;/li&gt;
&lt;li&gt;We don’t model &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; directly. Instead, we want to model &lt;span class=&#34;math inline&#34;&gt;\(\pi_{i}\)&lt;/span&gt;, which is the &lt;em&gt;expected value&lt;/em&gt; of &lt;span class=&#34;math inline&#34;&gt;\(y_{i}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The link function connecting &lt;span class=&#34;math inline&#34;&gt;\(\pi_{i}\)&lt;/span&gt; to the regression equation is called the &lt;em&gt;logit&lt;/em&gt; function, a.k.a. the “log odds” of &lt;span class=&#34;math inline&#34;&gt;\(\y_{i}\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here’s the math. We’ll use &lt;span class=&#34;math inline&#34;&gt;\(y_{i}\)&lt;/span&gt; to indicate the observed vote for voter &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\pi_{i}\)&lt;/span&gt; is the probability that &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; votes for the Republican.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} y_{i} &amp;amp;\sim \mathrm{Bernoulli}(\pi_{i}) \\[6pt] \ln \left( \frac{\pi_{i}}{1 - \pi_{i}} \right) &amp;amp;= \alpha + \beta_{1} x_{1i} + \beta_{2} x_{2i} + \ldots \end{align}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As we can see, neither our data &lt;span class=&#34;math inline&#34;&gt;\(y_{i}\)&lt;/span&gt; nor the expected value &lt;span class=&#34;math inline&#34;&gt;\(\pi_{i}\)&lt;/span&gt; are linearly related to our predictors. Instead, the transformation of &lt;span class=&#34;math inline&#34;&gt;\(\pi_{i}\)&lt;/span&gt; (the log odds) is linearly related to the predictors.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-do-this-in-r.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s do this in R.&lt;/h2&gt;
&lt;p&gt;Here are the data from 1996 only.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# vote, ideology, and gender data from 1996

logit_data &amp;lt;- anes %&amp;gt;%
  filter(cycle == 1996) %&amp;gt;%
  select(vote, libcon_self, gender) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,714 x 3
##    vote                 libcon_self gender
##    &amp;lt;chr&amp;gt;                      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; 
##  1 &amp;lt;NA&amp;gt;                           4 Women 
##  2 Democratic Candidate           4 Women 
##  3 &amp;lt;NA&amp;gt;                          NA Men   
##  4 Democratic Candidate           4 Men   
##  5 Republican Candidate           4 Women 
##  6 &amp;lt;NA&amp;gt;                          NA Men   
##  7 Republican Candidate           7 Men   
##  8 Democratic Candidate          NA Men   
##  9 Democratic Candidate           4 Women 
## 10 &amp;lt;NA&amp;gt;                           7 Men   
## # ... with 1,704 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s transform this data to make it play nicely with modeling math.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# convert rvote to a dummy (treat a logical as a number, 0 or 1)
# same with gender
# center the ideology scale on 4, so the constant (x = 0) represents moderates

logit_data &amp;lt;- logit_data %&amp;gt;%
  mutate(rvote = as.numeric(vote == &amp;quot;Republican Candidate&amp;quot;),
         woman = as.numeric(gender == &amp;quot;Women&amp;quot;),
         ideo = libcon_self - 4) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,714 x 6
##    vote                 libcon_self gender rvote woman  ideo
##    &amp;lt;chr&amp;gt;                      &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 &amp;lt;NA&amp;gt;                           4 Women     NA     1     0
##  2 Democratic Candidate           4 Women      0     1     0
##  3 &amp;lt;NA&amp;gt;                          NA Men       NA     0    NA
##  4 Democratic Candidate           4 Men        0     0     0
##  5 Republican Candidate           4 Women      1     1     0
##  6 &amp;lt;NA&amp;gt;                          NA Men       NA     0    NA
##  7 Republican Candidate           7 Men        1     0     3
##  8 Democratic Candidate          NA Men        0     0    NA
##  9 Democratic Candidate           4 Women      0     1     0
## 10 &amp;lt;NA&amp;gt;                           7 Men       NA     0     3
## # ... with 1,704 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll see &lt;code&gt;NA&lt;/code&gt;s in the data. Cases with missing values are automatically dropped during estimation. You may cover missing data imputation in your maximum likelihood course.&lt;/p&gt;
&lt;p&gt;The estimation formula in R looks like &lt;code&gt;lm()&lt;/code&gt;, but we specify a family of probability distributions. We use “binomial,” which is how you do logit. (Binomial is a Bernoulli for multiple observations).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# estimate the model with glm() and binomial distribution

vote_logit &amp;lt;- glm(rvote ~ ideo + woman + ideo*woman,
                  family = binomial(link = &amp;quot;logit&amp;quot;),
                  data = logit_data)

summary(vote_logit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = rvote ~ ideo + woman + ideo * woman, family = binomial(link = &amp;quot;logit&amp;quot;), 
##     data = logit_data)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.3949  -0.8651  -0.2842   0.6189   2.5415  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&amp;gt;|z|)    
## (Intercept) -0.78991    0.15241  -5.183 2.18e-07 ***
## ideo         1.19970    0.12051   9.955  &amp;lt; 2e-16 ***
## woman        0.01939    0.20222   0.096    0.924    
## ideo:woman  -0.03668    0.16285  -0.225    0.822    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1185.24  on 857  degrees of freedom
## Residual deviance:  833.29  on 854  degrees of freedom
##   (856 observations deleted due to missingness)
## AIC: 841.29
## 
## Number of Fisher Scoring iterations: 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can create coefficient plots and tables as before, so I won’t demonstrate those. I will say that when you want to compare GLMs to one another, it is usually smarter to compare predictions or model fit statistics than it is to compare coefficients themselves. Because coefficients are on unintuitive scales (the “link scale”) and sometimes involve ancillary parameters that help adjust the fit (such as cutoff parameters in ordinal logit), small changes to the model may change coefficients in ways that &lt;em&gt;look&lt;/em&gt; large, but the effects on the actual predicted value may be negligible.&lt;/p&gt;
&lt;p&gt;Visualizing the predictions from a GLM is similar to linear modeling, but we add one step.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create counterfactual data for simulated predictions&lt;/li&gt;
&lt;li&gt;Generate linear predictions using model coefficients&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Transform linear predictions with inverse link function&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Plot as desired&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here we only use coefficients to generate the linear predictions from the model. The predictions and bounds are on the link scale (log odds ratios).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# new data frame of values -3 through 3, 
#   which is the rescaled ideology scale

# for GLMs, the critical value is always 1.96 
#   (assumes normal coefficients on the link scale)

# here are predictions on the link scale (for logit: the log-odds scale)
# using the augment() function from the broom package

logit_preds &amp;lt;- data_frame(ideo = rep(-3:3, 2),
                          woman = c(rep(1, 7), rep(0, 7)),
                          `ideo:woman` = ideo * woman) %&amp;gt;%
  augment(vote_logit, newdata = .) %&amp;gt;%
  mutate(lower = .fitted - (1.96 * .se.fit),
         upper = .fitted + (1.96 * .se.fit)) %&amp;gt;% 
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    ideo woman ideo.woman    .fitted   .se.fit      lower      upper
## 1    -3     1         -3 -4.2595782 0.4024584 -5.0483967 -3.4707596
## 2    -2     1         -2 -3.0965603 0.2997848 -3.6841384 -2.5089821
## 3    -1     1         -1 -1.9335424 0.2043722 -2.3341119 -1.5329728
## 4     0     1          0 -0.7705245 0.1329063 -1.0310208 -0.5100281
## 5     1     1          1  0.3924935 0.1325109  0.1327721  0.6522149
## 6     2     1          2  1.5555114 0.2036006  1.1564543  1.9545685
## 7     3     1          3  2.7185293 0.2989084  2.1326689  3.3043897
## 8    -3     0          0 -4.3890098 0.4698294 -5.3098755 -3.4681441
## 9    -2     0          0 -3.1893107 0.3547655 -3.8846511 -2.4939703
## 10   -1     0          0 -1.9896116 0.2449925 -2.4697968 -1.5094264
## 11    0     0          0 -0.7899125 0.1524070 -1.0886302 -0.4911947
## 12    1     0          0  0.4097866 0.1244120  0.1659392  0.6536340
## 13    2     0          0  1.6094857 0.1917619  1.2336324  1.9853390
## 14    3     0          0  2.8091848 0.2951453  2.2307000  3.3876696&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we don’t transform the linear predictions, then we get predictions on the link scale (the log odds scale in a logit model). That’s how we can have negative predicted values, for example. We could plot them, and they’d look like straight lines (just like OLS), but log odd ratios are hard to interpret. Instead, we will transform the log odds to &lt;em&gt;predicted probabilities&lt;/em&gt; using the &lt;code&gt;plogis()&lt;/code&gt; function, which is the inverse of the logit link function (a.k.a. the “logistic function,” which happens to be the cumulative distribution function of the logistic distribution).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# transform log odds to probabilities

logit_preds &amp;lt;- logit_preds %&amp;gt;%
  select(-.se.fit) %&amp;gt;%
  # mutate only the selected variables
  mutate_at(vars(.fitted, upper, lower), plogis) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    ideo woman ideo.woman    .fitted       lower      upper
## 1    -3     1         -3 0.01393143 0.006378669 0.03015576
## 2    -2     1         -2 0.04324936 0.024503313 0.07523089
## 3    -1     1         -1 0.12635901 0.088336955 0.17755914
## 4     0     1          0 0.31636567 0.262886251 0.37518693
## 5     1     1          1 0.59688280 0.533144341 0.65750940
## 6     2     1          2 0.82570832 0.760687844 0.87594393
## 7     3     1          3 0.93811120 0.894038109 0.96457910
## 8    -3     0          0 0.01226082 0.004918234 0.03023234
## 9    -2     0          0 0.03956997 0.020141001 0.07628197
## 10   -1     0          0 0.12029796 0.078002845 0.18102382
## 11    0     0          0 0.31218746 0.251876301 0.37961216
## 12    1     0          0 0.60103671 0.541389862 0.65782892
## 13    2     0          0 0.83333997 0.774453699 0.87924916
## 14    3     0          0 0.94317014 0.902972705 0.96731695&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# modify data and plot

 
ggplot(logit_preds, aes(x = ideo, y = .fitted)) +
  geom_pointrange(aes(ymin = lower, ymax = upper, 
                    color = as.factor(woman)),
                position = position_dodge(width = 0.5),
                show.legend = FALSE) +
  annotate(&amp;quot;text&amp;quot;, x = 0.5, y = .59, label = &amp;quot;Men&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x = 1.7, y = .59, label = &amp;quot;Women&amp;quot;) +
  scale_x_continuous(breaks = -3:3,
                  labels = c(&amp;quot;Very\nLiberal&amp;quot;, 
                             &amp;quot;Liberal&amp;quot;, 
                             &amp;quot;Slightly\nLiberal&amp;quot;, 
                             &amp;quot;Moderate&amp;quot;, 
                             &amp;quot;Slightly\nConservative&amp;quot;, 
                             &amp;quot;Conservative&amp;quot;, 
                             &amp;quot;Very\nConservative&amp;quot;)) +
  labs(color = NULL,
     x = &amp;quot;Ideological Self-Placement&amp;quot;,
     y = &amp;quot;Probability of Republican Vote&amp;quot;) +
  theme(panel.grid.minor = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-05-analysis_files/figure-html/unnamed-chunk-37-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note how the predictions are non-linear. The predictions approach 0% and 100% but never exceed them. GLMs are useful because they accurately capture these sorts of ceiling and floor effects.&lt;/p&gt;
&lt;p&gt;There are &lt;em&gt;loads&lt;/em&gt; of GLMs out there, because there are loads of ways your data aren’t perfectly normal and linearly related. But they all fit the same basic framework: &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; follows some distribution, and you need some link function to describe how &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is related to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-diagnostics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model diagnostics&lt;/h1&gt;
&lt;p&gt;The model objects created by &lt;code&gt;lm()&lt;/code&gt; and &lt;code&gt;glm()&lt;/code&gt; do include some model diagnosis tools, such as F-statistics, &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; values, deviance, AIC, so on. We’ll walk through some here.&lt;/p&gt;
&lt;p&gt;Some diagnostics for linear models can be easily visualized using &lt;code&gt;plot()&lt;/code&gt;, including quantile plots, and analyses of residuals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(therm_mod)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-05-analysis_files/figure-html/unnamed-chunk-38-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/811/811-05-analysis_files/figure-html/unnamed-chunk-38-2.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/811/811-05-analysis_files/figure-html/unnamed-chunk-38-3.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/811/811-05-analysis_files/figure-html/unnamed-chunk-38-4.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are certain functions and packages that can be used to generate model fit statistics. I think the easiest tool for comparing models is &lt;code&gt;broom::glance()&lt;/code&gt;. Just like &lt;code&gt;broom::tidy()&lt;/code&gt;, you can stack the data frames created by &lt;code&gt;glance()&lt;/code&gt; to compare models easily or plot the statistics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(mutate(glance(therm_mod), mod = &amp;quot;LibCon&amp;quot;), 
          mutate(glance(dummy_mod), mod = &amp;quot;Dummies&amp;quot;),
          mutate(glance(int_mod), mod = &amp;quot;Intercepts&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   r.squared adj.r.squared    sigma statistic      p.value df    logLik
## 1 0.2415795     0.2403112 32.23982 190.48075 8.179967e-38  2 -2934.283
## 2 0.2503635     0.2427786 32.18742  33.00834 2.220915e-34  7 -2930.788
## 3 0.2507613     0.2419170 32.18742  28.35287 9.973339e-34  7 -2930.788
##        AIC      BIC deviance df.residual        mod
## 1 5874.566 5887.757 621564.9         598     LibCon
## 2 5877.576 5912.752 614366.0         593    Dummies
## 3 5877.576 5912.752 614366.0         593 Intercepts&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This works for GLMs as well, but maximum likelihood models have some different fit statistics than least-squares models. If you want to compare linear and nonlinear models, you could estimate the linear model as a GLM model of Gaussian family with an “identity” link.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glance(vote_logit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   null.deviance df.null    logLik      AIC      BIC deviance df.residual
## 1      1185.241     857 -416.6439 841.2877 860.3061 833.2877         854&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some additional tips and tools.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some of these diagnostics will show an improvement in model fit even if the improvement comes from fitting noise (such as &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt;). These diagnostics are statistics that take a distribution, so you want to compare models using a statistical comparison—i.e. is the fit improvement &lt;em&gt;enough&lt;/em&gt; given that you’ve added an extra variable to the model. Examples include F-tests and likelihood-ratio tests. If you go down this route, you might check out tools such as &lt;code&gt;epicalc::lrtest()&lt;/code&gt; or the &lt;code&gt;lmtest&lt;/code&gt; package. Other packages for model assistance (such as &lt;code&gt;arm&lt;/code&gt; or &lt;code&gt;rms&lt;/code&gt;) may have similar tools as well. Other diagnostic measures will penalize you for adding variables on the front-end, such as BIC, so they don’t require formal statistical tests.&lt;/li&gt;
&lt;li&gt;My advice is that if you want to be doing this kind of intense model comparison, make sure you know what these statistics are checking and that the use is appropriate for your task at hand. There really are no hard and fast rules here, so you want to do what makes sense for your use case.&lt;/li&gt;
&lt;li&gt;Out-of-sample prediction is a good test for model over-fitting. This can be evaluated using cross-validation. The &lt;code&gt;loo&lt;/code&gt; package provides tools for easier CV performance. (Also, the AIC is intended to estimate out-of-sample model accuracy).&lt;/li&gt;
&lt;li&gt;Simulating artificial data can be a useful face-validity check. If you are estimating a generative model of your data (and you are…), the model should generate data that look like your data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;intermediate-r-tricks&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Intermediate R tricks&lt;/h1&gt;
&lt;p&gt;Now we will quickly introduce some more nitty-gritty R tricks. These may not be essential for the problem set, but over the long run, you will be a much more efficient R user if you take these concepts seriously.&lt;/p&gt;
&lt;div id=&#34;type-coercion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Type coercion&lt;/h2&gt;
&lt;p&gt;As we covered early in the course, there are a few different data types in R: logical, numeric, factor, and character. Data can be &lt;em&gt;coerced&lt;/em&gt; from one type to another with &lt;code&gt;as.type()&lt;/code&gt; functions, where &lt;code&gt;type&lt;/code&gt; refers to the resulting data type.&lt;/p&gt;
&lt;p&gt;Let’s start as broad as possible with characters. As the broadest of these data types, anything can be coerced to a character.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# logical to character
as.character(TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;TRUE&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# numeric to character
as.character(c(1, 2, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1&amp;quot; &amp;quot;2&amp;quot; &amp;quot;3&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# factor to character
F &amp;lt;- factor(c(&amp;quot;hello&amp;quot;, &amp;quot;world&amp;quot;))
as.character(F)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;hello&amp;quot; &amp;quot;world&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Converting to factor is similar. Each unique value is given its own factor level, and the order of levels is assigned alphabetically unless specified with &lt;code&gt;factor(..., levels = c(...))&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.factor(c(TRUE, FALSE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE  FALSE
## Levels: FALSE TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.factor(c(1, 2, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3
## Levels: 1 2 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# note the level order
factor(c(&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;3&amp;quot;), levels = c(&amp;quot;3&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;1&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3
## Levels: 3 2 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Converting to numeric is slightly more confusing. Logical variables are easy and can be converted to &lt;code&gt;1&lt;/code&gt;a and &lt;code&gt;0&lt;/code&gt;s.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.numeric(c(TRUE, FALSE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Factors also work, but the coercion gives numeric meaning to the underlying factor labels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# levels assigned in reverse order
(F &amp;lt;- factor(c(&amp;quot;hello&amp;quot;, &amp;quot;world&amp;quot;), levels = c(&amp;quot;world&amp;quot;, &amp;quot;hello&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] hello world
## Levels: world hello&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# note the mapping to numeric...
# Making a data frame to visualize
data_frame(factor = F, 
           numeric = as.numeric(F))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##   factor numeric
##   &amp;lt;fct&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 hello        2
## 2 world        1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Character vectors cannot be directly mapped to numeric. They need to be converted to factor first.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;char &amp;lt;- c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;z&amp;quot;)
# direct coercion leads to NAs
as.numeric(char)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA NA NA&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# coercion through factor works
as.numeric(as.factor(char))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s where you typically see these forms of coercion.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;using logicals to convert categorical variables into dummy variables&lt;/li&gt;
&lt;li&gt;using &lt;code&gt;as.factor()&lt;/code&gt; to convert a numeric index into a set of dummy variables in a regression function&lt;/li&gt;
&lt;li&gt;converting numeric caseID variables to character in order to fix any problems with leading zeroes. This is common with geocodes like FIPS codes.&lt;/li&gt;
&lt;li&gt;Converting character vectors to factors for plotting (placing categories in order for legends or panel titles).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;user-defined-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;User-defined functions&lt;/h2&gt;
&lt;p&gt;In R, we can write our own functions to perform repetitive tasks. Let’s demonstrate the a task for finding a mean.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_mean &amp;lt;- function(x) {
  
  the_sum &amp;lt;- sum(x) 
  n &amp;lt;- length(x)
  the_mean &amp;lt;- the_sum / n 
  
  return(the_mean)

}

z &amp;lt;- 1:5
my_mean(z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;User-defined functions have three components.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The function name, which is what we assign the function to.&lt;/li&gt;
&lt;li&gt;Arguments, passed to the function, manipulated within the function&lt;/li&gt;
&lt;li&gt;The definition, which details how arguments are manipulated and what the function returns&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is important to note that the variables inside the function definition are called &lt;em&gt;local variables&lt;/em&gt;. This means they only exist in the world of that function. They are not accessible elsewhere in R. In the above example, &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;the_sum&lt;/code&gt;, &lt;code&gt;n&lt;/code&gt;, and &lt;code&gt;the_mean&lt;/code&gt; are manipulated by the function but are not available to you to play with. Furthermore, if there are other objects currently in R memory that share those same names, they have no bearing on how the function works. Local variables help define a function and perform its intended purpose, but they do not affect and are not affected by the other objects in your current R workspace.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lists&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Lists&lt;/h2&gt;
&lt;p&gt;There is one data structure that we have not yet discussed: lists. Lists are like vectors, but unlike vectors, their elements can be of any data type. Let’s demonstrate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a list of named elements
el &amp;lt;- list(num = 1, 
           fact = factor(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;)),
           char = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;, &amp;quot;z&amp;quot;))
# check it out
el&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $num
## [1] 1
## 
## $fact
## [1] a b c
## Levels: a b c
## 
## $char
## [1] &amp;quot;x&amp;quot; &amp;quot;y&amp;quot; &amp;quot;z&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# numeric indexing gives you the named element (including the name)
el[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $num
## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# to get all the way down to the data...
el$num&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;el[[2]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] a b c
## Levels: a b c&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;el[[&amp;quot;char&amp;quot;]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;x&amp;quot; &amp;quot;y&amp;quot; &amp;quot;z&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This can be handy for stacks of data frames. For example, the &lt;code&gt;anes&lt;/code&gt; dataset, but element is a data frame corresponding to each survey year.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This will print a big monstrosity, 
# but you should see what it looks like
anes_list &amp;lt;- split(anes, anes$cycle)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;functional-programming-with-apply-functions.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Functional programming with &lt;code&gt;apply()&lt;/code&gt; functions.&lt;/h2&gt;
&lt;p&gt;You’ll see stuff about &lt;code&gt;apply()&lt;/code&gt; functions online. They are scary at first, but they make sense if you give them a chance.&lt;/p&gt;
&lt;p&gt;Let’s see what we mean. Let’s create a two-D object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- data_frame(a = 1:5, b = a, c = a) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 3
##       a     b     c
##   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1     1     1     1
## 2     2     2     2
## 3     3     3     3
## 4     4     4     4
## 5     5     5     5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An &lt;code&gt;apply()&lt;/code&gt; function takes an object, and applies a function across its dimension(s). This is easier to explain using an example: here, we will apply the &lt;code&gt;mean&lt;/code&gt; function to the rows and columns of this &lt;code&gt;df&lt;/code&gt; object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 1 = row
# get the mean of every row
apply(df, 1, mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3 4 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It returns an object the same length as the number of rows in the object, containing the result of the &lt;code&gt;mean()&lt;/code&gt; function for each row.&lt;/p&gt;
&lt;p&gt;Here it is for each column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 2 = columns
# get the mean of every column
apply(df, 2, mean)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## a b c 
## 3 3 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You could pass a user-defined function to &lt;code&gt;apply()&lt;/code&gt;, or you could define a function within &lt;code&gt;apply()&lt;/code&gt; using “anonymous functions.” Example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 3
##       a     b     c
##   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1     1     1     1
## 2     2     2     2
## 3     3     3     3
## 4     4     4     4
## 5     5     5     5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# apply x * x to every column
apply(df, 2, function(x) {x * x})&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       a  b  c
## [1,]  1  1  1
## [2,]  4  4  4
## [3,]  9  9  9
## [4,] 16 16 16
## [5,] 25 25 25&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This anonymous function applies the function &lt;code&gt;x^2&lt;/code&gt; to each column in &lt;code&gt;df&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There are a few types of apply functions, but you’re only likely to use a few of them.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;apply&lt;/code&gt;: apply a function over the margins of an object&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sapply&lt;/code&gt;: simplify the &lt;code&gt;apply()&lt;/code&gt; results to a one-D vector, if possible&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lapply&lt;/code&gt;: apply for each element in a list&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is an &lt;code&gt;lapply&lt;/code&gt; example, using the &lt;code&gt;anes_list&lt;/code&gt; object we created above. We’ll use an anonymous function to find the mean &lt;code&gt;party_distance&lt;/code&gt; in each election cycle.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# &amp;#39;x&amp;#39; refers to each element of the list
# each element being a data frame
# so x$var finds &amp;#39;var&amp;#39; in the x data frame

lapply(anes_list, function(x) mean(x$party_distance, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From there, you can do cool things like “melt” the list into a data frame using &lt;code&gt;reshape2::melt()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lapply(anes_list, function(x) mean(x$party_distance, na.rm = TRUE)) %&amp;gt;%
  reshape2::melt()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;nesting-superpowered-lists&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Nesting: superpowered lists&lt;/h2&gt;
&lt;p&gt;When you get &lt;em&gt;really&lt;/em&gt; comfortable with function programming, you can do crazy stuff like nest a data frame. What is that?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anes %&amp;gt;%
  group_by(cycle) %&amp;gt;%
  nest() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 2
##    cycle data                  
##    &amp;lt;dbl&amp;gt; &amp;lt;list&amp;gt;                
##  1  1948 &amp;lt;tibble [662 × 961]&amp;gt;  
##  2  1952 &amp;lt;tibble [1,899 × 961]&amp;gt;
##  3  1954 &amp;lt;tibble [1,139 × 961]&amp;gt;
##  4  1956 &amp;lt;tibble [1,762 × 961]&amp;gt;
##  5  1958 &amp;lt;tibble [1,450 × 961]&amp;gt;
##  6  1960 &amp;lt;tibble [1,181 × 961]&amp;gt;
##  7  1962 &amp;lt;tibble [1,297 × 961]&amp;gt;
##  8  1964 &amp;lt;tibble [1,571 × 961]&amp;gt;
##  9  1966 &amp;lt;tibble [1,291 × 961]&amp;gt;
## 10  1968 &amp;lt;tibble [1,557 × 961]&amp;gt;
## # ... with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A nested data frame is a data frame where columns can themselves be a list of data frames (a.k.a. a “list column”). In this data frame, the &lt;code&gt;data&lt;/code&gt; column isn’t really a variable; it contains a list of data frames, each corresponding to the grouping variable (&lt;code&gt;cycle&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Unnest a list column from a data frame like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anes %&amp;gt;%
  group_by(cycle) %&amp;gt;%
  nest() %&amp;gt;%
  # unnest the `data` column
  unnest(data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why is this useful? Well…&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mapping-a-function-over-a-list-column&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mapping a function over a list column&lt;/h2&gt;
&lt;p&gt;This is another functional programming trick, like apply, but applied to a list column in a nested data frame.&lt;/p&gt;
&lt;p&gt;Let’s say we had the above nested frame (a data frame for each survey wave), but we wanted to estimate a regression for separate data frames.&lt;/p&gt;
&lt;p&gt;Here, we estimate the effect of gender on Republican voting using &lt;code&gt;purrr::map()&lt;/code&gt;, which is like &lt;code&gt;apply()&lt;/code&gt; but it works across a list column in nested data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# nesting the data
#   get indicator for R vote
#   removing NAs
#   group by cycle and nest
# Apply function over the list column
#   use every data frame in the list column
#   run glm() using an intercepts model for comparisons (no constant)
#   tidy the model output
# Unnest the data
#   unnest the results of map()
#   create a gender label

gender_gaps &amp;lt;- anes %&amp;gt;%
  mutate(rvote = as.numeric(vote == &amp;quot;Republican Candidate&amp;quot;)) %&amp;gt;% 
  filter(!is.na(rvote) &amp;amp; !is.na(gender)) %&amp;gt;%
  group_by(cycle) %&amp;gt;%
  nest() %&amp;gt;% 
  mutate(model = map(data, 
                     ~ glm(rvote ~ -1 + as.factor(gender), 
                           data = ., family = &amp;quot;binomial&amp;quot;) %&amp;gt;%
                       tidy(conf.int = TRUE))) %&amp;gt;%
  unnest(model) %&amp;gt;%
  mutate(term = case_when(str_detect(term, &amp;quot;Men&amp;quot;) ~ &amp;quot;Man&amp;quot;,
                          TRUE ~ &amp;quot;Woman&amp;quot;)) %&amp;gt;% 
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 34 x 8
##    cycle term  estimate std.error statistic  p.value conf.low conf.high
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
##  1  1948 Man     -0.228    0.145     -1.58  1.15e- 1  -0.513     0.0544
##  2  1948 Woman   -0.113    0.143     -0.787 4.31e- 1  -0.395     0.168 
##  3  1952 Man      0.286    0.0840     3.40  6.76e- 4   0.121     0.451 
##  4  1952 Woman    0.372    0.0829     4.49  6.98e- 6   0.211     0.536 
##  5  1956 Man      0.259    0.0815     3.18  1.46e- 3   0.1000    0.419 
##  6  1956 Woman    0.517    0.0809     6.39  1.71e-10   0.359     0.676 
##  7  1960 Man     -0.107    0.0967    -1.11  2.67e- 1  -0.297     0.0820
##  8  1960 Woman    0.124    0.0925     1.34  1.81e- 1  -0.0573    0.306 
##  9  1964 Man     -0.640    0.0934    -6.85  7.14e-12  -0.825    -0.459 
## 10  1964 Woman   -0.810    0.0881    -9.19  4.04e-20  -0.985    -0.639 
## # ... with 24 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# # plot coefficients over time
# # map pt shape, solid and empty points, generic white fill
ggplot(gender_gaps, aes(x = cycle, y = estimate, color = term)) +
  geom_hline(yintercept = 0) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high,
                      shape = term),
                  fill = &amp;quot;white&amp;quot;,
                  position = position_dodge(width = 0.5)) +
  scale_shape_manual(values = c(16, 21)) +
  scale_x_continuous(breaks = seq(1948, 2012, 8)) +
  labs(y = &amp;quot;Effect on Republican Voting (Log Odds Scale)&amp;quot;,
       x = &amp;quot;Election Cycle&amp;quot;,
       color = NULL, shape = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-05-analysis_files/figure-html/unnamed-chunk-57-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Mapping is a tool that takes some getting used to at first. In particular, you have to get a feel for the formula syntax where a function follows a &lt;code&gt;~&lt;/code&gt; symbol, and you use &lt;code&gt;.&lt;/code&gt; to represent element names in the &lt;code&gt;data&lt;/code&gt; column. Once you get this down, however, mapping is an extremely powerful tool for scaling up analysis because not only can you do a lot of repetitive work with very little code, the code is executed using parallel processing when possible. This makes it much faster because it distributes tasks across processing cores on your computer (nice!).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references-for-advanced-topics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References for advanced topics&lt;/h1&gt;
&lt;p&gt;As you develop your substantive scholarly interests, it is likely that you will develop a methodological expertise to fit your topic of study. Luckily, many others have come before you and have developed R tools for doing these analyses. Better yet, these computational tools are being increasingly folded into a &lt;code&gt;tidyverse&lt;/code&gt;-style tools. We’ll quickly point out a few of these resources. You will &lt;em&gt;NOT&lt;/em&gt; be required to use these tools for any take-home exercises.&lt;/p&gt;
&lt;p&gt;Some higher-level advice for navigating these packages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;My philosophy is that I like to rely on external packages for computation and estimation, but not for graphics. If there is a tool that estimates a model for me, or performs a particular statistical test, then that’s great. But I tend not to like the graphics that these tools produce. &lt;em&gt;As a result&lt;/em&gt;, I look for tools that make it easy for me to extract the data that I want to plot.&lt;/li&gt;
&lt;li&gt;Sometimes it is tedious to extract the data from these objects. In these situations, I tend to write my own functions to process the output from these packages into a tidy format for plotting or tabulating.&lt;/li&gt;
&lt;li&gt;If you want a quick and easy way to learn about packages, make a Twitter for your “academic self” and follow some researchers and R developers.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;survey-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Survey analysis&lt;/h2&gt;
&lt;p&gt;The statistics that we learn apply to data collected from simple random samples. In the real world, however, survey data often require some kind of clustered sample design and contain accompanying sample weights. Analyzing surveys requires (or, should require) accounting for weights and design as separate elements of the analysis.&lt;/p&gt;
&lt;p&gt;If you have a non-clustered sample design but some degree of oversampling, you might handle weights analytically—calculating weighted means and weighted sample sizes. If you have a more advanced sample design, you should incorporate elements of the design into the estimation. To that end, I’d recommend Thomas Lumley’s &lt;a href=&#34;https://cran.r-project.org/web/packages/survey/&#34;&gt;&lt;code&gt;survey&lt;/code&gt;&lt;/a&gt; package. You use your dataset to create a new object that contains metadata about the cluster structure of the sample. Functions in the &lt;code&gt;survey&lt;/code&gt; package then use the metadata about the sample design to estimate things properly. This is similar to the way you can declare survey design information using &lt;code&gt;svy&lt;/code&gt;-based commands in Stata.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;time-series&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Time series&lt;/h2&gt;
&lt;p&gt;For time series, you will want some special tools to deal with the accompanying statistical pitfalls: functional forms for autocorrelated errors, standard errors for autocorrelation, and the estimation of ancillary parameters for models designed for certain temporal interventions.&lt;/p&gt;
&lt;p&gt;First, for data manipulation, you will want some kind of data structure that contains metadata about which variable defines the time period. This structure will allow you to properly calculate differenced variables, lags, and leads. To create tidy, time-aware tibble datasets, you could use &lt;a href=&#34;https://github.com/business-science/tibbletime&#34;&gt;&lt;code&gt;tibbletime&lt;/code&gt;&lt;/a&gt; or the more recent (and supposedly more capable) &lt;a href=&#34;http://pkg.earo.me/tsibble/index.html&#34;&gt;&lt;code&gt;tsibble&lt;/code&gt;&lt;/a&gt;. You could also check out the &lt;code&gt;lubridate&lt;/code&gt;, &lt;code&gt;zoo&lt;/code&gt;, and &lt;code&gt;hms&lt;/code&gt; (Tidyverse!) packages for manipulating data-time variables, since the baked in R tools for dealing with &lt;code&gt;POSIXct&lt;/code&gt; and &lt;code&gt;POSIXlt&lt;/code&gt; data are very difficult to figure out. If you read that sentence and were like “wtf are &lt;code&gt;POSIXct&lt;/code&gt; and &lt;code&gt;POSIXlt&lt;/code&gt;?”, that’s exactly what I mean.&lt;/p&gt;
&lt;p&gt;For time series &lt;em&gt;modeling&lt;/em&gt;, you will want tools that perform a variety of functions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ARIMA modeling&lt;/li&gt;
&lt;li&gt;Unit root and (fractional) integration testing&lt;/li&gt;
&lt;li&gt;modeling for interventions, autoregressive distributed lag (ADL), error-correction (ECOM) vector autoregression (VAR), granger causality tests, impulse-response functions, and so on&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I don’t have expert-level advice here, but when I took our time series ITV course, I found the following packages useful for several of these needs: &lt;code&gt;TSA&lt;/code&gt;, &lt;code&gt;fUnitRoots&lt;/code&gt;, &lt;code&gt;egcm&lt;/code&gt;, &lt;code&gt;fracdiff&lt;/code&gt;, &lt;code&gt;forecast&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;panel-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Panel data&lt;/h2&gt;
&lt;p&gt;Panel data tends to be the realm of “fixed-effects” modeling, meaning that when you measure features over time, time-invariant predictors are absorbed into fixed unit-level averages, and time-varying features have coefficients that are constant across time. I don’t typically do this kind of analysis, but those who do often use the &lt;code&gt;plm&lt;/code&gt; package for these types of models.&lt;/p&gt;
&lt;p&gt;Alternatives to &lt;code&gt;plm&lt;/code&gt; include hierarchical modeling approaches, which we’ll cover in a separate subsection.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hierarchicalmultilevel-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Hierarchical/multilevel models&lt;/h2&gt;
&lt;p&gt;For complex hierarchical data structures (individuals within time periods, individuals within geographic groups, observations within countries within regions within time periods…), hierarchical models may more be a more direct modeling approach to attributing variation in the data to covariates at different levels of analysis without as much scrutiny about clustered variance estimators and so on. This is because hierarchical modeling allows you to directly model parameter estimates as functions of covariates at other levels of the data. For example, the probability that an individual votes Republican may be a function of their demographic characteristics but also the context of state the state in which they live.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} y_{i} &amp;amp;\sim \mathrm{Bernoulli}\left( \pi_{i} \right) \\[6pt] \mathrm{logit} \left( \pi_{i} \right) &amp;amp;= \alpha + \gamma^{\mathtt{demographics}}_{j[i]} + \delta^{\mathtt{state}}_{s[i]} \end{align}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The state effect applies to every individual in that state and could itself be a regression on state-level features such as the presidential vote in the state, state-level economics, and so on.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} \delta^{\mathtt{state}}_{s} &amp;amp;\sim \mathrm{Normal}\left( \beta_{1} \mathrm{pvote}_{s} + \beta_{2} \mathrm{GDP}_{s} + \ldots , \, \sigma^{\mathtt{state}} \right)\end{align}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This kind of modeling is useful because it allows estimates for small groups to “borrow strength” from larger groups. If we don’t have a lot of data for Alabama, for example, we can say that Alabama is probably like other states that have similar state-level characteristics, and it shrinks Alabama’s estimate toward the state regression trend. In other words, for small-&lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; groups, we assume that the group-level effect looks like the other group-level effects &lt;em&gt;unless&lt;/em&gt; the data give us a strong signal to the contrary. This is a key example of the bias-variance trade-off you heard about in stats courses.&lt;/p&gt;
&lt;p&gt;Although hierarchical models are “essentially Bayesian” because of the partial pooling setup, there are packages for fitting approximate maximum-likelihood versions. The most common would be &lt;code&gt;lme4&lt;/code&gt;, which provides &lt;a href=&#34;https://stats.stackexchange.com/questions/18428/formula-symbols-for-mixed-model-using-lme4&#34;&gt;syntax&lt;/a&gt; similar to &lt;code&gt;nlme&lt;/code&gt; for varying (“random”) effects, but it is more updated than &lt;code&gt;nlme&lt;/code&gt;. What I’m saying is, don’t use &lt;code&gt;nlme&lt;/code&gt;. The &lt;code&gt;arm&lt;/code&gt; package provides additional tools for interacting with &lt;code&gt;lme4&lt;/code&gt; hierarchical models, including the &lt;code&gt;bayesglm&lt;/code&gt; function that just says “screw-it” and fits the fully Bayesian version of the model. On that subject…&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bayesian analysis&lt;/h2&gt;
&lt;p&gt;Bayesian analysis varies from “frequentist” statistics in a few fundamental ways. The main source of difference is philosophical, where uncertainty estimates are understood as your uncertainty about the actual value of the parameter, and not uncertainty about the &lt;em&gt;data&lt;/em&gt;. Stated differently, frequentism measures the &lt;em&gt;probability of the data&lt;/em&gt; given an assumed model of null parameter values and infinitely repeated sampling. Bayesian statistics rejects the idea of the null model entirely and instead measures the &lt;em&gt;probability parameter values&lt;/em&gt; after having observed the data, which requires prior information over the parameter values. When it comes to the actual parameter estimates, you can think about maximum likelihood models as being &lt;em&gt;special cases of Bayesian models&lt;/em&gt; where the researcher inserts no prior information about the parameter values.&lt;/p&gt;
&lt;p&gt;There are a few ways to fit Bayesian models. For reduced-form regression models (like &lt;code&gt;lm&lt;/code&gt; and &lt;code&gt;glm&lt;/code&gt; functional forms), you can use packages such as &lt;code&gt;arm&lt;/code&gt;, &lt;code&gt;brms&lt;/code&gt;, and &lt;code&gt;rethinking&lt;/code&gt; to write Bayesian models using a &lt;a href=&#34;https://stats.stackexchange.com/questions/18428/formula-symbols-for-mixed-model-using-lme4&#34;&gt;syntax&lt;/a&gt; similar to &lt;code&gt;glm&lt;/code&gt; and &lt;code&gt;lme4&lt;/code&gt; models.&lt;/p&gt;
&lt;p&gt;For complicated structural models that are not easily expressed in a single regression equation (e.g. when you have a complex multi-level structure), you can may want to set up a fully Bayesian model using external Bayesian modeling software that can be accessed by R. For simpler models, one could use &lt;code&gt;JAGS&lt;/code&gt;, which samples a posterior distribution using a Gibbs sampling algorithm. You would use the &lt;code&gt;rjags&lt;/code&gt; package to talk to JAGS using R. For more complex hierarhical models, randomly-walking algorithms for Gibbs sampling (like &lt;code&gt;JAGS&lt;/code&gt;) do a poor job, so I recommend using &lt;code&gt;Stan&lt;/code&gt; (and talking to it with R using the &lt;code&gt;rstan&lt;/code&gt; package). Stan fits the model using a version of Hamiltonian Monte Carlo, both of which drastically increase the speed and quality of posterior sampling. The &lt;code&gt;Stan&lt;/code&gt; syntax is more complicated than &lt;code&gt;JAGS&lt;/code&gt;, but the payoff of using &lt;code&gt;Stan&lt;/code&gt; is worth it.&lt;/p&gt;
&lt;p&gt;For diagnosing and visualizing Bayesian model results, &lt;code&gt;rstan&lt;/code&gt; has some tools baked in. The &lt;code&gt;ggmcmc&lt;/code&gt; package turns posterior samples into a tidy data frame (good for ggplot!), and &lt;code&gt;bayesplot&lt;/code&gt; provides other tools for easy Bayes graphics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-as-front-end&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R as front-end&lt;/h2&gt;
&lt;p&gt;As the Bayes packages indicate, R can serve as a front-end interface to other programs and syntaxes. Some further examples include the following packages…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rsql&lt;/code&gt; and &lt;code&gt;RSQLite&lt;/code&gt; for SQL and SQLite&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Rcpp&lt;/code&gt; for C++&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rPython&lt;/code&gt; for Python&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…and so on&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;more-materials-from-past-years&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;More materials from past years&lt;/h2&gt;
&lt;p&gt;Sarah Bouchat (former instructor for this course) has online materials for some additional topics, including text analysis, Regular Expressions (RegEx), base graphics, loops, and so on. (I purposefully don’t teach loops because &lt;code&gt;apply()&lt;/code&gt; functions are better!)&lt;/p&gt;
&lt;p&gt;View Sarah’s site &lt;a href=&#34;https://bouchat.github.io/553&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 2: Graphics</title>
      <link>/811/811-graphics/</link>
      <pubDate>Fri, 16 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/811/811-graphics/</guid>
      <description>&lt;div id=&#34;schedule&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Schedule:&lt;/h1&gt;
&lt;p&gt;Read this before our second R lecture, after the &lt;a href=&#34;811/811-data&#34;&gt;data lesson&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-follow-along&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to follow along&lt;/h1&gt;
&lt;p&gt;A script file walking through some of these commands is available &lt;a href=&#34;https://uwmadison.box.com/s/mbb25zbc7r7h5plpesgk71kzjqcv7hw1&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;objectives&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Objectives&lt;/h1&gt;
&lt;p&gt;The goal of this lesson is to provide an introduction to graphics in R, by way of &lt;code&gt;ggplot2&lt;/code&gt; in particular. We will cover:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The “grammar of graphics”—the “gg” in &lt;code&gt;ggplot&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;How &lt;code&gt;ggplot2&lt;/code&gt; works&lt;/li&gt;
&lt;li&gt;Common graphics in social science&lt;/li&gt;
&lt;li&gt;Customizing the appearance of ggplot graphic&lt;/li&gt;
&lt;li&gt;Saving graphics&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;some-notes-to-get-us-started&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Some notes to get us started:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This lesson makes liberal use of pipe chains, which bundle many operations together in one block of code. After last week’s lesson, you should be getting comfortable with these. Hopefully my heavy use of them in this (and the next) lesson will demonstrate how essential piping is to the cutting-edge of using R.&lt;/li&gt;
&lt;li&gt;Because piping is so essential that it appears nearly everywhere, I cannot painstakingly describe every step of every pipe chain—it will take too much of your attention away from what I’m trying to teach in the moment. If you want to dissect what a particular pipe chain is doing, you should run the chain &lt;em&gt;up to a point&lt;/em&gt; and notice what the results look like when you stop the chain &lt;em&gt;here&lt;/em&gt; as opposed to &lt;em&gt;there&lt;/em&gt;. This is often how you write pipe chains as well—writing a line of code, checking the results, and planning what the next step should be.&lt;/li&gt;
&lt;li&gt;Plots created using &lt;code&gt;ggplot&lt;/code&gt; generally look good by default. As we get started, however, they may look a little awkward. This is because I want to begin by demonstrating ggplot &lt;em&gt;functionality&lt;/em&gt; (which we don’t want to rush though), not creating the prettiest plot imaginable. As we introduce more and more ggplot concepts, plots will begin to look better.&lt;/li&gt;
&lt;li&gt;If you want more help with &lt;code&gt;ggplot&lt;/code&gt;, I’d recommend that you consult resources I list in the syllabus, in other lessons, and Hadley Wickham’s &lt;code&gt;ggplot2&lt;/code&gt; book (which you can build into a PDF on your own computer [after installing some other tools]).&lt;/li&gt;
&lt;li&gt;For advice about the principles of creating &lt;em&gt;good&lt;/em&gt; graphics, you can also check books by folks such as &lt;a href=&#34;http://serialmentor.com/dataviz/index.html&#34;&gt;Claus Wilke&lt;/a&gt; (author of the &lt;code&gt;ggridges&lt;/code&gt; and &lt;code&gt;cowplot&lt;/code&gt; packages for augmenting &lt;code&gt;ggplot2&lt;/code&gt;) and &lt;a href=&#34;http://socviz.co/&#34;&gt;Kieran Healy&lt;/a&gt; (author of the brilliant “&lt;a href=&#34;https://kieranhealy.org/files/papers/fuck-nuance.pdf&#34;&gt;Fuck Nuance&lt;/a&gt;” paper, which isn’t about graphics but is worth reading anyway).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;get-started&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Get started&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;ggplot2&lt;/code&gt; package is loaded whenever you load the &lt;code&gt;tidyverse&lt;/code&gt; package (but I sometimes load the &lt;code&gt;ggplot2&lt;/code&gt; package anyway because it sometimes gives your code editor better auto-complete behavior). We’ll also install and load &lt;code&gt;labelled&lt;/code&gt;, which we’ll use to remove Stata labels from the data (we don’t need them).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;magrittr&amp;quot;)
library(&amp;quot;tidyverse&amp;quot;)
library(&amp;quot;ggplot2&amp;quot;)
install.packages(&amp;quot;labelled&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Set your directory where it was last lesson and load the &lt;em&gt;modified ANES dataset from the previous lesson&lt;/em&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set directory
setwd(&amp;quot;~/path/to/wherever&amp;quot;)

# read saved RDS data from last lesson
# and remove Stata labels from the data
anes &amp;lt;- readRDS(&amp;quot;data/anes-modified.RDS&amp;quot;) %&amp;gt;% 
        mutate_all(labelled::remove_labels) 

# pkg::function lets us use functions without loading the full package
# mutate_all applies a function to every variable in the dataset
#   similar to apply() functions, which we&amp;#39;ll cover next lesson&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Verify that you imported the correct dataset when you notice the modified variable names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(anes)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-grammar-of-graphics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The grammar of graphics&lt;/h1&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.springer.com/us/book/9780387245447&#34;&gt;grammar of graphics&lt;/a&gt; is essentially a theory/model that describing the components of a graphic. &lt;code&gt;ggplot2&lt;/code&gt; is an R package that implements the grammar &lt;a href=&#34;http://byrneslab.net/classes/biol607/readings/wickham_layered-grammar.pdf&#34;&gt;in a layered fashion&lt;/a&gt; by iteratively adding grammatical components to a figure using functions.&lt;/p&gt;
&lt;p&gt;It is not necessary to consciously memorize the theoretical components of the grammar of graphics—you get an unconscious feel for it—though we will briefly describe it. Suffice it to say that what matters most for you is that the underlying grammar provides a &lt;em&gt;structure&lt;/em&gt; to &lt;code&gt;ggplot2&lt;/code&gt; that makes it easy to create complex graphics with an integrated syntax and carefully chosen defaults.&lt;/p&gt;
&lt;p&gt;Here are the core components of the grammar of graphics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data&lt;/strong&gt;: what gets visualized&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Aesthetic mappings&lt;/strong&gt;: Attributes of the plot that come directly from the data (plot axes, color groupings)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Geoms&lt;/strong&gt;: geometric representations of the data (lines, points, etc.); the shapes used to present the values in your data in the plot&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scales&lt;/strong&gt;: modify how aesthetic mappings are presented. Every mapping from data to plot can be altered (e.g. changing colors, modifying axes, etc.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Coordinates&lt;/strong&gt;: the plane on which you’re plotting. Most plots use a Cartesian plane (&lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; coordinates), but less conventional planes are also possible (e.g. polar coordinates)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Faceting system&lt;/strong&gt;: how to plot subsets of data in different panels.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Theme&lt;/strong&gt;: other aesthetic minutia, such as fonts&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Our examples today will start from the basics and build outward, touching on all of these components of the grammar.&lt;/p&gt;
&lt;p&gt;Because &lt;code&gt;ggplot&lt;/code&gt; is rooted in an underlying model, it’s easy to create many different types of plots that share an underlying philosophy and syntax structure. Even if you have never made a particular sort of plot before, you know how you &lt;em&gt;would&lt;/em&gt; create it, because all plots come from the same building blocks. For instructional purposes, this is great because we will be making very interesting graphics in a very short amount of time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-ggplot2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Using &lt;code&gt;ggplot2&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Graphics from &lt;code&gt;ggplot2&lt;/code&gt; begin with the titular &lt;code&gt;ggplot()&lt;/code&gt; function. It works generically like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(dataset, aes(x = xvariable, y = yvariable))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where &lt;code&gt;dataset&lt;/code&gt; is the name of your dataset, &lt;code&gt;xvariable&lt;/code&gt; is the variable you want to plot on the horizontal axis, and &lt;code&gt;yvariable&lt;/code&gt; is the variable you want to plot on the vertical axis. Some details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All &lt;code&gt;ggplot&lt;/code&gt; graphics begin with a data frame. It must be tidy, because we must specify the columns that are mapped to plot aesthetics. As such, we can see why the other components of the Tidyverse work with ggplot—ggplot requires tidy data, and the rest of the Tidyverse is designed to make that easy.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;aes()&lt;/code&gt; function maps variables in your data to an aesthetic feature of the plot. We will use &lt;code&gt;aes()&lt;/code&gt; whenever we want to modify the plot’s according to &lt;em&gt;features of the dataset&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Every graphic will begin with a declaration of a dataset and a declaration of at least one aesthetic mapping.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;anes-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;ANES example&lt;/h2&gt;
&lt;p&gt;Let’s see this with real data.&lt;/p&gt;
&lt;p&gt;We will first recode two variables, “feeling thermometer” scores for the Democratic and Republican presidential candidates. These variables ask respondents to rate candidates on a 0-100 scale, where 100 is “most warm” and 0 is “most cold,” with 50 in the middle.&lt;/p&gt;
&lt;p&gt;If we consult the codebook for information on the “feeling thermometer,” We will notice that all values 97-100 are represented with the number 97 in the codebook, while 98 and 99 are special codes for “don’t know” and missing responses. I have no idea why this decision was made, but we have to work with it. We’ll want to keep only values 0–97 as valid, and recode everything else to &lt;code&gt;NA&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Once we do that, we will take the difference between the thermometer scores to create a &lt;em&gt;relative&lt;/em&gt; candidate thermometer rating. Positive values will indicate that an individual feels more warmly to the Republican candidate than to the Democratic candidate, so we will calculate this as the Republican rating minus the Democratic rating.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# learn some stuff about the feeling therm variables
summary(anes$VCF0424)  # democratic candidate&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&amp;#39;s 
##    0.00   40.00   60.00   58.74   85.00   99.00   27799&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(anes$VCF0426)  # republican candidate&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&amp;#39;s 
##    0.00   40.00   60.00   55.94   85.00   99.00   27799&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# bonus: try the skim() function in the &amp;#39;skimr&amp;#39; package
#   skim() is like summarize(), but it creates data frames

# now that we have a sense of the values of this variable, we&amp;#39;ll recode 
# keep 0-97 with case_when(), which implicitly converts all else to NA
# then calculate the difference

anes &amp;lt;- anes %&amp;gt;% 
  mutate(therm_demcand = case_when(VCF0424 &amp;gt; 0 &amp;amp; VCF0424 &amp;lt;= 97 ~ VCF0424),
         therm_gopcand = case_when(VCF0426 &amp;gt; 0 &amp;amp; VCF0426 &amp;lt;= 97 ~ VCF0426),
         reltherm_cand = therm_gopcand - therm_demcand)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll plot the Republican candidate thermometer over the 7-point index of party ID, which we recoded last week.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# data come from anes dataset
# x = party ID, y = candidate thermometer difference
ggplot(data = anes, aes(x = pid7, y = reltherm_cand))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This creates a blank plot, but if you think about the grammar, you will understand what happened. We mapped these variables to the &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; aesthetics, but we haven’t chosen how to present the data yet.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;geoms&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Geoms&lt;/h1&gt;
&lt;p&gt;It is important to note that we could visualize the data using a variety of geoms. It happens to be the cases that points make intuitive sense here.&lt;/p&gt;
&lt;p&gt;We layer on grammatical components to a plot using the plus sign &lt;code&gt;+&lt;/code&gt; after the &lt;code&gt;ggplot()&lt;/code&gt; function. Each thing that we layer on is done with a function. For geoms, there are a bunch of functions that share the prefix &lt;code&gt;geom_&lt;/code&gt;. Points are done with &lt;code&gt;geom_point()&lt;/code&gt;, lines with &lt;code&gt;geom_line()&lt;/code&gt;, and so on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# represent the data as points
ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 33520 rows containing missing values (geom_point).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What happened here?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We got a warning about missing data not being plotted. This is helpful, but I will suppress these for the remainder of the lesson.&lt;/li&gt;
&lt;li&gt;We have a lot of data printing overtop one another because we have so many observations at relatively few combinations of values (only 7 &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; values).&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;jittering-points&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Jittering points&lt;/h2&gt;
&lt;p&gt;To prevent data from printing overtop one another, it is often helpful to &lt;em&gt;jitter&lt;/em&gt; the points. Jittering is no more than adding a little bit of noise to the data. We also change the “shape” of the point. Learn more about the available point shapes &lt;a href=&#34;http://www.sthda.com/english/wiki/r-plot-pch-symbols-the-different-point-shapes-available-in-r&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# geom_jitter() plots jittered points
# we jitter the points IN THE PLOT, not in the underlying data
# we specify how much noise to add (width = )
# shape = 1 plots empty points
# alpha controls the opacity of the points

ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, shape = 1, alpha = 0.3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-lines&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fit lines&lt;/h2&gt;
&lt;p&gt;Let’s add a regression line with &lt;code&gt;geom_smooth()&lt;/code&gt;. “Smooth” refers to any model-fit curve we might impose on the plot. We specify that we want a linear curve with &lt;code&gt;method = lm&lt;/code&gt;. Adding a smooth also adds a confidence interval to the plot by default, but we can’t see this one because it is so narrow. I will also demonstrate how you can directly change colors (learn more about available colors &lt;a href=&#34;http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# geom_smooth() adds a model fit line
# method = &amp;quot;lm&amp;quot; specifies a Linear Model
#   By default, `geom_smooth()` fits a loess regression (method = &amp;quot;loess&amp;quot;) 
#   for large datasets, it will fit a polynomial model (method = &amp;quot;gam&amp;quot;)

ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, shape = 1, alpha = 0.3) +
  geom_smooth(method = &amp;quot;lm&amp;quot;, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You could plot your own custom regression using the &lt;code&gt;formula =&lt;/code&gt; argument.&lt;/p&gt;
&lt;p&gt;Here’s an important point. The regression line gets fit to the underlying data (the &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; aesthetics), so it does not get biased by the jittering. This is because jittering is only applied to the points &lt;em&gt;as they are printed in the plot&lt;/em&gt;; it does not jitter the underlying data directly. This is an example of an important philosophical point about plotting: if you need to perform any weird tricks to make the plot look good, you should strive to modify the &lt;em&gt;plot&lt;/em&gt; rather than the underlying data. Because ggplot is another “opinionated” package, it has many tools that make it easy to adhere to this philosophy.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;more-aesthetics-color-etc&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;More aesthetics (color, etc)&lt;/h1&gt;
&lt;p&gt;As we said above, aesthetic mappings apply features of the data to some aesthetic property in the plot. So far, we have mapped two variables to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; axes. We can also map colors, fills (interior colors), the sizes of points and lines sizes, line patterns (called “linetypes”), and so on.&lt;/p&gt;
&lt;p&gt;Instead of plotting one regression line, we’ll add separate regression lines for two different groups in the data. Let’s use gender, so first we need to recode it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# here is the raw gender variable in the data
count(anes, VCF0104)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   VCF0104     n
##     &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1       0   103
## 2       1 24862
## 3       2 30709&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 0 means NA/missing
# use case_when() to implicitly recode 0 as NA

anes &amp;lt;- anes %&amp;gt;%
  mutate(gender = case_when(VCF0104 == 1 ~ &amp;quot;Men&amp;quot;, 
                            VCF0104 == 2 ~ &amp;quot;Women&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have this variable cleaned up, we can map it to the color aesthetic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create different colored lines by gender
# that is, map color according to gender (from the data)
# any time we want to map from the data, we must use aes().

ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, shape = 1, alpha = 0.3) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Simple! These colors are also automatically added to a legend. (If you’re ever created a legend using base graphics, you know how awesome it is that you no longer have to struggle with that).&lt;/p&gt;
&lt;p&gt;When you map a variable to an aesthetic, ggplot automatically picks some default values. This happens for colors, fills (e.g. the color of the confidence interval shading), point sizes, line widths, and so on. You can change defaults using scales, which we’ll describe below.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scales&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Scales&lt;/h1&gt;
&lt;p&gt;When you use &lt;code&gt;aes()&lt;/code&gt;, ggplot picks some default mapping settings, such as axis scales, color defaults, and so on. Use &lt;code&gt;scale_&lt;/code&gt; functions to modify the defaults of any aesthetic mapping.&lt;/p&gt;
&lt;p&gt;First we’ll use it to control gender’s mapping by selecting our own colors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# aesthetic mapping makes default choices
# modify those default mapping choices using scale_aes_something() functions
# scale_color_brewer modifies color using color palettes
#   (can do your own googling about color palettes)

ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, shape = 1, alpha = 0.3, size = 0.25) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender)) +
  scale_color_brewer(palette = &amp;quot;Set2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Scale functions follow a format of &lt;code&gt;scale_aesthetic_xyz()&lt;/code&gt;, where &lt;code&gt;aesthetic&lt;/code&gt; is color, size, and so on. You can control color using color palettes with &lt;code&gt;scale_color_brewer()&lt;/code&gt;. If you want to specify colors manually, use &lt;code&gt;scale_color_manual()&lt;/code&gt; with the &lt;code&gt;values =&lt;/code&gt; argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# manual specification of color: scale_color_manual()
# one color for each category from the aesthetic mapping
# this will fail if you don&amp;#39;t supply the correct number of colors

ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, shape = 1, alpha = 0.3, size = 0.25,) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here we also map the confidence interval’s fill color and the linetype of the smooth using gender.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# modifying more mappings
# such as fill color, linetype
# (Again, pardon the ugliness of the graphic 
#  as we demonstrate general ggplot functionality)


ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Because &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are also aesthetics, we can also modify them using &lt;code&gt;scale&lt;/code&gt; functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# axes are aesthetics, so you also modify axes with scale functions
#   breaks are where ticks are drawn
#   `labels =` can be used to specify the label for each break
#   minor_breaks can be specified separately from breaks

ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I can also add text labels to the tick positions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Specify axis labels for each break
# The `\n` character inserts a line break.

ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7, 
                     labels = c(&amp;quot;Strong\nDem&amp;quot;, &amp;quot;Weak\nDem&amp;quot;, 
                                &amp;quot;Lean\nDem&amp;quot;, &amp;quot;Independent&amp;quot;, &amp;quot;Lean\nRep&amp;quot;, 
                                &amp;quot;Weak\nRep&amp;quot;, &amp;quot;Strong\nRep&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;labeling-aesthetics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Labeling aesthetics&lt;/h2&gt;
&lt;p&gt;Related to aesthetics and scales is the labels we give these aesthetics. Notice that when we map variables to &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, axis titles are created, and as we map variables to color, fill, and so on, a legend title was created. The variable names that get printed can be modified with the &lt;code&gt;labs()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Specify aesthetic labels using labs()
# good for axes, legend titles, also plot title (title = ), etc.

ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7, 
                     labels = c(&amp;quot;Strong\nDem&amp;quot;, &amp;quot;Weak\nDem&amp;quot;, &amp;quot;Lean\nDem&amp;quot;, &amp;quot;Independent&amp;quot;, &amp;quot;Lean\nRep&amp;quot;, &amp;quot;Weak\nRep&amp;quot;, &amp;quot;Strong\nRep&amp;quot;)) +
  labs(x = &amp;quot;Party ID Index&amp;quot;, y = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
       color = &amp;quot;Gender&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;labs()&lt;/code&gt; function only changes the names that you specify. To fix this dirty legend, I should specify the name for color, fill, and linetype all as &lt;code&gt;&amp;quot;Gender&amp;quot;&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# specify all labels
ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7, 
                     labels = c(&amp;quot;Strong\nDem&amp;quot;, &amp;quot;Weak\nDem&amp;quot;, &amp;quot;Lean\nDem&amp;quot;, &amp;quot;Independent&amp;quot;, &amp;quot;Lean\nRep&amp;quot;, &amp;quot;Weak\nRep&amp;quot;, &amp;quot;Strong\nRep&amp;quot;)) +
  labs(x = &amp;quot;Party ID Index&amp;quot;, y = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
       color = &amp;quot;Gender&amp;quot;, fill = &amp;quot;Gender&amp;quot;, linetype = &amp;quot;Gender&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I could also remove labels by specifying them as &lt;code&gt;NULL&lt;/code&gt;. In this case, we’re pretty sure what men and women signify, so maybe including the “Gender” label is redundant. So we can suppress the legend title.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# removing labels using NULL
ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7, 
                     labels = c(&amp;quot;Strong\nDem&amp;quot;, &amp;quot;Weak\nDem&amp;quot;, &amp;quot;Lean\nDem&amp;quot;, &amp;quot;Independent&amp;quot;, &amp;quot;Lean\nRep&amp;quot;, &amp;quot;Weak\nRep&amp;quot;, &amp;quot;Strong\nRep&amp;quot;)) +
  labs(x = &amp;quot;Party ID Index&amp;quot;, y = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
       color = NULL, fill = NULL, linetype = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;NULL&lt;/code&gt; isn’t the same as &lt;code&gt;NA&lt;/code&gt;. We use &lt;code&gt;NA&lt;/code&gt; for missing data—there should be data here, but we don’t know what it is. We use &lt;code&gt;NULL&lt;/code&gt; to mean “nothing.”&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;coordinates&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Coordinates&lt;/h1&gt;
&lt;p&gt;Coordinates are not very complicated. Most of the time you will use a Cartesian grid, so you’ll probably do one of two things.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set the axis limits&lt;/li&gt;
&lt;li&gt;Flip the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; dimensions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, set the axis limits. This is an unrealistic application just to demonstrate the functionality.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set axis limits using the coordinate system
# coord_cartesian(xlim = , ylim =)

ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7, 
                     labels = c(&amp;quot;Strong\nDem&amp;quot;, &amp;quot;Weak\nDem&amp;quot;, &amp;quot;Lean\nDem&amp;quot;, &amp;quot;Independent&amp;quot;, &amp;quot;Lean\nRep&amp;quot;, &amp;quot;Weak\nRep&amp;quot;, &amp;quot;Strong\nRep&amp;quot;)) +
  labs(x = &amp;quot;Party ID Index&amp;quot;, y = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
       color = NULL, fill = NULL, linetype = NULL) +
  coord_cartesian(xlim = c(0, 8), ylim = c(-125, 125))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Remember, because the underlying values in the &lt;code&gt;x&lt;/code&gt; aesthetic are 1 to 7, setting the &lt;code&gt;xlim&lt;/code&gt; to 0 through 8 will pad each side by one unit. We use the &lt;code&gt;c()&lt;/code&gt; function to pass a two-element vector of limits (minimum and maximum).&lt;/p&gt;
&lt;p&gt;Second is flipping &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, which is handy for dot plots and coefficient plots (which we’ll see next week). This is going to look strange in this example, of course, but again we’re just demonstrating the functionality.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# invert the coordinate system with coord_flip()
# can specify changes to the coordinate limits when you do this as well

ggplot(data = anes, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7, 
                     labels = c(&amp;quot;Strong\nDem&amp;quot;, &amp;quot;Weak\nDem&amp;quot;, &amp;quot;Lean\nDem&amp;quot;, &amp;quot;Independent&amp;quot;, &amp;quot;Lean\nRep&amp;quot;, &amp;quot;Weak\nRep&amp;quot;, &amp;quot;Strong\nRep&amp;quot;)) +
  labs(x = &amp;quot;Party ID Index&amp;quot;, y = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
       color = NULL, fill = NULL, linetype = NULL) +
  coord_flip(xlim = c(0.5, 7.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As above with jittering and smoothing, the &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; aesthetics themselves have not changed, only the way they are &lt;em&gt;displayed&lt;/em&gt; in the graphic. The &lt;code&gt;scale_x_continuous()&lt;/code&gt; function, therefore, still modifies the party ID variable scale even though it’s now the vertical axis. That’s because &lt;code&gt;scale_x_continuous()&lt;/code&gt; modifies the &lt;em&gt;x aesthetic&lt;/em&gt;, not the &lt;em&gt;horizontal axis&lt;/em&gt; per se. This same intuition works when we specify &lt;code&gt;xlim&lt;/code&gt; inside the &lt;code&gt;coord_flip()&lt;/code&gt; function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;faceting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Faceting&lt;/h1&gt;
&lt;p&gt;Faceting is relatively simple. We use it to plot subsets of the data in different panels. There are two ways to do this.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;facet_wrap()&lt;/code&gt; creates horizontal panels that will “wrap” to the next line if we run out of space.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;facet_grid()&lt;/code&gt; creates a grid according to variables that you specify as the rows and columns.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both of these functions require us to use tildes &lt;code&gt;~&lt;/code&gt;, so pay attention.&lt;/p&gt;
&lt;p&gt;First: &lt;code&gt;facet_wrap&lt;/code&gt; using the election cycle variable (on a subset of presidential year data)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# save only recent presidential years
prez &amp;lt;- anes %&amp;gt;%
  filter(cycle %% 4 == 0) %&amp;gt;%
  filter(cycle &amp;gt;= 1992) 

# wrap panels using facet_wrap( ~ cycle)
# the tilde is necessary

ggplot(prez, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7) +
  labs(x = &amp;quot;Party ID Index&amp;quot;, 
       y = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
       color = NULL, fill = NULL, linetype = NULL) +
  facet_wrap(~ cycle)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Next: &lt;code&gt;facet_grid()&lt;/code&gt;, which requires us to specify row and column variables. We’ll use election cycle and gender. This will make the legend redundant, but just ignore that for now.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(prez, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7) +
  labs(x = &amp;quot;Party ID Index&amp;quot;, 
       y = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
       color = NULL, fill = NULL, linetype = NULL) +
  facet_grid(cycle ~ gender)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Use a period in the &lt;code&gt;facet_grid&lt;/code&gt; function to suppress rows or columns. Observe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# suppress rows

ggplot(prez, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7) +
  labs(x = &amp;quot;Party ID Index&amp;quot;, 
       y = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
       color = NULL, fill = NULL, linetype = NULL) +
  facet_grid(. ~ gender)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# suppress columns

ggplot(prez, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7) +
  labs(x = &amp;quot;Party ID Index&amp;quot;, 
       y = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
       color = NULL, fill = NULL, linetype = NULL) +
  facet_grid(gender ~ .)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-26-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;themes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Themes&lt;/h1&gt;
&lt;p&gt;Themes control ancillary aesthetic components of the plot. There are several preloaded themes that you can learn about &lt;a href=&#34;http://ggplot2.tidyverse.org/reference/ggtheme.html&#34;&gt;here&lt;/a&gt;, and you can learn about &lt;a href=&#34;https://cran.r-project.org/web/packages/ggthemes/vignettes/ggthemes.html&#34;&gt;other ggplot theme packages online&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We’ll use &lt;code&gt;theme_bw()&lt;/code&gt;, in case you (like me) think this gray background is kinda nasty.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# theme_bw()

ggplot(prez, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7) +
  labs(x = &amp;quot;Party ID Index&amp;quot;, 
       y = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
       color = NULL, fill = NULL, linetype = NULL) +
  facet_wrap(~ cycle) +
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There is also a &lt;code&gt;theme()&lt;/code&gt; function, which allows you to change individual details of the theme without changing the entire theme. Here we will suppress the “minor” grid lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(prez, aes(x = pid7, y = reltherm_cand)) +
  geom_jitter(width = 0.2, 
              shape = 1, alpha = 0.3, size = 0.25, 
              color = &amp;quot;slategray&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;,
              aes(color = gender, linetype = gender, fill = gender)) +
  scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) + 
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;maroon&amp;quot;)) +
  scale_linetype_manual(values = c(&amp;quot;dotted&amp;quot;, &amp;quot;solid&amp;quot;)) +
  scale_x_continuous(breaks = 1:7) +
  labs(x = &amp;quot;Party ID Index&amp;quot;, 
       y = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
       color = NULL, fill = NULL, linetype = NULL) +
  facet_wrap(~ cycle) +
  theme_bw() +
  theme(panel.grid.minor = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;finishing-touches-and-saving-a-graphic&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Finishing touches and saving a graphic&lt;/h1&gt;
&lt;p&gt;This looks like an okay graphic now, and it didn’t take much code at all!&lt;/p&gt;
&lt;p&gt;Saving this graphic is easy with the &lt;code&gt;ggsave&lt;/code&gt; function. You generally want to save graphic as a “vector” image type in order to scale (that is, increase the size of) a graphic without any pixelation. PDF is usually good for papers and presentations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# generally want to save it into your paper&amp;#39;s dedicated folder
#   then inside the graphics subfolder

# set height and width (usually requires some trial and error)
ggsave(&amp;quot;paper/graphics/my-plot.PDF&amp;quot;, width = 7, height = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;another-example-party-id-of-men-and-women-over-time&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Another example: party ID of men and women over time&lt;/h1&gt;
&lt;p&gt;Let’s take these tools for a spin. Let’s re-create this graphic from an old paper from a former professor of mine.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/811/kp-fig-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We will need to set up a dataset that has all of the required components. Let’s think of what we need to have in place.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;x&lt;/code&gt; is election cycle, &lt;code&gt;y&lt;/code&gt; is the percentage of men and women identifying as Democrat and Republican (aesthetics). We will need to calculate the &lt;code&gt;y&lt;/code&gt; variable.&lt;/li&gt;
&lt;li&gt;We have separate point styles based on party (aesthetic)&lt;/li&gt;
&lt;li&gt;We have separate panels for men and women (faceting)&lt;/li&gt;
&lt;li&gt;the &lt;code&gt;x&lt;/code&gt; axis scale has been modified, and &lt;code&gt;y&lt;/code&gt; axis scale probably needs to be coerced to go from 0 to 100 (scales)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s add some extra flair:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;calculate confidence intervals for each trend and plot as a “ribbon,” which is a shaded region.&lt;/li&gt;
&lt;li&gt;Unlike before, let’s make this as pretty as we can.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;data-cleaning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data cleaning&lt;/h2&gt;
&lt;p&gt;First, we have to create the data.&lt;/p&gt;
&lt;p&gt;To get the confidence intervals, we’ll use a user-defined confidence interval function that can handle survey weights. We’ll discuss custom functions in the final lesson; for now, just know that this function calculates confidence intervals for proportions based on the number of “successes” and the number of observations. (Side note: you don’t need to calculate your own confidence intervals most of the time—this is a special case because survey weights create non-whole-numbers of successes and observations.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Confidence intervals for proportions
# based on the normal approximation to the binomial

prop_ci &amp;lt;- function(successes, n, level = 0.05) {

  # get pt estimates and standard error
  p &amp;lt;- successes / n
  q &amp;lt;- 1 - p
  SE &amp;lt;- sqrt( (p * q) / n )

  # upper and lower bound
  lower &amp;lt;- p - qnorm(1 - (level / 2) ) * SE
  upper &amp;lt;- p + qnorm(0.975) * SE

  # return data frame
  return(data.frame(estimate = p, lower, upper))

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get the DV, we’ll need the weight variable and to collapse the party ID variable. (We want to keep Independents to calculate proportions, but we’ll drop them before plotting.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# copy weight variable and
# collapse the party variable into Dems and Reps
#   code &amp;quot;leaners&amp;quot; as partisans
anes &amp;lt;- anes %&amp;gt;% 
  mutate(wt = VCF0009z,
         party = case_when(pid7 %in% 1:3 ~ &amp;quot;Dem&amp;quot;, 
                           pid7 == 4 ~ &amp;quot;Ind&amp;quot;, 
                           pid7 %in% 5:7 ~ &amp;quot;Rep&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will need to find the proportion of men and women in each party ID category, in each cycle. We’ll do this with a pipe chain:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;find the number of men and women in each party ID category in each cycle&lt;/li&gt;
&lt;li&gt;get proportions by dividing by the total number of men and women in each cycle&lt;/li&gt;
&lt;li&gt;use the number of successes and the “denominator” from above to find upper and lower bounds on the confidence interval&lt;/li&gt;
&lt;li&gt;trim extraneous stuff from the data&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# You may want to run this chain line by line 
# to see what each step does
# we want to plot Women left of Men, so we&amp;#39;ll reorder the gender variable

pid_gendergap &amp;lt;- anes %&amp;gt;%
  select(cycle, gender, party, wt) %&amp;gt;%  # trim unnecessary stuff
  group_by(gender, cycle, party) %&amp;gt;%    # calc weighted n in each PID
  count(wt = wt) %&amp;gt;%
  rename(x = n) %&amp;gt;%                     # less ambiguous name
  group_by(gender, cycle) %&amp;gt;%           # &amp;quot;denominator&amp;quot; for gender x cycle
  mutate(n = sum(x)) %&amp;gt;% 
  ungroup() %&amp;gt;%
  # proportions and CIs
  mutate(prop = prop_ci(successes = x, n = n)$estimate,
         lower = prop_ci(successes = x, n = n)$lower,
         upper = prop_ci(successes = x, n = n)$upper) %&amp;gt;%
  # keep only Ds and Rs (drop NA and Ind) 
  # keep only presidential years since 1952 reorder variables
  filter(party %in% c(&amp;quot;Dem&amp;quot;, &amp;quot;Rep&amp;quot;)) %&amp;gt;%     
  filter( (cycle &amp;gt;= 1952) &amp;amp; ((cycle %% 4) == 0) ) %&amp;gt;% 
  select(cycle, gender, party, prop:upper) %&amp;gt;% 
  # reorder gender as a factor
  mutate(gender = fct_relevel(as.factor(gender), &amp;quot;Women&amp;quot;, &amp;quot;Men&amp;quot;)) %&amp;gt;% 
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 64 x 6
##    cycle gender party  prop lower upper
##    &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1  1952 Men    Dem   0.571 0.537 0.605
##  2  1952 Men    Rep   0.324 0.292 0.356
##  3  1956 Men    Dem   0.536 0.501 0.571
##  4  1956 Men    Rep   0.343 0.310 0.376
##  5  1960 Men    Dem   0.521 0.488 0.554
##  6  1960 Men    Rep   0.352 0.320 0.383
##  7  1964 Men    Dem   0.602 0.566 0.638
##  8  1964 Men    Rep   0.297 0.264 0.331
##  9  1968 Men    Dem   0.532 0.495 0.570
## 10  1968 Men    Rep   0.352 0.317 0.388
## # ... with 54 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’ll use this dataset to build the plot.&lt;/p&gt;
&lt;p&gt;We know we need separate panels for men and women, separate trends and linetypes for party.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# use `group =` to plot separate line trends
# try removing `group =` from the plot to see why we include it

ggplot(pid_gendergap, aes(x = cycle, y = prop)) +
  facet_grid(. ~ gender) +
  geom_line(aes(group = party)) +
  geom_point(aes(shape = party))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-34-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s modify some scales. We’ll want to specify the point styles and change the axis scales.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;by default, fill any empty point with while fill (in &lt;code&gt;grom_point()&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;set the coordinates a little wider (&lt;code&gt;coord_cartesian()&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;manually specify point shapes (&lt;code&gt;scale_shape_manual()&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;modify the ticks on x and y (&lt;code&gt;scale_x_continuous()&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(pid_gendergap, aes(x = cycle, y = prop)) +
  facet_grid(. ~ gender) +
  geom_line(aes(group = party)) +
  geom_point(aes(shape = party), fill = &amp;quot;white&amp;quot;) +
  coord_cartesian(ylim = c(0, 1), xlim = c(1948, 2014),
                  expand = FALSE) +
  scale_shape_manual(values = c(17, 22)) +
  scale_y_continuous(breaks = seq(0, 1, .1)) +
  scale_x_continuous(breaks = seq(1952, 2012, 12))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-35-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The X axis looks funky now. Let’s do some theme modifications to make the text diagonal and suppress busy grid lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(pid_gendergap, aes(x = cycle, y = prop)) +
  facet_grid(. ~ gender) +
  geom_line(aes(group = party)) +
  geom_point(aes(shape = party), fill = &amp;quot;white&amp;quot;) +
  coord_cartesian(ylim = c(0, 1), xlim = c(1948, 2016),
                  expand = FALSE) +
  scale_shape_manual(values = c(17, 22)) +
  scale_y_continuous(breaks = seq(0, 1, .1)) +
  scale_x_continuous(breaks = seq(1952, 2012, 12)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.8),
        panel.grid.minor = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-36-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s suppress the legend created by &lt;code&gt;geom_point()&lt;/code&gt; and add text labels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(pid_gendergap, aes(x = cycle, y = prop)) +
  facet_grid(. ~ gender) +
  geom_line(aes(group = party)) +
  geom_point(aes(shape = party), fill = &amp;quot;white&amp;quot;,
             show.legend = FALSE) +
  coord_cartesian(ylim = c(0, 1), xlim = c(1948, 2016), 
                  expand = FALSE) +
  scale_shape_manual(values = c(17, 22)) +
  scale_y_continuous(breaks = seq(0, 1, .1)) +
  scale_x_continuous(breaks = seq(1952, 2012, 12)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.8),
        panel.grid.minor = element_blank()) +
  annotate(&amp;quot;text&amp;quot;, x = 1984, y = 0.65, label = &amp;quot;Democrats&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x = 1984, y = 0.25, label = &amp;quot;Republicans&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-37-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we want to add confidence intervals as ribbons, we’ll use &lt;code&gt;geom_ribbon()&lt;/code&gt;. It inherits the &lt;code&gt;x&lt;/code&gt; aesthetic from the plot, but we need to specify extra &lt;code&gt;ymin&lt;/code&gt; and &lt;code&gt;ymax&lt;/code&gt; aesthetics to draw the upper and lower bounds of the “polygon” that gets drawn. Again, suppress the legend, and for good measure, let’s modify the fill color.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# I always prefer to add ribbons below points and lines
# we want to reduce the ribbon opacity
ggplot(pid_gendergap, aes(x = cycle, y = prop)) +
  facet_grid(. ~ gender) +
  geom_ribbon(aes(ymin = lower, ymax = upper,
                  fill = party), 
              alpha = 0.4, show.legend = FALSE) +
  geom_line(aes(group = party)) +
  geom_point(aes(shape = party), fill = &amp;quot;white&amp;quot;, 
             show.legend = FALSE) +
  coord_cartesian(ylim = c(0, 1), xlim = c(1948, 2016), 
                  expand = FALSE) +
  scale_shape_manual(values = c(17, 22)) +
  scale_y_continuous(breaks = seq(0, 1, .1)) +
  scale_x_continuous(breaks = seq(1952, 2012, 12)) +
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;orangered&amp;quot;)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.8),
        panel.grid.minor = element_blank()) +
  annotate(&amp;quot;text&amp;quot;, x = 1984, y = 0.65, label = &amp;quot;Democrats&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x = 1984, y = 0.25, label = &amp;quot;Republicans&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-38-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We’ll want to convert the axis to percentages. We can do this in the plot using the &lt;code&gt;scale_y_continuous()&lt;/code&gt; function and applying a function to the labels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# check the labels = argument in scale_y_continuous
# it uses the percent() function from the &amp;#39;scales&amp;#39; package
#   scales is automatically installed with ggplot2

ggplot(pid_gendergap, aes(x = cycle, y = prop)) +
  facet_grid(. ~ gender) +
  geom_ribbon(aes(ymin = lower, ymax = upper,
                  fill = party), 
              alpha = 0.4, show.legend = FALSE) +
  geom_line(aes(group = party)) +
  geom_point(aes(shape = party), fill = &amp;quot;white&amp;quot;, 
             show.legend = FALSE) +
  coord_cartesian(ylim = c(0, 1), xlim = c(1948, 2016), 
                  expand = FALSE) +
  scale_shape_manual(values = c(17, 22)) +
  scale_y_continuous(breaks = seq(0, 1, .1), 
                     labels = scales::percent) +
  scale_x_continuous(breaks = seq(1952, 2012, 12)) +
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;orangered&amp;quot;)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.8),
        panel.grid.minor = element_blank()) +
  annotate(&amp;quot;text&amp;quot;, x = 1984, y = 0.65, label = &amp;quot;Democrats&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x = 1984, y = 0.25, label = &amp;quot;Republicans&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-39-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we’ll need to change the labels so they fit the scale transformation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(pid_gendergap, aes(x = cycle, y = prop)) +
  facet_grid(. ~ gender) +
  geom_ribbon(aes(ymin = lower, ymax = upper,
                  fill = party), 
              alpha = 0.4, show.legend = FALSE) +
  geom_line(aes(group = party)) +
  geom_point(aes(shape = party), fill = &amp;quot;white&amp;quot;, 
             show.legend = FALSE) +
  coord_cartesian(ylim = c(0, 1), xlim = c(1948, 2016), 
                  expand = FALSE) +
  scale_shape_manual(values = c(17, 22)) +
  scale_y_continuous(breaks = seq(0, 1, .1), 
                     labels = scales::percent) +
  scale_x_continuous(breaks = seq(1952, 2012, 12)) +
  scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;orangered&amp;quot;)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.8),
        panel.grid.minor = element_blank()) +
  annotate(&amp;quot;text&amp;quot;, x = 1984, y = 0.65, label = &amp;quot;Democrats&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x = 1984, y = 0.25, label = &amp;quot;Republicans&amp;quot;) +
  labs(x = NULL, y = &amp;quot;Percent (including leaners)&amp;quot;,
       title = &amp;quot;Party Identification of Men and Women&amp;quot;,
       caption = &amp;quot;Source: NES Surveys of the indicated years&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-40-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;other-graphics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Other graphics&lt;/h1&gt;
&lt;p&gt;There are plenty of other geoms that use slightly different aesthetics. Let’s just breeze through some now.&lt;/p&gt;
&lt;p&gt;As we do this, let’s use &lt;code&gt;theme_bw()&lt;/code&gt; as the default. Here’s a trick to set the default ggplot theme.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_set(theme_bw())&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;histograms-and-density-plots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Histograms and density plots&lt;/h2&gt;
&lt;p&gt;Histograms and density plots, because they only show the distribution of one variable, only need one axis aesthetic (&lt;code&gt;x&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# subset the anes data
# pipe into the ggplot function 
#   (can do that! but not usually recommended)

anes %&amp;gt;%
  filter(!is.na(party)) %&amp;gt;% 
  ggplot(aes(x = reltherm_cand)) +
    geom_histogram(aes(color = party)) +
    labs(x = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
         y = &amp;quot;Frequency&amp;quot;,
         color = &amp;quot;Partisanship&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 31866 rows containing non-finite values (stat_bin).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-42-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Histogram bars are stacked by default, which is weird. Let’s make them dodge each other.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# make histogram bars non-stacked (&amp;quot;dodge&amp;quot;)

anes %&amp;gt;%
  filter(!is.na(party)) %&amp;gt;% 
  ggplot(aes(x = reltherm_cand)) +
    geom_histogram(aes(color = party,
                       fill = party),
                   alpha = 0.5,
                   position = &amp;quot;dodge&amp;quot;) +
    scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;gray20&amp;quot;, &amp;quot;maroon&amp;quot;)) +
    scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;gray20&amp;quot;, &amp;quot;maroon&amp;quot;)) +
    labs(x = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
         y = &amp;quot;Frequency&amp;quot;,
         color = &amp;quot;Partisanship&amp;quot;,
         fill = &amp;quot;Partisanship&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 31866 rows containing non-finite values (stat_bin).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-43-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You can also do kernel density estimates (which allow you set the kernel bandwidth):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# density plot instead of histogram

anes %&amp;gt;%
  filter(!is.na(party)) %&amp;gt;% 
  ggplot(aes(x = reltherm_cand)) +
    geom_density(aes(color = party, fill = party),
                   alpha = 0.5,
                   bw = 7) +
    scale_color_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;gray20&amp;quot;, &amp;quot;maroon&amp;quot;)) +
    scale_fill_manual(values = c(&amp;quot;dodgerblue&amp;quot;, &amp;quot;gray20&amp;quot;, &amp;quot;maroon&amp;quot;)) +
    labs(x = &amp;quot;Relative Candidate Thermometer Score&amp;quot;,
         y = &amp;quot;Density&amp;quot;,
         color = &amp;quot;Partisanship&amp;quot;,
         fill = &amp;quot;Partisanship&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Removed 31866 rows containing non-finite values (stat_density).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-44-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bar-graphs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bar graphs&lt;/h2&gt;
&lt;p&gt;It’s a personal preference of mine that I think just about anything that you can show with a bar graph would be better with a dot plot. I tend to think that bar graphs are awkward and misused (e.g. for experimental treatment effects). In my head, bars should be for counts or other things where zero is a hard lower bound (such as proportions).&lt;/p&gt;
&lt;p&gt;Bah! Anyway, here’s how you do them.&lt;/p&gt;
&lt;p&gt;Let’s make some data of the Democratic share of the two-party vote choice for each partisanship category.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# dummy variable for Dem vote (0 = Rep vote, else NA)
anes &amp;lt;- anes %&amp;gt;%
  mutate(vote = VCF0706,
         vote = case_when(vote == 1 ~ &amp;quot;Democratic Candidate&amp;quot;,
                          vote == 2 ~ &amp;quot;Republican Candidate&amp;quot;))

# calculate averages for each party ID
# presidential years since 2000
mean_votes &amp;lt;- anes %&amp;gt;%
  filter(cycle &amp;gt;= 2000 &amp;amp; (cycle %% 4) == 0) %&amp;gt;%
  filter(!is.na(pid7)) %&amp;gt;% 
  group_by(cycle, pid7, vote) %&amp;gt;%  # Numerator
  count(wt = wt) %&amp;gt;%
  filter(!is.na(vote)) %&amp;gt;%
  rename(x = n) %&amp;gt;%
  group_by(pid7, cycle) %&amp;gt;%     # Denominator
  mutate(n = sum(x, na.rm = TRUE),
         prop = x / n) %&amp;gt;%
  filter(vote == &amp;quot;Democratic Candidate&amp;quot;) %&amp;gt;% 
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 28 x 6
## # Groups:   pid7, cycle [28]
##    cycle  pid7 vote                      x     n   prop
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                 &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1  2000     1 Democratic Candidate 226.   233.  0.970 
##  2  2000     2 Democratic Candidate 139.   163.  0.855 
##  3  2000     3 Democratic Candidate 105.   135.  0.777 
##  4  2000     4 Democratic Candidate  32.8   73.5 0.446 
##  5  2000     5 Democratic Candidate  19.5  136.  0.144 
##  6  2000     6 Democratic Candidate  20.8  128.  0.163 
##  7  2000     7 Democratic Candidate   3.20 181.  0.0177
##  8  2004     1 Democratic Candidate 137.   140.  0.975 
##  9  2004     2 Democratic Candidate  94.1  111.  0.851 
## 10  2004     3 Democratic Candidate 104.   119.  0.878 
## # ... with 18 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then plot these averages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# geom_col to create a column as tall as the (x, y) point
ggplot(mean_votes, aes(x = pid7, y = prop)) +
  geom_col(fill = &amp;quot;gray50&amp;quot;) +
  facet_wrap(~ cycle) +
  scale_x_continuous(breaks = 1:7,
                     labels = c(&amp;quot;Strong\nDem&amp;quot;, &amp;quot;Weak\nDem&amp;quot;, &amp;quot;Lean\nDem&amp;quot;, &amp;quot;Ind&amp;quot;, &amp;quot;Lean\nRep&amp;quot;, &amp;quot;Weak\nRep&amp;quot;, &amp;quot;Strong\nRep&amp;quot;)) +
  labs(x = &amp;quot;Party ID&amp;quot;,
       y = &amp;quot;Democratic Share of Two-Party Vote&amp;quot;) +
  theme_bw() +
  theme(panel.grid.minor = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-46-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here is the same plot as a dot plot, also changing the scales.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# dots instead of bars
ggplot(mean_votes, aes(x = pid7, y = prop)) +
  geom_point() +
  facet_wrap(~ cycle) +
  scale_x_continuous(breaks = 1:7,
                     labels = c(&amp;quot;Strong\nDem&amp;quot;, &amp;quot;Weak\nDem&amp;quot;, &amp;quot;Lean\nDem&amp;quot;, &amp;quot;Ind&amp;quot;, &amp;quot;Lean\nRep&amp;quot;, &amp;quot;Weak\nRep&amp;quot;, &amp;quot;Strong\nRep&amp;quot;)) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = &amp;quot;Party ID&amp;quot;,
       y = &amp;quot;Democratic Share of Two-Party Vote&amp;quot;) +
  theme_bw() +
  theme(panel.grid.minor = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-47-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And you can often rotate dot plots so that their labels have more space to print out.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# rotate the dot plot for axis readability
# this should be used carefully...
# not all plots are easy to read like this
ggplot(mean_votes, aes(x = pid7, y = prop)) +
  geom_point() +
  facet_wrap(~ cycle) +
  scale_x_continuous(breaks = 1:7,
                     labels = c(&amp;quot;Strong Democrat&amp;quot;, &amp;quot;Weak Democrat&amp;quot;, &amp;quot;Lean Democrat&amp;quot;, &amp;quot;Independent&amp;quot;, &amp;quot;Lean Republican&amp;quot;, &amp;quot;Weak Republican&amp;quot;, &amp;quot;Strong Republican&amp;quot;)) +
  scale_y_continuous(breaks = seq(0, 1, .2),
                     labels = scales::percent) +
  labs(x = &amp;quot;Party Identification&amp;quot;,
       y = &amp;quot;Democratic Share of Two-Party Vote&amp;quot;) +
  theme_bw() +
  theme(panel.grid.minor = element_blank()) +
  coord_flip()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-48-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are some other things you can do with geoms. One thing you can do for dot plots is use &lt;code&gt;geom_pointrange&lt;/code&gt;, which adds a point and an error bar. Like &lt;code&gt;geom_ribbon&lt;/code&gt;, it takes a &lt;code&gt;ymin&lt;/code&gt; and &lt;code&gt;ymax&lt;/code&gt; aesthetic. This makes it good for point estimates and confidence intervals. In this case though, we’ll use it in a slightly hacky way to help us trace which point goes with which category, making it a little easier to read the plot. Notice how I set the min and max aesthetics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set ymin = 0, ymax = prop. 
# the error bar goes from 0 to the point
ggplot(mean_votes, aes(x = pid7, y = prop)) +
  geom_pointrange(aes(ymin = 0, ymax = prop),
                  linetype = &amp;quot;dotted&amp;quot;) +
  facet_wrap(~ cycle) +
  scale_x_continuous(breaks = 1:7,
                     labels = c(&amp;quot;Strong Democrat&amp;quot;, &amp;quot;Weak Democrat&amp;quot;, &amp;quot;Lean Democrat&amp;quot;, &amp;quot;Independent&amp;quot;, &amp;quot;Lean Republican&amp;quot;, &amp;quot;Weak Republican&amp;quot;, &amp;quot;Strong Republican&amp;quot;)) +
  scale_y_continuous(breaks = seq(0, 1, .2),
                     labels = scales::percent) +
  labs(x = &amp;quot;Party Identification&amp;quot;,
       y = &amp;quot;Democratic Share of Two-Party Vote&amp;quot;) +
  theme_bw() +
  theme(panel.grid.minor = element_blank()) +
  coord_flip()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-49-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;categorical-variables-strings-and-factors&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Categorical variables (strings and factors)&lt;/h1&gt;
&lt;p&gt;If you plot a categorical variable on one of the axes, &lt;code&gt;ggplot&lt;/code&gt; will automatically interpret it and plot categories side-by-side. We’ll demonstrate this with a toy example.&lt;/p&gt;
&lt;p&gt;One potential problem, though, is that &lt;code&gt;ggplot&lt;/code&gt; will order categorical variables alphabetically or, if the variable is already an ordered factor, will interpret the factor order out of the metadata about the levels.&lt;/p&gt;
&lt;p&gt;Here we show what happens when we plot a string variable that can be ordered alphabetically:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# x and y: continuous variables
# s: string variable
# f: factor variable with weird order
d &amp;lt;- data_frame(x = rnorm(100, 0, 1),
                y = 4 + (2 * x) + rnorm(100, 0, 1),
                s = sample(c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;), 100, replace = TRUE),
                f = factor(s, levels = c(&amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;)))

# plot y as a function of s (jittering the points)
ggplot(d, aes(x = s, y = y)) +
  geom_jitter(width = 0.15) +
  labs(x = &amp;quot;String&amp;quot;, y = &amp;quot;Continuous Y&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-50-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;…and if we plot from a factor that already has ordered levels…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# plot y as f(f), jittered points
# notice weird order. This comes from the underlying data
ggplot(d, aes(x = f, y = y)) +
  geom_jitter(width = 0.15) +
  labs(x = &amp;quot;Ordered Factor&amp;quot;, y = &amp;quot;Continuous Y&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-51-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;…or we wanted to assign colors using an ordered factor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# same situation here
ggplot(d, aes(x = x, y = y)) +
  geom_point(aes(color = f)) +
  labs(x = &amp;quot;Continuous X&amp;quot;, 
       y = &amp;quot;Continuous Y&amp;quot;,
       color = &amp;quot;Ordered Factor&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-52-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To reorder these categories, I recommend using tools in the &lt;code&gt;forcats&lt;/code&gt; package, which, conveniently, is part of &lt;code&gt;tidyverse&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;fct_relevel()&lt;/code&gt;: take a factor variable and reorder the levels. Any level not listed during reordering is given the same precedence as the original variable&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fct_rev()&lt;/code&gt;: reverse the order of a factor’s levels&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fct_recode()&lt;/code&gt;: change the levels (text labels) of a factor&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is an example where we take the &lt;code&gt;f&lt;/code&gt; variable, a factor with ordered levels, and rearrange the order of the levels so that they appear in the legend with the proper order. This is called “releveling” (changing the order of levels), as opposed to “recoding” (changing the labels themselves).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# start with the d object
# mutate
# create fixed_f, which is f but with levels of specified order
fixed_d &amp;lt;- d %&amp;gt;%
  mutate(fixed_f = fct_relevel(f, &amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;)) %&amp;gt;%
  print()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 100 x 5
##          x     y s     f     fixed_f
##      &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;  
##  1 -0.504  2.69  c     c     c      
##  2 -0.448  3.30  a     a     a      
##  3 -0.896  2.67  c     c     c      
##  4 -0.326  1.64  b     b     b      
##  5  0.0344 2.99  b     b     b      
##  6 -1.26   0.620 b     b     b      
##  7  1.63   7.29  b     b     b      
##  8  0.705  6.40  d     d     d      
##  9  0.330  4.63  a     a     a      
## 10  0.480  4.94  b     b     b      
## # ... with 90 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll note that the variables &lt;code&gt;f&lt;/code&gt; and &lt;code&gt;fixed_f&lt;/code&gt; now have the same values, but the ordering of &lt;code&gt;fixed_f&lt;/code&gt;’s levels has been modified.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# f as color
ggplot(fixed_d, aes(x = x, y = y)) +
  geom_point(shape = 1,
             aes(color = fixed_f)) +
  labs(x = &amp;quot;Continuous X&amp;quot;, 
       y = &amp;quot;Continuous Y&amp;quot;,
       color = &amp;quot;Ordered Factor&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-54-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# f as x axis
ggplot(fixed_d, aes(x = f, y = y)) +
  geom_point(shape = 1) +
  labs(x = &amp;quot;Ordered Factor&amp;quot;, y = &amp;quot;Continuous Y&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/811/811-04-graphics_files/figure-html/unnamed-chunk-54-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;an-aside-on-stringr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;An aside on &lt;code&gt;stringr&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;stringr&lt;/code&gt; package contains a few useful functions for modifying character vectors.&lt;/p&gt;
&lt;p&gt;Let’s take the &lt;code&gt;state.name&lt;/code&gt; vector that comes with R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;state.name&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;Alabama&amp;quot;        &amp;quot;Alaska&amp;quot;         &amp;quot;Arizona&amp;quot;        &amp;quot;Arkansas&amp;quot;      
##  [5] &amp;quot;California&amp;quot;     &amp;quot;Colorado&amp;quot;       &amp;quot;Connecticut&amp;quot;    &amp;quot;Delaware&amp;quot;      
##  [9] &amp;quot;Florida&amp;quot;        &amp;quot;Georgia&amp;quot;        &amp;quot;Hawaii&amp;quot;         &amp;quot;Idaho&amp;quot;         
## [13] &amp;quot;Illinois&amp;quot;       &amp;quot;Indiana&amp;quot;        &amp;quot;Iowa&amp;quot;           &amp;quot;Kansas&amp;quot;        
## [17] &amp;quot;Kentucky&amp;quot;       &amp;quot;Louisiana&amp;quot;      &amp;quot;Maine&amp;quot;          &amp;quot;Maryland&amp;quot;      
## [21] &amp;quot;Massachusetts&amp;quot;  &amp;quot;Michigan&amp;quot;       &amp;quot;Minnesota&amp;quot;      &amp;quot;Mississippi&amp;quot;   
## [25] &amp;quot;Missouri&amp;quot;       &amp;quot;Montana&amp;quot;        &amp;quot;Nebraska&amp;quot;       &amp;quot;Nevada&amp;quot;        
## [29] &amp;quot;New Hampshire&amp;quot;  &amp;quot;New Jersey&amp;quot;     &amp;quot;New Mexico&amp;quot;     &amp;quot;New York&amp;quot;      
## [33] &amp;quot;North Carolina&amp;quot; &amp;quot;North Dakota&amp;quot;   &amp;quot;Ohio&amp;quot;           &amp;quot;Oklahoma&amp;quot;      
## [37] &amp;quot;Oregon&amp;quot;         &amp;quot;Pennsylvania&amp;quot;   &amp;quot;Rhode Island&amp;quot;   &amp;quot;South Carolina&amp;quot;
## [41] &amp;quot;South Dakota&amp;quot;   &amp;quot;Tennessee&amp;quot;      &amp;quot;Texas&amp;quot;          &amp;quot;Utah&amp;quot;          
## [45] &amp;quot;Vermont&amp;quot;        &amp;quot;Virginia&amp;quot;       &amp;quot;Washington&amp;quot;     &amp;quot;West Virginia&amp;quot; 
## [49] &amp;quot;Wisconsin&amp;quot;      &amp;quot;Wyoming&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are some useful functions. Play with these on your own.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# look for pattern, return a logical vector
str_detect(state.name, &amp;quot; &amp;quot;) #  spaces

# example: return all two-word state names
state.name[str_detect(state.name, &amp;quot; &amp;quot;)]

# substring based on character position
str_sub(state.name, 1L, 3L)
str_sub(state.name, -3L, -1L)

# cut a string based on a pattern match (returns a list)
str_split(state.name, pattern = &amp;quot; &amp;quot;)

# grab the nth element of a split string list
# in this case, the second element (x[2])
sapply(str_split(state.name, pattern = &amp;quot; &amp;quot;) , function(x) x[2])

# replace a pattern with another pattern
str_replace(state.name, pattern = &amp;quot; &amp;quot;, replacement = &amp;quot;-&amp;quot;)

# for strings that might contain multiple instances of the pattern
# (won&amp;#39;t notice a difference here)
str_replace_all(state.name, pattern = &amp;quot; &amp;quot;, replacement = &amp;quot;-&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;concluding-notes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Concluding notes&lt;/h1&gt;
&lt;div id=&#34;why-plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why plot&lt;/h2&gt;
&lt;p&gt;You should be plotting your data often, even if you don’t expect the plot to make it into your final product.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plotting shows you the distribution of your data, which can help you decide on certain modeling assumptions or variable transformations. (You should not rely entirely on plots for this…let theory guide you)&lt;/li&gt;
&lt;li&gt;Plotting shows outliers, which may help you think about unmodeled covariates.&lt;/li&gt;
&lt;li&gt;Plotting gives you a sense of the underlying trends in your data so you can be a better thinker about the problem at hand.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can see Hadley Wickham do some exploratory analysis &lt;a href=&#34;https://www.youtube.com/watch?v=go5Au01Jrvs&#34;&gt;here&lt;/a&gt;, which shows how graphics (and &lt;code&gt;ggplot&lt;/code&gt; in particular) facilitates principled and &lt;em&gt;fast&lt;/em&gt; exploration of your data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-and-ggplot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data and &lt;code&gt;ggplot&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;If you haven’t already picked up on it, &lt;code&gt;ggplot&lt;/code&gt; is designed to complement the philosophy of tidy data. It does this mainly by forcing you to declare a data frame from which you are plotting. This helps ensure that the data you are plotting are conceptually related and can be easily mapped to plot aesthetics. And in order to shape your data so that these mappings are done correctly, the tools in &lt;code&gt;tidyr&lt;/code&gt; and &lt;code&gt;dplyr&lt;/code&gt; are extremely helpful.&lt;/p&gt;
&lt;p&gt;As we have seen, many tools in &lt;code&gt;ggplot&lt;/code&gt; are designed to prevent you from modifying the underlying data too much. This is generally a tenet of the Tidyverse philosophy. Your original data frames are sacrosanct, and they serve as the raw material from which analyses and plots are extracted. This is why pipe chains begin with a tidy dataset and work out from there. Changes that you make to the data that &lt;em&gt;only&lt;/em&gt; exist for the purpose of plotting (or modeling, etc.) should be temporary, as they are not essential to the core underlying data.&lt;/p&gt;
&lt;p&gt;Say that you have raw data that has an ugly text label, and every time you plot that variable, you want a prettier text label. Rather than change the underlying data, you might make another table that serves as a dictionary for converting the ugly label to a prettier label. You can then merge this table into your data just before plotting. Practices such as this keep your original data free of extraneous stuff while still allowing you to produce beautiful graphics.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphics-approaches-base-vs-ggplot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graphics approaches, base vs &lt;code&gt;ggplot&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Base graphics, on the other hand, do not rely on an underlying data model in order to work. You can plot points, lines, labels, and so on, with no conceptual connection between the data used for any of these geoms. Furthermore, legends and labels are entirely detached from the data. This makes base graphics inefficient and prone to human error in a number of ways, mainly because updates to the elements of your graphics need to made separately from updates to legends, labels, axes and so on. These elements are all conceptually independent in base graphics, so they have no knowledge about how you change the data or the appearance of the graphics. That said, it is definitely possible to create beautiful graphics using base tools; it will just take more work and more time.&lt;/p&gt;
&lt;p&gt;All this being said, base graphics do have some advantage on &lt;code&gt;ggplot&lt;/code&gt; graphics if you have to create a plot that contains many unrelated elements that don’t share a common data frame. (It is possible to plot from multiple data frames in &lt;code&gt;ggplot&lt;/code&gt;, but it isn’t easy.)&lt;/p&gt;
&lt;p&gt;You can find plenty of disagreements online about how and when base or &lt;code&gt;ggplot&lt;/code&gt; tools are better. I know no human being who has learned ggplot and opted for base graphics, so I’m making the bet that this lesson will lead you to the same conclusion.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-graphical-dos-and-donts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other graphical Dos and Don’ts&lt;/h2&gt;
&lt;p&gt;Some general advice for plotting:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Don’t use multiple Y axes. It’s easy to use multiple Y axis scales to make variables look more or less related (&lt;a href=&#34;https://kieranhealy.org/blog/archives/2016/01/16/two-y-axes/&#34;&gt;see here&lt;/a&gt;), so you shouldn’t do it. In fact, for the longest time, &lt;code&gt;ggplot&lt;/code&gt; would not allow you to create a second y-axis (because it’s opinionated like that).&lt;/li&gt;
&lt;li&gt;If you can label points or trends &lt;em&gt;in the plot&lt;/em&gt; rather than in a legend, do so. You can do this with &lt;code&gt;geom_text&lt;/code&gt; or the &lt;code&gt;annotate()&lt;/code&gt; function.&lt;/li&gt;
&lt;li&gt;Try to make your graphics as minimal as possible. Add elements where it improves the graphic. Otherwise, you don’t want to create clutter.&lt;/li&gt;
&lt;li&gt;If you can use aesthetic features &lt;em&gt;besides&lt;/em&gt; color to distinguish groups, that would be ideal. Some forms of color-blindness are remarkably common, and at any rate, journals may not allow your article to print in color. It’s best to get mentally prepared to use more line types, point styles, and so on, to distinguish groups of data.&lt;/li&gt;
&lt;li&gt;If you must use colors, you should check out some colorblindness-friendly color palettes and packages. You could check out the &lt;code&gt;dichromat&lt;/code&gt; package to investigate how your color selections look to individuals with various forms of colorblindness. The &lt;code&gt;viridis&lt;/code&gt; package also provides a variety of scales for colorblind-friendly graphics.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;other-gg-tools&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other &lt;code&gt;gg&lt;/code&gt; tools&lt;/h2&gt;
&lt;p&gt;There are many extensions for &lt;code&gt;ggplot&lt;/code&gt; that you can install. Rather than tediously describe them, I’ll point you to a &lt;a href=&#34;http://www.ggplot2-exts.org/gallery/?utm_content=buffer6d153&amp;amp;utm_medium=social&amp;amp;utm_source=twitter.com&amp;amp;utm_campaign=buffer&#34;&gt;web page&lt;/a&gt; discussing many of the tools out there. These let you create heatmaps, choropleths, network graphs, mosaic plots, autocorrelation plots, and much more. Extensions I have used in the past include &lt;code&gt;ggfortify&lt;/code&gt;, &lt;code&gt;ggridges&lt;/code&gt;, &lt;code&gt;ggthemes&lt;/code&gt;, &lt;code&gt;ggsci&lt;/code&gt;, &lt;code&gt;GGally&lt;/code&gt;, and &lt;code&gt;ggalt&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Many more extensions are in development and cannot be found on CRAN, but they can be downloaded and installed. One that I particularly like is &lt;a href=&#34;https://github.com/thomasp85/patchwork&#34;&gt;&lt;code&gt;patchwork&lt;/code&gt;&lt;/a&gt;, which combines multiple graphics into the same image using an extremely simple syntax.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;graphics-in-future-lessons&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graphics in future lessons&lt;/h2&gt;
&lt;p&gt;We will further explore graphics using &lt;code&gt;ggplot&lt;/code&gt; in the final lesson on statistical analysis. In particular, we’ll discuss how to use &lt;code&gt;ggplot&lt;/code&gt; tools to summarize statistical models and create post-estimation graphics.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;save-data-from-this-session&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Save data from this session&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;saveRDS(anes, &amp;quot;data/anes-modified-2.RDS&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Lecture 1: Data Manipulation</title>
      <link>/811/811-data/</link>
      <pubDate>Fri, 09 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/811/811-data/</guid>
      <description>&lt;div id=&#34;schedule&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Schedule:&lt;/h1&gt;
&lt;p&gt;Read this before our first R lecture.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-follow-along&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to follow along&lt;/h1&gt;
&lt;p&gt;A script file walking through some of these commands is available &lt;a href=&#34;https://uwmadison.box.com/s/xqr5frqtwbtlv342fg7zn1ts9va2ei2t&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;objectives&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Objectives&lt;/h1&gt;
&lt;p&gt;The goal of this lesson is to simulate some data manipulation for a research project. This requires…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;setting up the project on your computer&lt;/li&gt;
&lt;li&gt;Get data onto the computer (the &lt;a href=&#34;http://electionstudies.org/studypages/anes_timeseries_cdf/anes_timeseries_cdf.htm&#34;&gt;ANES&lt;/a&gt; should already be downloaded!)&lt;/li&gt;
&lt;li&gt;Load the data into R&lt;/li&gt;
&lt;li&gt;Cleaning and modifying the data&lt;/li&gt;
&lt;li&gt;Doing some simple calculations&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Future lessons pick up where this one leaves off, so you must complete this lesson!. We will be &lt;a href=&#34;811/811-graphics&#34;&gt;making graphics&lt;/a&gt; and doing &lt;a href=&#34;811/811-analysis&#34;&gt;statistical analysis&lt;/a&gt; that depend on the changes we make in this document.&lt;/p&gt;
&lt;!-- # How to read this document --&gt;
&lt;!-- I have also uploaded an R file containing the commands from this document. You can use this other file to follow along with the code on this webpage. You may also benefit from transcribing the code from this page into your own script file, as a way to practice writing the code yourself. --&gt;
&lt;/div&gt;
&lt;div id=&#34;setting-up-a-project&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Setting up a project&lt;/h1&gt;
&lt;p&gt;Each projects should have a dedicated folder on your computer. These folders should be internally organized: separate folders for data, R scripts, writing, other documentation, and so on.&lt;/p&gt;
&lt;p&gt;Here is an example of one of my project folders.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/811/dir.png&#34; width=&#34;80%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this class, set up your class folder like this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You should already have a dedicated &lt;code&gt;ps811&lt;/code&gt; folder&lt;/li&gt;
&lt;li&gt;Inside of &lt;code&gt;ps811&lt;/code&gt;, create an &lt;code&gt;R&lt;/code&gt; folder for all of your R materials.&lt;/li&gt;
&lt;li&gt;Inside of &lt;code&gt;R&lt;/code&gt;, create folders for &lt;code&gt;data&lt;/code&gt;, &lt;code&gt;lessons&lt;/code&gt;, and &lt;code&gt;exercises&lt;/code&gt;. Put all data in the &lt;code&gt;data&lt;/code&gt; folder, and put any R files corresponding to online lessons and lecture in the &lt;code&gt;lessons&lt;/code&gt; folder.&lt;/li&gt;
&lt;li&gt;(Exercise files will go in the &lt;code&gt;exercises&lt;/code&gt; folder).&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;tips-for-project-folders&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tips for project folders&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;When you name your folders and files, use hyphens or underscores to separate words, not spaces. Something like &lt;code&gt;811-data-lesson.R&lt;/code&gt; is better than &lt;code&gt;811 data lesson.R&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Use short folder and file names names when you can. This makes your life easier in the long run (e.g. with Git, which I recommend learning).&lt;/li&gt;
&lt;li&gt;Avoid setting up the folders in ways that would require you to navigate &lt;em&gt;up&lt;/em&gt; the directory tree. See below for more about what I mean.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;directories&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Directories&lt;/h1&gt;
&lt;p&gt;Just as you can look around your computer in the file browser (“Finder” on Mac and “Explorer” on Windows), R looks around your computer as well, but it needs your help knowing where to look.&lt;/p&gt;
&lt;p&gt;Find the current working directory with &lt;code&gt;getwd()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# &amp;quot;get working directory&amp;quot; 
# prints the current directory pathway (here is mine)
getwd()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;/Users/michaeldecrescenzo/Box Sync/site/leave_it/content/811&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To find your project folder, &lt;em&gt;set your working directory&lt;/em&gt; to the appropriate path (the &lt;code&gt;ps811/R/lessons&lt;/code&gt; folder).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# setwd() = &amp;quot;set working directory&amp;quot; 
# changes the directory to the specified file path
# the &amp;quot;~&amp;quot; is a shortcut that means &amp;quot;the top of my user profile&amp;quot; 
setwd(&amp;quot;~/pathway/to/ps811/R/lessons&amp;quot;)

# confirm directory location
getwd()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As with many R functions, you know &lt;code&gt;setwd()&lt;/code&gt; worked when it gives you no feedback whatsoever.&lt;/p&gt;
&lt;p&gt;You should always set your directory to the &lt;em&gt;top&lt;/em&gt; of the project folder (also called the “project root” of the project). Do &lt;em&gt;not&lt;/em&gt; set it all the way into the &lt;code&gt;data/&lt;/code&gt; folder. This is because it is always easier to navigate &lt;em&gt;down&lt;/em&gt; into the data folder than it is to navigate &lt;em&gt;up&lt;/em&gt; back into the project folder. That’s because the keyword for doing up a folder, &lt;code&gt;..&lt;/code&gt;, is very uninformative.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-started&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Getting started&lt;/h1&gt;
&lt;p&gt;Load some packages so they can be used in this R session. These should already be downloaded from the previous lesson.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# package loading is done using library().
# Quotes around the package name aren&amp;#39;t necessary 
# but recommended for technical reasons

library(&amp;quot;magrittr&amp;quot;)
library(&amp;quot;tidyverse&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you load &lt;code&gt;tidyverse&lt;/code&gt;, you should see a warning that it “masks” some names in the &lt;code&gt;magrittr&lt;/code&gt; and other packages. This means some of the function names in the packages are the same. This is &lt;em&gt;generally&lt;/em&gt; something you should be watching out for, since your code may not work as intended. It won’t be a problem right now, though.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;read-external-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Read external data&lt;/h1&gt;
&lt;p&gt;With your directory set at &lt;code&gt;ps811/R/lessons&lt;/code&gt;, confirm that the ANES data file are where they should be using &lt;code&gt;list.files()&lt;/code&gt;. You can look inside folders by adding the folder path as an argument. The ANES data should be in the &lt;code&gt;data/&lt;/code&gt; folder.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# this is similar to typing `ls` in your computer&amp;#39;s shell / command line
list.files()

# you should see the &amp;quot;data&amp;quot; folder.
# Now look inside the &amp;quot;data&amp;quot; folder; should see the ANES file
list.files(&amp;quot;data&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R has many functions for “reading” datasets into memory, depending on the file format. They typically follow a format of &lt;code&gt;read.xyz()&lt;/code&gt; or &lt;code&gt;read_xyz()&lt;/code&gt;, where &lt;code&gt;xyz&lt;/code&gt; refers to the file type.&lt;/p&gt;
&lt;p&gt;We want to read a Stata file, which uses the &lt;code&gt;.dta&lt;/code&gt; file extension. Although many tutorials will recommend using the &lt;code&gt;foreign&lt;/code&gt; package for Stata files, &lt;code&gt;foreign&lt;/code&gt; is outdated and can fail with newer Stata files. I usually use the &lt;code&gt;haven&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# should already be installed
library(&amp;quot;haven&amp;quot;)

# read_dta(&amp;quot;path/to/data-file.dta&amp;quot;)
anes &amp;lt;- read_dta(&amp;quot;data/anes_timeseries_cdf.dta&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This should take a few moments to load because the ANES cumulative file is a large file. Don’t worry.&lt;/p&gt;
&lt;p&gt;You may want to check out the &lt;code&gt;rio&lt;/code&gt; package for more generic file-reading functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-frames&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data frames&lt;/h1&gt;
&lt;p&gt;Data sets in R are known as “data frames.” Data frames are tabular objects where the columns are variables with variable names. This is just like Stata, but what makes R different is that we can have many data frames in R at one time.&lt;/p&gt;
&lt;p&gt;Print the data to see what the table looks like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Technically speaking, the &lt;code&gt;anes&lt;/code&gt; object isn’t an ordinary data frame. It’s a “tibble”, which is a modified data frame object, the main differences being that tibbles are often faster and prettier when printed to the console.&lt;/p&gt;
&lt;p&gt;You can always print a full data frame by coercing a tibble to the standard data frame class, but be warned: the results can be ugly if R tries to print a full data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# as.data.frame() coerces an object to be data.frame class
# (there are many different as.class() functions for coercing data)

# You should run this command to see how it works, but be warned: 
# this is gonna look gnarsty
as.data.frame(anes)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can create your own data frame using &lt;code&gt;data_frame()&lt;/code&gt;. An example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create x and y variables,
# then use x and y to create other variables 
#   (inside the same function!)
data_frame(x = 1:3, 
           y = 4:6, 
           z = x + y, 
           abc = z * z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 4
##       x     y     z   abc
##   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
## 1     1     4     5    25
## 2     2     5     7    49
## 3     3     6     9    81&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;learning-about-data-frames&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Learning about data frames&lt;/h2&gt;
&lt;p&gt;Some functions for learning about your data:&lt;/p&gt;
&lt;p&gt;Find the number of rows (observations). In this case, rows are survey respondents.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# number of rows
nrow(anes) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 55674&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Find the number of columns (variables).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# number of columns
ncol(anes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 952&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Print the top or bottom of a data frame to get a glance of it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# top 6 and bottom 6 rows
# can set n != 6 if you desire
head(anes) 
tail(anes)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Print a vector of variable names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# vector of variable names
names(anes)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;other-functions-for-viewing-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other functions for viewing data&lt;/h2&gt;
&lt;p&gt;There are two for interacting directly with a data table as if it were a spreadsheet: &lt;code&gt;View()&lt;/code&gt; and &lt;code&gt;edit()&lt;/code&gt;. I recommend against using these, because these functions often make R freak out and freeze. The &lt;em&gt;only time this has ever worked for me&lt;/em&gt; is when I was using Rstudio, which has a handy spread sheet window for datasets.&lt;/p&gt;
&lt;p&gt;If you must edit data as a spread sheet, you may want to save it as a &lt;code&gt;csv&lt;/code&gt; file and open it in Numbers, Excel, or some other similar program.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;variables-in-a-data-frame&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Variables in a data frame&lt;/h1&gt;
&lt;p&gt;Here is a funky but &lt;em&gt;extremely important&lt;/em&gt; R thing. Variables in a dataset cannot be accessed by typing only the variable name.&lt;/p&gt;
&lt;p&gt;Try to print &lt;code&gt;VCF0004&lt;/code&gt; variable. The codebook (which you should have!) tells us that it’s the election cycle variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VCF0004&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should get an error. To prevent the error, use &lt;code&gt;dataset$variable&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# this should work
anes$VCF0004&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;$&lt;/code&gt; symbol tells R that the variable is &lt;em&gt;inside&lt;/em&gt; the &lt;code&gt;anes&lt;/code&gt; dataset. This is necessary because we may have multiple datasets in R with the same variable names, so we have to be specific when we want one particular variable. Yes, this is more complicated than Stata, but it lets us do a lot of cool stuff that Stata makes difficult or tedious.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;do-not-attach-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;DO NOT attach data&lt;/h1&gt;
&lt;p&gt;Others may have advised you that you can sidestep the &lt;code&gt;dataset$variable&lt;/code&gt; syntax by attaching data (&lt;code&gt;attach(dataset)&lt;/code&gt;). &lt;em&gt;Ignore that advice&lt;/em&gt;. You should not attach data. It does not do what you think it does, and it creates so many more (invisible) problems than it solves. Attaching data is playing with fire.&lt;/p&gt;
&lt;p&gt;My policy for this class is that attaching is forbidden. Do not attach data for your homework. Do not attach data for your final project. Do not attach data in a house or with a mouse. If you are used to attaching data, I’m sorry, but you will thank me later.&lt;/p&gt;
&lt;p&gt;Luckily for us (and all of the R community), the &lt;code&gt;tidyverse&lt;/code&gt; package provides many tools that make attaching unnecessary.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-tidyverse&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Tidyverse&lt;/h1&gt;
&lt;p&gt;Now, the good stuff. The &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;Tidyverse&lt;/a&gt; describes itself as…&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;…an opinionated collection of R packages designed for data science. All packages share an underlying philosophy and common APIs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;in-short&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;In short&lt;/h2&gt;
&lt;p&gt;There are lots of R packages out there. Some of them exist under umbrellas of shared use and interface. You can think about the Tidyverse as an umbrella of similar packages that are designed to have similar interfaces and intuitions.&lt;/p&gt;
&lt;p&gt;The “Tidyverse” as a &lt;em&gt;concept&lt;/em&gt; refers to the collection of packages, including &lt;code&gt;tidyr&lt;/code&gt;, &lt;code&gt;dplyr&lt;/code&gt;, and so on. The &lt;code&gt;tidyverse&lt;/code&gt; package &lt;em&gt;unto itself&lt;/em&gt; is a relatively recent entity. It is simply a bundling of the most-used Tidyverse tools (not &lt;em&gt;every&lt;/em&gt; tool, however).&lt;/p&gt;
&lt;p&gt;The &lt;a href=&#34;https://www.tidyverse.org/packages/&#34;&gt;packages in the Tidyverse&lt;/a&gt; are all designed to clean and manipulate data according to the principle of “tidy data” (described below). Moreover, the tools are designed with a coherent syntax that makes them easy for beginners to learn, easy to understand (when you read the code), easy to integrate into complex analysis, and easy for visualizing data. It is hard for me, as someone who has been using R for years, to describe to newcomers just how much the Tidyverse has improved the world of R in recent years.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;in-medium&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;In medium&lt;/h2&gt;
&lt;p&gt;The Tidyverse is based on a philosophy is based on &lt;em&gt;tidy data&lt;/em&gt;, which refers to data organization where (1) rows contain cases, (2) columns contain variables, and (3) cells contain variable values.&lt;/p&gt;
&lt;p&gt;Although this sounds simple, there are many data formats that do not fit that pattern. Legislative data, for example, is often represented as a vote matrix with legislators in rows and bills in columns. The cells, in turn, would contain &lt;code&gt;1&lt;/code&gt;s and &lt;code&gt;0&lt;/code&gt;s to indicate legislators’ Yea and Nay votes, respectively, on each bill. A tidy legislative voting dataset, on the other hand, would have a legislator variable, a bill variable, and a vote variable. Both datasets contain the same information, but the organization of the data allow for different sorts of manipulations. And it so happens that the tidy organization is particularly helpful for doing a lot of powerful stuff with R with very little code.&lt;/p&gt;
&lt;p&gt;For more resources about the Tidyverse (aside from this course), you can visit a webpage devoted to &lt;a href=&#34;https://www.tidyverse.org/learn/&#34;&gt;such resources&lt;/a&gt;, which links you to the &lt;a href=&#34;http://r4ds.had.co.nz/&#34;&gt;R 4 Data Science&lt;/a&gt; book, a book on &lt;a href=&#34;https://github.com/hadley/ggplot2-book&#34;&gt;&lt;code&gt;ggplot2&lt;/code&gt;&lt;/a&gt;, and various &lt;a href=&#34;https://www.rstudio.com/resources/cheatsheets/&#34;&gt;cheatsheets&lt;/a&gt; for the constituent packages of the Tidyverse. I got my start using &lt;a href=&#34;https://rpubs.com/bradleyboehmke/data_wrangling&#34;&gt;this blog post&lt;/a&gt;, which describes the concept of “piping data” (which we will cover later) and two of the most important Tidyverse packages: &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;tidyr&lt;/code&gt;. We will cover the main points of the Tidyverse, but I would bookmark these resources for later browsing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;One last note before &lt;em&gt;really&lt;/em&gt; jumping in:&lt;/strong&gt; It is a conscious decision to focus on the Tidyverse at the expense of other approaches (namely, “base R”). As I wrote in &lt;a href=&#34;811/811-intro&#34;&gt;the online introduction to these R lessons&lt;/a&gt;, this is because we have a limited time to make R fun and accessible, and base R is not ideal for that purpose. That being said, you may encounter base R online and in replication materials for other studies, so you should be open to learning a little bit about it on your own time. But I would encourage against making it your “default” mode of doing R, because it is quite old and inefficient compared to the tools we’ll learn in class. Hopefully you’ll see how easy the Tidyverse is as we proceed!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;how-tidyverse-functions-work&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How &lt;code&gt;tidyverse&lt;/code&gt; functions work&lt;/h1&gt;
&lt;p&gt;Tidyverse literature refers to its core functions as “verbs.” These are functions that take a data frame and modify it.&lt;/p&gt;
&lt;p&gt;When you call one of these verbs, you declare the dataset name in the function, so you don’t need to use the &lt;code&gt;$&lt;/code&gt; to reference a variable (nice!). The function assumes that the variable is located in the declared dataset, and if not, it will check the global R memory for objects of the same name. A generic example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# overwrite the old dataset with the results
# declare the dataset as the first argument, then specify any arguments
dataset &amp;lt;- verb_name(dataset, verb_arguments = ...)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will review the following &lt;code&gt;tidyverse&lt;/code&gt; functions from the &lt;code&gt;dplyr&lt;/code&gt; package. The &lt;code&gt;dplyr&lt;/code&gt; tools are designed to manipulate data that is already in a tidy format.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rename()&lt;/code&gt;: renaming variables&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mutate()&lt;/code&gt;: create and recode variables&lt;/li&gt;
&lt;li&gt;&lt;code&gt;select()&lt;/code&gt;: keep/eliminate variables (columns)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filter()&lt;/code&gt;: keep/eliminate observations (rows)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;summarize()&lt;/code&gt;: collapse/aggregate data (e.g. summary statistics, group means…)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;group_by()&lt;/code&gt;: create groups out of your data (e.g. for summarizing within group)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;arrange()&lt;/code&gt;: sorting data&lt;/li&gt;
&lt;li&gt;various &lt;code&gt;join&lt;/code&gt; functions: merging data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;tidyr&lt;/code&gt; package is designed to take un-tidy data and make it tidy. We’ll cover these functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;gather()&lt;/code&gt;: turn many columns into one column (wide to long)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;spread()&lt;/code&gt;: turn one column into many columns (long to wide)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Most data manipulation tasks fall under the umbrella of one or more of these functions. This is what makes the Tidyverse so useful: it has a small number of very powerful tools that facilitate nearly all common data munging tasks!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;renaming&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Renaming&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;rename()&lt;/code&gt; function takes a data frame with one set of names, and it returns a data frame with different names.&lt;/p&gt;
&lt;p&gt;Here, we rename the following variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;election year&lt;/li&gt;
&lt;li&gt;respondents’ ratings of the two major US parties on a 7-pt ideological scale (1 “extremely liberal” to 7 “extremely conservative”)&lt;/li&gt;
&lt;li&gt;respondents’ ratings of themselves on the same scale&lt;/li&gt;
&lt;li&gt;and a 7-pt index of party ID (Strong Democrat, Weak Democrat, Independent leaning Democrat, True Independent, Leaning Republican, and so on)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# rename(dataset, 
#        new_name = old_name,
#        new_name2 = old_name2)

anes &amp;lt;- rename(anes, 
               cycle = VCF0004,
               libcon_demparty = VCF0503, 
               libcon_repparty = VCF0504, 
               libcon_self = VCF0803,
               pid7 = VCF0301)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Be warned: this command &lt;em&gt;overwrites the original &lt;code&gt;anes&lt;/code&gt; dataset&lt;/em&gt; with a new version with different variables names. If you want to keep the original variables, copy the old variable into a new variable with a new name. How would you do that? Well…&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;modifying-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Modifying data&lt;/h1&gt;
&lt;p&gt;Modify the columns of a dataset with &lt;code&gt;mutate()&lt;/code&gt;. We can create new variables or modify existing variables (a.k.a. “recoding”).&lt;/p&gt;
&lt;p&gt;How it works: declare an existing data frame, modify variables within it, and the result is a new data frame with the specified changes.&lt;/p&gt;
&lt;p&gt;Let’s test it out. Let’s look at the ideological self-placement variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(anes$libcon_self, exclude = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##     0     1     2     3     4     5     6     7     9  &amp;lt;NA&amp;gt; 
##  1748   750  3138  3603  9873  5304  5379   995  9568 15316&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We only care about the values 1 through 7. We want to recode everything else as missing (&lt;code&gt;NA&lt;/code&gt;). Here are the two methods I use most often to modify variables.&lt;/p&gt;
&lt;div id=&#34;the-ifelse-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The &lt;code&gt;ifelse()&lt;/code&gt; function&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;ifelse()&lt;/code&gt; function follows the following psueocode intuition:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if (this) then {that} 
  else {something else}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may have seen these sorts of if-else statements in other programming languages. In R, we can use the &lt;code&gt;ifelse()&lt;/code&gt; function to apply an if-else statement to an entire vector (variable).&lt;/p&gt;
&lt;p&gt;A dummy example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_result &amp;lt;- ifelse(condition, A, B)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;ifelse()&lt;/code&gt; function checks a condition in the data. This condition is a logical statement: is something equal to something, greater than something, and so on. If the condition applies (meaning, if the statement evaluates to &lt;code&gt;TRUE&lt;/code&gt;), the result is &lt;code&gt;A&lt;/code&gt;, and if the condition does not apply, the result is &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We will use it within the &lt;code&gt;mutate()&lt;/code&gt; function. I have to get creative with code indentation to make this example more legible, so bear with me.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# translation: 
#   modify anes
#   recode libson_self, the result of ifelse()
#   ifelse(logical test, result if TRUE, result if FALSE)
#   and recode demparty

# Notes: 
#   notice how I can break lines after the &amp;lt;- symbol
#   this is because &amp;lt;- needs a left-side and right-side object
#   if there is no right-side object, R looks for on next line
#   this works for all &amp;quot;binary operators&amp;quot; such as +, -, *, and so on
#   In general, R will look at the next line until a statement is complete
#   so you should be careful to close all &amp;quot;quotes&amp;quot; and (parentheses)
anes &amp;lt;- 
  mutate(anes, 
         libcon_self = ifelse(libcon_self == 0 | 
                                libcon_self &amp;gt;= 8 | 
                                is.na(libcon_self), 
                              NA, 
                              libcon_self), 
         libcon_demparty = ifelse(libcon_demparty %in% 1:7, 
                                  libcon_demparty, 
                                  NA))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We recode two variables in this &lt;code&gt;mutate()&lt;/code&gt; call. We use &lt;code&gt;ifelse()&lt;/code&gt; in slightly different ways. Here is the translation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If &lt;code&gt;libcon_self&lt;/code&gt; is 0 &lt;em&gt;or&lt;/em&gt; greater than &lt;em&gt;or&lt;/em&gt; equal to 8 &lt;em&gt;or&lt;/em&gt; NA, &lt;em&gt;then&lt;/em&gt; recode to &lt;code&gt;NA&lt;/code&gt;, &lt;em&gt;else&lt;/em&gt; recode to the existing value of &lt;code&gt;libcon_self&lt;/code&gt; (i.e. no change).&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;libcon_demparty&lt;/code&gt; is an integer value 1 through 7, keep it the way it is, else recode to &lt;code&gt;NA&lt;/code&gt;. We’ll return to the &lt;code&gt;%in%&lt;/code&gt; operator at the end of this section.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Read the binary logical operations as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;A == B&lt;/code&gt;: A is equal to B&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A &amp;gt; B&lt;/code&gt;: A is greater than to B&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A &amp;lt; B&lt;/code&gt;: A is less than to B&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A &amp;gt;= B&lt;/code&gt;: A is greater than or equal to B&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A &amp;lt;= B&lt;/code&gt;: A is less than or equal to B&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A | B&lt;/code&gt;: A or B&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A &amp;amp; B&lt;/code&gt;: A and B&lt;/li&gt;
&lt;li&gt;&lt;code&gt;A %in% c(B, C, D)&lt;/code&gt;: A is equal to any of the following: &lt;code&gt;B&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt;, or &lt;code&gt;D&lt;/code&gt;. Or, &lt;code&gt;A&lt;/code&gt; is some element of the set &lt;code&gt;{B, C, D}&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;is.na(A)&lt;/code&gt;: A is &lt;code&gt;NA&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;!is.na(A)&lt;/code&gt;: A is &lt;em&gt;not&lt;/em&gt; &lt;code&gt;NA&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Heads up: nothing can be &lt;em&gt;equal to&lt;/em&gt; &lt;code&gt;NA&lt;/code&gt;. That’s because &lt;code&gt;NA&lt;/code&gt; isn’t a value; it’s a stand-in for an unknown value. This is why we use the &lt;code&gt;is.na()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;Also: the &lt;code&gt;%in%&lt;/code&gt; operator is a godsend because…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;x == (1 | 2 | 3)&lt;/code&gt; doesn’t work&lt;/li&gt;
&lt;li&gt;&lt;code&gt;x == 1 | x == 2 | x == 3&lt;/code&gt; works but is annoying&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Instead, it is easier to type &lt;code&gt;x %in% c(1, 2, 3)&lt;/code&gt; (or &lt;code&gt;x %in% 1:3&lt;/code&gt; if we want to match adjacent integers).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-case_when-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The &lt;code&gt;case_when()&lt;/code&gt; function&lt;/h2&gt;
&lt;p&gt;Whenever we have multiple conditions that we want to check in the same function, we could nest several &lt;code&gt;ifelse()&lt;/code&gt; functions within each other or use a very complicated logical test, but it gets quickly gets ugly and is easy to mess up.&lt;/p&gt;
&lt;p&gt;In situations like this, you should use the &lt;code&gt;case_when()&lt;/code&gt; function, which is a more flexible version of &lt;code&gt;ifelse()&lt;/code&gt;, but it’s a little different. See the comments in the code chunk below for how it works.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# case_when(test ~ result if test is true,
#           test2 ~ result if test2 is true,
#           test3 ~ you get the idea)

# NOTE: all non-matched cases are given an NA by default
# to override this, use the catch-all replacement: TRUE ~ x

# case_when(test ~ result,
#           test2 ~ result2,
#           test3 ~ result3,
#           TRUE ~ result4)

# read as &amp;quot;and everything else should be recoded as result4&amp;quot;

anes &amp;lt;- mutate(anes,
  libcon_repparty = case_when(
                      libcon_repparty == 1 ~ libcon_repparty,
                      libcon_repparty == 2 ~ libcon_repparty,
                      libcon_repparty %in% c(3, 4) ~ libcon_repparty,
                      libcon_repparty %in% (5:7) ~ libcon_repparty),
  pid7 = case_when( (pid7 %in% 1:7) ~ pid7) )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may find it helpful to place the tests in parentheses, as I do in the &lt;code&gt;pid7&lt;/code&gt; example. It doesn’t affect the code, but is sometimes easier to read, especially if the logical test is complicated or lengthy.&lt;/p&gt;
&lt;p&gt;The above code, translated:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If &lt;code&gt;libcon_repparty&lt;/code&gt; is equal to 1, replace with &lt;code&gt;libcon_repparty&lt;/code&gt; (i.e. keep the same). If it is 2, keep the same. Same with values 3 and 4, and 5 through 7. The only reason I break these into different conditions is to show you different ways to do this logical matching.&lt;/li&gt;
&lt;li&gt;If the &lt;code&gt;pid7&lt;/code&gt; variable is an integer value 1 through 7, keep it the same.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;general-tips-for-recoding&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;General tips for recoding&lt;/h2&gt;
&lt;p&gt;Depending on what you’re doing, you may not want to overwrite the original data. Instead you might create a new variable that modifies the original.&lt;/p&gt;
&lt;p&gt;When you recode new variables, you can compare the new and old variables using the &lt;code&gt;table()&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;I try to consolidate all of my data cleaning tasks into as few calls to &lt;code&gt;mutate()&lt;/code&gt; as possible. This makes it easy to retrace your steps. In fact, I usually devote an entire &lt;code&gt;.R&lt;/code&gt; file in my project solely to cleaning the original data. Once the data are clean, I save a cleaned dataset, and then load the cleaned dataset in a separate &lt;code&gt;.R&lt;/code&gt; file for subsequent analyses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;variables-from-other-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Variables from other variables&lt;/h2&gt;
&lt;p&gt;Intuitively, you can create variables from other variables.&lt;/p&gt;
&lt;p&gt;Here, we calculate the ideological distance between one’s self placement and their placement of the two parties. We also calculate how far apart they perceive the parties to be. The sign of the result (&lt;span class=&#34;math inline&#34;&gt;\(+/-\)&lt;/span&gt;) indicates the ideological direction of the difference. Negative values indicate that respondents find themselves to be more liberal than a party, or that they find the Republican Party to be more liberal than the Democratic Party (which would be weird, but hey, that’s survey data for you).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anes &amp;lt;- mutate(anes, 
               dem_distance = libcon_self - libcon_demparty,
               rep_distance = libcon_self - libcon_repparty,
               party_distance = libcon_repparty - libcon_demparty)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;mutate()&lt;/code&gt; is great because you can create a variable in one line and use it in another line, without ending the &lt;code&gt;mutate()&lt;/code&gt; call.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;manipulating-factors-and-strings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Manipulating factors and strings&lt;/h2&gt;
&lt;p&gt;You should check out the &lt;code&gt;forcats&lt;/code&gt; and &lt;code&gt;stringr&lt;/code&gt; packages. They are tools for manipulating factors and character variables (a.k.a. “strings”), respectively, and are loaded when you load the &lt;code&gt;tidyverse&lt;/code&gt; package. We will revisit these when we discuss graphics in the next lesson, but the functions from these packages that I use the most are (using the &lt;code&gt;pkg::function&lt;/code&gt; notation)…&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;fct_relevel()&lt;/code&gt;: reorder the levels in a factor&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fct_recode()&lt;/code&gt;: recoding a factor, but &lt;code&gt;case_when&lt;/code&gt; works here also&lt;/li&gt;
&lt;li&gt;&lt;code&gt;str_sub()&lt;/code&gt;: extract a pattern from a string&lt;/li&gt;
&lt;li&gt;&lt;code&gt;str_split()&lt;/code&gt;: split a string at a certain character&lt;/li&gt;
&lt;li&gt;&lt;code&gt;str_detect()&lt;/code&gt;: returns &lt;code&gt;TRUE&lt;/code&gt; if a string contains a pattern&lt;/li&gt;
&lt;li&gt;&lt;code&gt;str_replace()&lt;/code&gt;: replace a pattern in a string with a different pattern&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Check online or investigate the help files to learn about how they’re used. We’ll see some examples next week when we do graphics.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;selecting-columns&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Selecting columns&lt;/h1&gt;
&lt;p&gt;Maybe you don’t need all these variables for something. You can select specific variables using the &lt;code&gt;select()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# from the anes dataset, grab only the cycle variable
select(anes, cycle)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 55,674 x 1
##    cycle
##    &amp;lt;dbl&amp;gt;
##  1  1948
##  2  1948
##  3  1948
##  4  1948
##  5  1948
##  6  1948
##  7  1948
##  8  1948
##  9  1948
## 10  1948
## # ... with 55,664 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are various “select helper” functions that aid us in selecting variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# select a series of variables in the data frame using `:` 
# grab cycle, and all variables between dem_distance and party_distance
select(anes, cycle, dem_distance:party_distance)

# select cycle and any variable containing &amp;quot;libcon&amp;quot; in the variable name
select(anes, cycle, contains(&amp;quot;libcon&amp;quot;))

# drop variables using negative sign `-`
# matches(&amp;quot;.&amp;quot;) means &amp;quot;all remaining variables&amp;quot;

# drop cycle, keep all remaining variables
select(anes, -cycle, matches(&amp;quot;.&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Learn more about “select helper functions” in the help file (&lt;code&gt;?select&lt;/code&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;filtering-rows-subsetting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Filtering rows (subsetting)&lt;/h1&gt;
&lt;p&gt;Let’s say we only want some of the observations. Use the &lt;code&gt;filter()&lt;/code&gt; function and a logical test to identify the cases you want.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# keep cases from 2012 cycle
filter(anes, cycle == 2012)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5,914 x 955
##    Version      cycle VCF0006 VCF0006a VCF0009x VCF0010x VCF0011x VCF0009y
##    &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
##  1 ANES_cdf_VE…  2012       1 20120001    0.380    0.380    0.380        0
##  2 ANES_cdf_VE…  2012       2 20120002    0.547    0.547    0.547        0
##  3 ANES_cdf_VE…  2012       3 20120003    0.498    0.498    0.498        0
##  4 ANES_cdf_VE…  2012       4 20120004    0.255    0.255    0.255        0
##  5 ANES_cdf_VE…  2012       5 20120005    0.603    0.603    0.603        0
##  6 ANES_cdf_VE…  2012       6 20120006    0.286    0.286    0.286        0
##  7 ANES_cdf_VE…  2012       7 20120007    0.195    0.195    0.195        0
##  8 ANES_cdf_VE…  2012       8 20120008    0.394    0.394    0.394        0
##  9 ANES_cdf_VE…  2012       9 20120009    0.506    0.506    0.506        0
## 10 ANES_cdf_VE…  2012      10 20120010    2.51     2.51     2.51         0
## # ... with 5,904 more rows, and 947 more variables: VCF0010y &amp;lt;dbl&amp;gt;,
## #   VCF0011y &amp;lt;dbl&amp;gt;, VCF0009z &amp;lt;dbl&amp;gt;, VCF0010z &amp;lt;dbl&amp;gt;, VCF0011z &amp;lt;dbl&amp;gt;,
## #   VCF0012 &amp;lt;dbl&amp;gt;, VCF0012a &amp;lt;dbl&amp;gt;, VCF0012b &amp;lt;dbl&amp;gt;, VCF0013 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0014 &amp;lt;dbl+lbl&amp;gt;, VCF0015a &amp;lt;dbl+lbl&amp;gt;, VCF0015b &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0016 &amp;lt;dbl+lbl&amp;gt;, VCF0017 &amp;lt;dbl+lbl&amp;gt;, VCF0018a &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0018b &amp;lt;dbl+lbl&amp;gt;, VCF0019 &amp;lt;dbl+lbl&amp;gt;, VCF0050a &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0050b &amp;lt;dbl+lbl&amp;gt;, VCF0070a &amp;lt;dbl+lbl&amp;gt;, VCF0070b &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0071a &amp;lt;dbl+lbl&amp;gt;, VCF0071b &amp;lt;dbl+lbl&amp;gt;, VCF0071c &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0071d &amp;lt;dbl+lbl&amp;gt;, VCF0072a &amp;lt;dbl+lbl&amp;gt;, VCF0072b &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0101 &amp;lt;dbl+lbl&amp;gt;, VCF0102 &amp;lt;dbl+lbl&amp;gt;, VCF0103 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0104 &amp;lt;dbl+lbl&amp;gt;, VCF0105a &amp;lt;dbl+lbl&amp;gt;, VCF0105b &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0106 &amp;lt;dbl+lbl&amp;gt;, VCF0107 &amp;lt;dbl+lbl&amp;gt;, VCF0108 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0109 &amp;lt;dbl+lbl&amp;gt;, VCF0110 &amp;lt;dbl+lbl&amp;gt;, VCF0111 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0112 &amp;lt;dbl+lbl&amp;gt;, VCF0113 &amp;lt;dbl+lbl&amp;gt;, VCF0114 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0115 &amp;lt;dbl+lbl&amp;gt;, VCF0116 &amp;lt;dbl+lbl&amp;gt;, VCF0117 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0118 &amp;lt;dbl+lbl&amp;gt;, VCF0119 &amp;lt;dbl+lbl&amp;gt;, VCF0120 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0121 &amp;lt;dbl+lbl&amp;gt;, VCF0122 &amp;lt;dbl+lbl&amp;gt;, VCF0123 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0124 &amp;lt;dbl+lbl&amp;gt;, VCF0125 &amp;lt;dbl+lbl&amp;gt;, VCF0126 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0126a &amp;lt;dbl+lbl&amp;gt;, VCF0126b &amp;lt;dbl+lbl&amp;gt;, VCF0126c &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0127 &amp;lt;dbl+lbl&amp;gt;, VCF0127a &amp;lt;dbl+lbl&amp;gt;, VCF0127b &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0128 &amp;lt;dbl+lbl&amp;gt;, VCF0128a &amp;lt;dbl+lbl&amp;gt;, VCF0128b &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0129 &amp;lt;dbl+lbl&amp;gt;, VCF0130 &amp;lt;dbl+lbl&amp;gt;, VCF0130a &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0131 &amp;lt;dbl+lbl&amp;gt;, VCF0132 &amp;lt;dbl+lbl&amp;gt;, VCF0133 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0134 &amp;lt;dbl+lbl&amp;gt;, VCF0135 &amp;lt;dbl+lbl&amp;gt;, VCF0136 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0137 &amp;lt;dbl+lbl&amp;gt;, VCF0138 &amp;lt;dbl+lbl&amp;gt;, VCF0138a &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0138b &amp;lt;dbl+lbl&amp;gt;, VCF0138c &amp;lt;dbl+lbl&amp;gt;, VCF0138d &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0138e &amp;lt;dbl+lbl&amp;gt;, VCF0139 &amp;lt;dbl+lbl&amp;gt;, VCF0140 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0140a &amp;lt;dbl+lbl&amp;gt;, VCF0141 &amp;lt;dbl+lbl&amp;gt;, VCF0142 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0143 &amp;lt;dbl+lbl&amp;gt;, VCF0144 &amp;lt;dbl+lbl&amp;gt;, VCF0145 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0146 &amp;lt;dbl+lbl&amp;gt;, VCF0147 &amp;lt;dbl+lbl&amp;gt;, VCF0148 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0148a &amp;lt;dbl+lbl&amp;gt;, VCF0149 &amp;lt;dbl+lbl&amp;gt;, VCF0150 &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0151 &amp;lt;dbl+lbl&amp;gt;, VCF0152 &amp;lt;dbl+lbl&amp;gt;, VCF0153a &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0153b &amp;lt;dbl+lbl&amp;gt;, VCF0153c &amp;lt;dbl+lbl&amp;gt;, VCF0154a &amp;lt;dbl+lbl&amp;gt;,
## #   VCF0154b &amp;lt;dbl+lbl&amp;gt;, …&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;summarizing&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Summarizing&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;summarize()&lt;/code&gt; will process multiple observations into summary statistics. This is also known as “collapsing” or “aggregating.”&lt;/p&gt;
&lt;p&gt;Find the mean ideological distance between the two parties (as judged by the respondents).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# data contain NAs so we use na.rm = TRUE
summarize(anes, 
          mean_party_distance_na = mean(party_distance, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   mean_party_distance_na
##                    &amp;lt;dbl&amp;gt;
## 1                   1.92&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;grouping-and-summarizing&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Grouping and summarizing&lt;/h1&gt;
&lt;p&gt;Most of the time you will use &lt;code&gt;summarize()&lt;/code&gt; in conjunction with &lt;code&gt;group_by()&lt;/code&gt;, which groups the data by some selection of variables. It doesn’t modify the cells in any way; it only implicitly partitions the data for later calculations.&lt;/p&gt;
&lt;p&gt;For instance, let’s say we want to do find the number of observations within each election year the above calculation but within each election year. The &lt;code&gt;n()&lt;/code&gt; function, when used inside of &lt;code&gt;summarize()&lt;/code&gt; or &lt;code&gt;mutate()&lt;/code&gt;, will find the number of observations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# group by cycle
s &amp;lt;- group_by(anes, cycle)

# summarize the grouped data
summarize(s, 
          n = n(),
          mean_party_distance = mean(party_distance, na.rm = TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 30 x 3
##    cycle     n mean_party_distance
##    &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;               &amp;lt;dbl&amp;gt;
##  1  1948   662                 NaN
##  2  1952  1899                 NaN
##  3  1954  1139                 NaN
##  4  1956  1762                 NaN
##  5  1958  1450                 NaN
##  6  1960  1181                 NaN
##  7  1962  1297                 NaN
##  8  1964  1571                 NaN
##  9  1966  1291                 NaN
## 10  1968  1557                 NaN
## # ... with 20 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A data frame can later be ungrouped with (wait for it…) &lt;code&gt;ungroup()&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sorting-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sorting data&lt;/h1&gt;
&lt;p&gt;Sort data frames using &lt;code&gt;arrange()&lt;/code&gt;. By default, sorting is done in ascending order. Sort variables in descending order using the &lt;code&gt;desc()&lt;/code&gt; function within &lt;code&gt;arrange()&lt;/code&gt;. You can also sort by multiple variables at once.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# keep cycle and party distance variables
# sort by cycle (descending order) and then by party distance
arr &amp;lt;- select(anes, cycle, party_distance) 
arrange(arr, desc(cycle), party_distance)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 55,674 x 2
##    cycle party_distance
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl+lbl&amp;gt;     
##  1  2012 -6            
##  2  2012 -6            
##  3  2012 -6            
##  4  2012 -6            
##  5  2012 -6            
##  6  2012 -6            
##  7  2012 -6            
##  8  2012 -6            
##  9  2012 -6            
## 10  2012 -6            
## # ... with 55,664 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Get a sense for the sorting precedence with this toy example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create some data to sort
d &amp;lt;- data_frame(x = c(1, 1, 2, 2), 
                y = c(1, 2, 1, 2))
d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 2
##       x     y
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1     1
## 2     1     2
## 3     2     1
## 4     2     2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sort by y and then by x (meaning, x within y)
arrange(d, y, x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 2
##       x     y
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1     1
## 2     2     1
## 3     1     2
## 4     2     2&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;joining-merging&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Joining (merging)&lt;/h1&gt;
&lt;p&gt;Merging is done with &lt;code&gt;join&lt;/code&gt; functions.&lt;/p&gt;
&lt;p&gt;Because the ANES is so big, this concept will be easier to demonstrate with a toy example. Create two datasets with some overlapping cases and some non-overlapping cases:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# cases 2 and 3 appear in both data sets
# cases 1 and 4 exist in one dataset but not the other
(data1 &amp;lt;- data_frame(case = 1:3, 
                     var1 = c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##    case var1 
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;
## 1     1 a    
## 2     2 b    
## 3     3 c&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(data2 &amp;lt;- data_frame(case = 2:4, 
                     var2 = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;, &amp;quot;z&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##    case var2 
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;
## 1     2 x    
## 2     3 y    
## 3     4 z&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We want to put these datasets together into one table, matching data to the appropriate cases.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;full_join()&lt;/code&gt; function keeps all cases from both datasets. Non-matching cells are filled with &lt;code&gt;NA&lt;/code&gt; by default, but you can specify replacement values for non-matches if you wish.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# join all cases, keep non-matches
full_join(data1, data2, by = &amp;quot;case&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 3
##    case var1  var2 
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1     1 a     &amp;lt;NA&amp;gt; 
## 2     2 b     x    
## 3     3 c     y    
## 4     4 &amp;lt;NA&amp;gt;  z&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can merge along multiple variables using &lt;code&gt;by = c(&amp;quot;var1&amp;quot;, &amp;quot;var2&amp;quot;, ...)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;left_join()&lt;/code&gt; keeps all cases from left dataset. If the right dataset can’t fill a cell in the left dataset, the result is &lt;code&gt;NA&lt;/code&gt;. If the right dataset has other cases that aren’t present in the left, they disappear.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# keep left data in tact, 
# merge only matching cases from right data
left_join(data1, data2, by = &amp;quot;case&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##    case var1  var2 
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1     1 a     &amp;lt;NA&amp;gt; 
## 2     2 b     x    
## 3     3 c     y&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;right_join()&lt;/code&gt; is the mirror of &lt;code&gt;left_join&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;right_join(data1, data2, by = &amp;quot;case&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##    case var1  var2 
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1     2 b     x    
## 2     3 c     y    
## 3     4 &amp;lt;NA&amp;gt;  z&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;inner_join()&lt;/code&gt; keeps only cases with matches in both datasets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# keep only matching cases, drop everything else
inner_join(data1, data2, by = &amp;quot;case&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##    case var1  var2 
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1     2 b     x    
## 2     3 c     y&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;anti_join()&lt;/code&gt; is a little funky and different. It keeps only the &lt;em&gt;unmatched&lt;/em&gt; cases from the left dataset only. This is helpful for diagnosing a problem with an imperfect attempt to join two data frames.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# what doesn&amp;#39;t match?
anti_join(data1, data2, by = &amp;quot;case&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##    case var1 
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;
## 1     1 a&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anti_join(data2, data1, by = &amp;quot;case&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##    case var2 
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;
## 1     4 z&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tabulating&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tabulating&lt;/h1&gt;
&lt;p&gt;Here are two ways to tabulate data: &lt;code&gt;table()&lt;/code&gt; and &lt;code&gt;count()&lt;/code&gt;. &lt;code&gt;table()&lt;/code&gt; produces a table object; &lt;code&gt;count()&lt;/code&gt; produces a data frame.&lt;/p&gt;
&lt;div id=&#34;table&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;table()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;First, &lt;code&gt;table()&lt;/code&gt;. The &lt;code&gt;exclude = NULL&lt;/code&gt; argument will force R to print the number of missing values (which it does not do by default).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table(anes$libcon_self, exclude = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##     1     2     3     4     5     6     7  &amp;lt;NA&amp;gt; 
##   750  3138  3603  9873  5304  5379   995 26632&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Turn frequencies into proportions by wrapping a table object with &lt;code&gt;prop.table()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop.table(table(anes$libcon_self, exclude = NULL))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##          1          2          3          4          5          6 
## 0.01347128 0.05636383 0.06471603 0.17733592 0.09526889 0.09661601 
##          7       &amp;lt;NA&amp;gt; 
## 0.01787190 0.47835614&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can round these proportions to get more manageable values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# round to 3 decimal positions
round(prop.table(table(anes$libcon_self, exclude = NULL)), 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##     1     2     3     4     5     6     7  &amp;lt;NA&amp;gt; 
## 0.013 0.056 0.065 0.177 0.095 0.097 0.018 0.478&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice how these are nested functions, like &lt;span class=&#34;math inline&#34;&gt;\(f(g(h(x)))\)&lt;/span&gt;. This is the kind of flexibility that we like about R.&lt;/p&gt;
&lt;p&gt;To make two-way tables, the first variable prints as rows, and the second as columns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# pid7 as rows, libcon_self as columns
table(anes$pid7, anes$libcon_self, exclude = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       
##           1    2    3    4    5    6    7 &amp;lt;NA&amp;gt;
##   1     360 1392  848 1696  455  433  131 5490
##   2     109  643 1018 2109  799  431   72 6080
##   3     165  609  795 1552  451  251   42 2531
##   4      64  188  287 1552  502  337   84 3395
##   5      17  115  257 1083  991  847  135 1937
##   6      14   92  280 1275 1362 1009  107 3274
##   7      16   78   97  550  725 2049  418 2421
##   &amp;lt;NA&amp;gt;    5   21   21   56   19   22    6 1504&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By default, &lt;code&gt;prop.table()&lt;/code&gt; estimates proportions out of the entire table. To estimate proportions within rows or columns, use the &lt;code&gt;margin&lt;/code&gt; argument (&lt;code&gt;margin = 1&lt;/code&gt; for the fraction within a row, &lt;code&gt;margin = 2&lt;/code&gt; for the fraction within a column).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# two-way table
tab &amp;lt;- table(anes$pid7, anes$libcon_self, exclude = NULL)

# proportions as fractions of each row
ptab &amp;lt;- prop.table(tab, margin = 1)

# round the result
round(ptab, 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       
##            1     2     3     4     5     6     7  &amp;lt;NA&amp;gt;
##   1    0.033 0.129 0.078 0.157 0.042 0.040 0.012 0.508
##   2    0.010 0.057 0.090 0.187 0.071 0.038 0.006 0.540
##   3    0.026 0.095 0.124 0.243 0.071 0.039 0.007 0.396
##   4    0.010 0.029 0.045 0.242 0.078 0.053 0.013 0.530
##   5    0.003 0.021 0.048 0.201 0.184 0.157 0.025 0.360
##   6    0.002 0.012 0.038 0.172 0.184 0.136 0.014 0.442
##   7    0.003 0.012 0.015 0.087 0.114 0.322 0.066 0.381
##   &amp;lt;NA&amp;gt; 0.003 0.013 0.013 0.034 0.011 0.013 0.004 0.909&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;count&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;count()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;If you want your table to be organized as a data frame (which you often do want), use &lt;code&gt;count()&lt;/code&gt;. This is nice for doing further calculations, exporting results (e.g. to &lt;span class=&#34;math inline&#34;&gt;\({\mathrm{\LaTeX}}\)&lt;/span&gt;), and so on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# from the anes data, count the intersections of cycle and party ID
count(anes, cycle, pid7)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 233 x 3
##    cycle pid7          n
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl+lbl&amp;gt; &amp;lt;int&amp;gt;
##  1  1948 &amp;lt;NA&amp;gt;        662
##  2  1952 1           392
##  3  1952 2           435
##  4  1952 3           173
##  5  1952 4            83
##  6  1952 5           128
##  7  1952 6           237
##  8  1952 7           241
##  9  1952 &amp;lt;NA&amp;gt;        210
## 10  1954 1           248
## # ... with 223 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This contains the same information as &lt;code&gt;table(anes\$cycle, anes\$pid7)&lt;/code&gt;, but the result is a “tidy” data frame.&lt;/p&gt;
&lt;p&gt;To get proportions, mutate the resulting table as desired. Here we get the proportion of each partisan identity within each election cycle. Group on the cycle and then dividing each count by the number of individuals in each cycle.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# tabulate these variables, party by cycle
(tab &amp;lt;- count(anes, cycle, pid7))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 233 x 3
##    cycle pid7          n
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl+lbl&amp;gt; &amp;lt;int&amp;gt;
##  1  1948 &amp;lt;NA&amp;gt;        662
##  2  1952 1           392
##  3  1952 2           435
##  4  1952 3           173
##  5  1952 4            83
##  6  1952 5           128
##  7  1952 6           237
##  8  1952 7           241
##  9  1952 &amp;lt;NA&amp;gt;        210
## 10  1954 1           248
## # ... with 223 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# group by cycle
# find n per cycle
# divide counts by n_in_cycle
# round
mutate(group_by(tab, cycle), 
       n_in_cycle = sum(n, na.rm = TRUE),
       p = n / n_in_cycle,
       p = round(p, 3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 233 x 5
## # Groups:   cycle [30]
##    cycle pid7          n n_in_cycle     p
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl+lbl&amp;gt; &amp;lt;int&amp;gt;      &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
##  1  1948 &amp;lt;NA&amp;gt;        662        662 1    
##  2  1952 1           392       1899 0.206
##  3  1952 2           435       1899 0.229
##  4  1952 3           173       1899 0.091
##  5  1952 4            83       1899 0.044
##  6  1952 5           128       1899 0.067
##  7  1952 6           237       1899 0.125
##  8  1952 7           241       1899 0.127
##  9  1952 &amp;lt;NA&amp;gt;        210       1899 0.111
## 10  1954 1           248       1139 0.218
## # ... with 223 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;count()&lt;/code&gt; function also handles sample weights.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# keep only elections since 2000
# tabulate cycle and party
# apply sample weights
count(filter(anes, cycle &amp;gt;= 2000), 
      cycle, pid7, 
      wt = VCF0009z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 40 x 3
##    cycle pid7          n
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl+lbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1  2000 1         345. 
##  2  2000 2         274. 
##  3  2000 3         275. 
##  4  2000 4         237. 
##  5  2000 5         231. 
##  6  2000 6         207. 
##  7  2000 7         221. 
##  8  2000 &amp;lt;NA&amp;gt;       16.5
##  9  2002 1         246. 
## 10  2002 2         250. 
## # ... with 30 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The “counts” are no longer whole numbers, thanks to the survey weights (some people count as “partial observations” due to sample design).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;tidyr-functions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tidyr functions&lt;/h1&gt;
&lt;p&gt;This concludes today’s foray into the &lt;code&gt;dplyr&lt;/code&gt; family of functions. Now we’ll switch to the &lt;code&gt;tidyr&lt;/code&gt; functions. The main difference is that &lt;code&gt;dplyr&lt;/code&gt; tends to &lt;em&gt;change&lt;/em&gt; data while &lt;code&gt;tidyr&lt;/code&gt; simply moves it around.&lt;/p&gt;
&lt;p&gt;We’ll talk about “wide” and “long” data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wide data might be data from multiple time periods, where variables from different time periods are represented as different columns. So we might have different &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; variables from three different time periods as columns named &lt;code&gt;x1&lt;/code&gt;, &lt;code&gt;x2&lt;/code&gt;, &lt;code&gt;x3&lt;/code&gt;, &lt;code&gt;y1&lt;/code&gt;, &lt;code&gt;y2&lt;/code&gt;, &lt;code&gt;y3&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Long data would have the same information as the wide data, but instead of different variables for time periods, we stack the time periods on top of one another into one variable. So we would have variables for &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; as well as a &lt;code&gt;time_period&lt;/code&gt; variable to indicate which observations come from which wave.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When we shape data, what we’re really doing is moving data around (also called “reshaping”) to make it long (elongating) or wide (widening).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reshape-wide-to-long-with-gather&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Reshape wide to long, with &lt;code&gt;gather()&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Gathering will take multiple columns and stack the cells into one variable (with an accompanying variable for labeling).&lt;/p&gt;
&lt;p&gt;Here is an example using the ideological distance variables from above. First we have to prep some data so we can see how this works.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# keep only certain variables
d &amp;lt;- select(anes, cycle, dem_distance, rep_distance)

# keep certain election years
d &amp;lt;- filter(d, cycle %in% c(2004, 2008, 2012))

# get mean in each year
d &amp;lt;- summarize(group_by(d, cycle), 
               dem_distance = mean(dem_distance, na.rm = TRUE),
               rep_distance = mean(rep_distance, na.rm = TRUE))

# show results
d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##   cycle dem_distance rep_distance
##   &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1  2004         1.41        -1.05
## 2  2008         1.09        -1.01
## 3  2012         1.54        -1.23&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll gather the two distance variables into one variable, with another variable to indicate which party we’re contrasting from.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# gather(data, resulting key, resulting value, initial varlist)
l &amp;lt;- gather(d, key = party, value = distance, dem_distance, rep_distance)
l&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   cycle party        distance
##   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1  2004 dem_distance     1.41
## 2  2008 dem_distance     1.09
## 3  2012 dem_distance     1.54
## 4  2004 rep_distance    -1.05
## 5  2008 rep_distance    -1.01
## 6  2012 rep_distance    -1.23&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Select helper functions also work for selecting which variables to gather.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# gather(data, key, value, varlist)
gather(d, key = party, value = distance, contains(&amp;quot;distance&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   cycle party        distance
##   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1  2004 dem_distance     1.41
## 2  2008 dem_distance     1.09
## 3  2012 dem_distance     1.54
## 4  2004 rep_distance    -1.05
## 5  2008 rep_distance    -1.01
## 6  2012 rep_distance    -1.23&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reshaping-long-to-wide-with-spread&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Reshaping long to wide, with &lt;code&gt;spread()&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;Spreading is the opposite of gathering. It takes a column and unstacks it into several columns. We need a corresponding label variable also, which becomes the variable names. Observe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;l&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   cycle party        distance
##   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1  2004 dem_distance     1.41
## 2  2008 dem_distance     1.09
## 3  2012 dem_distance     1.54
## 4  2004 rep_distance    -1.05
## 5  2008 rep_distance    -1.01
## 6  2012 rep_distance    -1.23&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# &amp;#39;key&amp;#39; variable becomes new variable names. 
# &amp;#39;value&amp;#39; variable becomes new variable values
spread(l, key = party, value = distance) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 3
##   cycle dem_distance rep_distance
##   &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1  2004         1.41        -1.05
## 2  2008         1.09        -1.01
## 3  2012         1.54        -1.23&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;piping-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Piping data&lt;/h1&gt;
&lt;p&gt;This section is &lt;em&gt;extremely important&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Now that we have covered some essential tools for wrangling data, let’s tie it all together with the concept of &lt;strong&gt;&lt;em&gt;piping&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Let’s start by identifying the problem. Data processing requires a lot of steps (each represented by the functions we have learned so far). Many of these steps are related. Can we string these operations together in a way that is easy to understand and easy to write?&lt;/p&gt;
&lt;p&gt;One (suboptimal) way to sew multiple operations together is with nested functions. Just as we can nest functions in math like &lt;span class=&#34;math inline&#34;&gt;\(f(g(h(x)))\)&lt;/span&gt;, we can also do this with R. The problem with this is that the order of operations creates an unintuitive reading experience—we have to read from the inside out. The code becomes ugly and difficult to interpret.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# this works, and it follows order of operations, but it&amp;#39;s annoying
tidy_data &amp;lt;- gather(summarize(group_by(filter(select(dataset, ...), ...), ...), ...), ...)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another (suboptimal) way would be to break up the operation into multiple lines. The problem with this method is that it is verbose and creates a lot of redundancy with object assignment (which can slow down your code with big datasets).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# each function takes the results from the previous function
# this also works, but requires overwriting the data a lot
# and lots of redundant `d &amp;lt;- ` instances
d &amp;lt;- select(dataset, ...)
d &amp;lt;- filter(d, ...)
d &amp;lt;- group_by(d, ...)
d &amp;lt;- summarize(d, ...)
d &amp;lt;- gather(d, ...)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll use the &lt;em&gt;pipe operator&lt;/em&gt; &lt;code&gt;%&amp;gt;%&lt;/code&gt; to make this process easier. The pipe operator takes a left-hand side object and “pipes” it into a right-hand side function. It sounds trivial, but just wait.&lt;/p&gt;
&lt;p&gt;Here is how it works. We’ll use &lt;code&gt;x&lt;/code&gt; to represent data and &lt;code&gt;f&lt;/code&gt; to represent functions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;By default, &lt;code&gt;x %&amp;gt;% f()&lt;/code&gt; sets &lt;code&gt;x&lt;/code&gt; as the first argument in &lt;code&gt;f&lt;/code&gt;. So &lt;code&gt;f(x)&lt;/code&gt; is equivalent to &lt;code&gt;x %&amp;gt;% f()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If &lt;code&gt;x&lt;/code&gt; is needed elsewhere inside of &lt;code&gt;f&lt;/code&gt; besides the first argument, we can use &lt;code&gt;.&lt;/code&gt; to stand-in for &lt;code&gt;x&lt;/code&gt;. For example, &lt;code&gt;f(arguments, data = x)&lt;/code&gt; is equivalent to &lt;code&gt;x %&amp;gt;% f(arguments, data = .)&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If only one argument is needed, you can drop the parentheses on &lt;code&gt;f()&lt;/code&gt;. So &lt;code&gt;f(x)&lt;/code&gt; is equivalent to &lt;code&gt;x %&amp;gt;% f()&lt;/code&gt;, which is equivalent to &lt;code&gt;x %&amp;gt;% f&lt;/code&gt;. I would recommend you keep the parentheses, however, because it’s easier to see which names are associated with data and which names are associated with functions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The pipe operator allows you to do multiple dataset operations in a &lt;em&gt;linear&lt;/em&gt; fashion without creating a ton of intermediary objects. The above processing task could be written as the following “pipe chain.”&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# take `dataset` object and pass it to select
# the result from select is passed to filter
# and so on
d &amp;lt;- dataset %&amp;gt;%
  select(...) %&amp;gt;%
  filter(...) %&amp;gt;%
  group_by(...) %&amp;gt;%
  summarize(...) %&amp;gt;%
  gather(...) %&amp;gt;%
  print() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Adding &lt;code&gt;print()&lt;/code&gt; at the end of the chain will print the results even if you are assigning the results to &lt;code&gt;d&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;What has the pipe chain done? It has made our code linear and readable, and it makes our workflow more straightforward because we can &lt;em&gt;think&lt;/em&gt; linearly again. Reading a complex set of operations linearly isn’t normally something you can easily do with programming, so we should really appreciate this!&lt;/p&gt;
&lt;p&gt;Here’s an example using real data. The pipe chain makes it extremely easy to understand exactly what the code is doing.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# start with anes
#   keep certain variables
#   keep certain observations
#   group and summarize
#   gather
#   print result of the chain
l &amp;lt;- anes %&amp;gt;%
  select(cycle, contains(&amp;quot;distance&amp;quot;)) %&amp;gt;%
  filter(cycle %in% c(2004, 2008, 2012)) %&amp;gt;%
  group_by(cycle) %&amp;gt;%
  summarize(n = n(),
            Democratic = mean(dem_distance, na.rm = TRUE),
            Republican = mean(rep_distance, na.rm = TRUE)) %&amp;gt;%
  ungroup() %&amp;gt;%
  gather(key = party, value = distance, Democratic, Republican) %&amp;gt;%
  print() &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
##   cycle     n party      distance
##   &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;
## 1  2004  1212 Democratic     1.41
## 2  2008  2322 Democratic     1.09
## 3  2012  5914 Democratic     1.54
## 4  2004  1212 Republican    -1.05
## 5  2008  2322 Republican    -1.01
## 6  2012  5914 Republican    -1.23&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can use pipes to simplify other tasks from earlier in this lesson, like processing a table using proportions and rounding but without all of the nested functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create a table
# send table to prop.table to calculate proportions
# send proportions to round() 
table(anes$pid7, anes$libcon_self, exclude = NULL) %&amp;gt;% 
  prop.table(margin = 1) %&amp;gt;%
  round(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       
##            1     2     3     4     5     6     7  &amp;lt;NA&amp;gt;
##   1    0.033 0.129 0.078 0.157 0.042 0.040 0.012 0.508
##   2    0.010 0.057 0.090 0.187 0.071 0.038 0.006 0.540
##   3    0.026 0.095 0.124 0.243 0.071 0.039 0.007 0.396
##   4    0.010 0.029 0.045 0.242 0.078 0.053 0.013 0.530
##   5    0.003 0.021 0.048 0.201 0.184 0.157 0.025 0.360
##   6    0.002 0.012 0.038 0.172 0.184 0.136 0.014 0.442
##   7    0.003 0.012 0.015 0.087 0.114 0.322 0.066 0.381
##   &amp;lt;NA&amp;gt; 0.003 0.013 0.013 0.034 0.011 0.013 0.004 0.909&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although we covered piping last, you should not view it as afterthought. The pipe operator will change the way you use R forever.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tips-for-piping&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tips for piping&lt;/h1&gt;
&lt;div id=&#34;create-a-keyboard-shortcut&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Create a keyboard shortcut&lt;/h2&gt;
&lt;p&gt;If your text editor has the capability, &lt;em&gt;create a keyboard shortcut for the pipe operator!&lt;/em&gt; I create this kind of thing with Sublime Text all the time. Rstudio can do it as well. Here’s what I do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;super + .&lt;/code&gt; creates a pipe&lt;/li&gt;
&lt;li&gt;&lt;code&gt;super + shift + .&lt;/code&gt; creates a pipe and adds a new line&lt;/li&gt;
&lt;li&gt;relatedly, I use &lt;code&gt;super + shift + ,&lt;/code&gt; to create an assignment operator (&lt;code&gt;&amp;lt;-&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;other-helpful-pipes&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Other helpful pipes&lt;/h2&gt;
&lt;p&gt;There is one other helpful pipe-like operator that we will talk about: &lt;code&gt;%$%&lt;/code&gt;. It tells a right-hand function that the variable names in the function come from the left-hand dataset. It doesn’t pipe the entire dataset per se; it only says “look here for variable names.” The two following commands do the same thing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# look in anes for pid7 variable
table(anes$pid7)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##     1     2     3     4     5     6     7 
## 10805 11261  6396  6409  5382  7413  6354&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# look in anes for pid7 variable
anes %$% table(pid7)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## pid7
##     1     2     3     4     5     6     7 
## 10805 11261  6396  6409  5382  7413  6354&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is useful when you need to reference multiple variables.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# notice which pipe I use after &amp;#39;anes&amp;#39;
# %$% for piping just variable names
# %&amp;gt;% for piping the entire object

anes %$% 
  table(pid7, libcon_self, exclude = NULL) %&amp;gt;% 
  prop.table(margin = 1) %&amp;gt;%
  round(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       libcon_self
## pid7       1     2     3     4     5     6     7  &amp;lt;NA&amp;gt;
##   1    0.033 0.129 0.078 0.157 0.042 0.040 0.012 0.508
##   2    0.010 0.057 0.090 0.187 0.071 0.038 0.006 0.540
##   3    0.026 0.095 0.124 0.243 0.071 0.039 0.007 0.396
##   4    0.010 0.029 0.045 0.242 0.078 0.053 0.013 0.530
##   5    0.003 0.021 0.048 0.201 0.184 0.157 0.025 0.360
##   6    0.002 0.012 0.038 0.172 0.184 0.136 0.014 0.442
##   7    0.003 0.012 0.015 0.087 0.114 0.322 0.066 0.381
##   &amp;lt;NA&amp;gt; 0.003 0.013 0.013 0.034 0.011 0.013 0.004 0.909&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;saving-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Saving data&lt;/h1&gt;
&lt;p&gt;You can write or save data from R with many &lt;code&gt;write.xyz&lt;/code&gt; or &lt;code&gt;save.xyz&lt;/code&gt; functions. I usually prefer to save data in an R-specific format.&lt;/p&gt;
&lt;p&gt;You should save the data from this lesson so we can come back to it next week.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;saveRDS(anes, &amp;quot;data/anes-modified.RDS&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If it’s possible that someone using Stata (or some other software) might be using your data, you might save in a more accessible format such as &lt;code&gt;.csv&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;write_csv(anes, &amp;quot;data/anes-modified.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R can read and save to a multitude of file types, including &lt;code&gt;.dta&lt;/code&gt; for Stata. R could put Stat/Transfer out of business if more people knew about it.&lt;/p&gt;
&lt;p&gt;Some packages provide “swiss-army-knife” data input/output services, such as the &lt;code&gt;import()&lt;/code&gt; and &lt;code&gt;export()&lt;/code&gt; functions in Thomas Leeper’s &lt;code&gt;rio&lt;/code&gt; package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;looking-forward&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Looking forward&lt;/h1&gt;
&lt;p&gt;Make sure you are comfortable with piping, &lt;code&gt;dplyr&lt;/code&gt;, and &lt;code&gt;tidyr&lt;/code&gt; before beginning the &lt;a href=&#34;811/811-graphics&#34;&gt;lesson on graphics&lt;/a&gt;, because we will use those concepts throughout.&lt;/p&gt;
&lt;p&gt;There are some other common data-munging tasks that we will put off until the final lesson:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Writing your own functions&lt;/li&gt;
&lt;li&gt;Loops (and why you should not use them)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;apply()&lt;/code&gt; functions (and why you should use them instead of loops)&lt;/li&gt;
&lt;li&gt;Nesting and mapping, a tidy (and parallel!) method for applying complex functions across many datasets at once.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;postscript-on-coding-style&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Postscript on coding style&lt;/h1&gt;
&lt;p&gt;I would talk about coding style, but others can probably do that better than I can (though you can check the R scripts on Canvas for do-as-I-do examples). You can find lots of style guides for R online. They will broadly agree on how to write R with good style, but they won’t agree on every fine point. Here are some that I endorse:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a &lt;a href=&#34;http://adv-r.had.co.nz/Style.html&#34;&gt;short style guide&lt;/a&gt; by Hadley Wickham that will put you on the right track&lt;/li&gt;
&lt;li&gt;a &lt;a href=&#34;http://style.tidyverse.org/&#34;&gt;longer style guide&lt;/a&gt; (again by Wickham) that has general style guidance but also guidance specifically for working with the &lt;code&gt;tidyverse&lt;/code&gt;, for those who want to be a little more obsessive about their programming style&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Getting Started with R</title>
      <link>/811/811-basics/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/811/811-basics/</guid>
      <description>&lt;div id=&#34;schedule&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Schedule:&lt;/h1&gt;
&lt;p&gt;Read this before our first R lecture.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-follow-along&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to follow along&lt;/h1&gt;
&lt;p&gt;Follow the instructions in this lesson in &lt;em&gt;your own&lt;/em&gt; &lt;code&gt;.R&lt;/code&gt; script.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;objectives&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Objectives&lt;/h1&gt;
&lt;p&gt;This document describes how to get started with R and understand its basics. We discuss installing R, running simple commands, and some elementary programming concepts such as indexing, logic, and functions. We close with some higher-level discussion about the differences between R and Stata.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Although I promised concrete lessons, this one unfortunately has to be a little more “abstract” than others. This is because we exploring R’s &lt;em&gt;general&lt;/em&gt; behavior rather than a concrete application of R workflow. Luckily, this will be short, and we get much more concrete in future lessons.&lt;/p&gt;
&lt;p&gt;You should take this lesson slowly at first if you have not played with R before. Mess around with some of the code if it helps you understand what it’s doing. Type it yourself bit by bit, so you can see what each component does. If you encounter material that does not make sense, please take note of it so we can review it in class before progressing too far.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-read-these-lessons&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to read these lessons&lt;/h1&gt;
&lt;p&gt;Pages in this series contain code blocks that you can paste into R. Some of the code blocks are included with their results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;quot;Code appears in blocks like this.&amp;quot;
&amp;quot;You can paste this code directly into R.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Results appear on this page with two &amp;#39;##&amp;#39; signs on the left&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;installing-r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Installing R&lt;/h1&gt;
&lt;p&gt;If you have not set up R already, click &lt;a href=&#34;https://mirror.las.iastate.edu/CRAN/&#34;&gt;here&lt;/a&gt; to download R for your operating system (if you haven’t already).&lt;/p&gt;
&lt;p&gt;A little bit about what’s going on here: R is open source and is distributed from various &lt;a href=&#34;https://en.wikipedia.org/wiki/Mirror_website&#34;&gt;“mirrors,”&lt;/a&gt; which are clone websites that contain essentially identical information. The CRAN (Comprehensive R Archive Network) hosts these mirrors &lt;a href=&#34;https://cran.r-project.org/mirrors.html&#34;&gt;all over the world&lt;/a&gt;. It is generally recommended that you install R (and related software like R packages) using mirrors in nearby locations. Any mirror in the U.S. should be fine for our purposes. The link at the top of this section uses the Iowa State University mirror.&lt;/p&gt;
&lt;p&gt;Once R is downloaded, make sure that it is fully installed. You can run R using the GUI app (&lt;code&gt;R.app&lt;/code&gt; on OSX or &lt;code&gt;Rgui.exe&lt;/code&gt; on Windows), using the Rstudio application (which we discuss below), or as a program in your computer’s command-line shell (which I do, for technical reasons).&lt;/p&gt;
&lt;p&gt;If you have a Chromebook or some other computing machine that makes it impossible to install R, try the &lt;a href=&#34;https://rstudio.cloud/&#34;&gt;Rstudio Cloud&lt;/a&gt; platform.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Using R&lt;/h1&gt;
&lt;p&gt;The most essential part of using R is the &lt;em&gt;console&lt;/em&gt;. This is where results of all commands are displayed. There is a prompt at the bottom of the console where commands can be submitted directly. Yours won’t be the same colors as mine, but it looks sort of like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/811/r-console.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Although you can type commands directly into the console, most commands should be written in a &lt;em&gt;script file&lt;/em&gt;. Script files serve the same purpose as they do in Stata; they provide a record of all commands you want to run in your analysis. This lets you replicate your analysis the next day, the next week, the next year, or whenever (presuming your code does not become obsolete for some reason).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;editing-an-r-script-file&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Editing an R script file&lt;/h1&gt;
&lt;p&gt;Script files in R are similar to Stata. They are a place where your code should live, and you should execute code by sending it to the console to be evaluated.&lt;/p&gt;
&lt;p&gt;Use whatever program you desire to open a script file.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The basic R application has a script editor (accessed using the &lt;code&gt;File&lt;/code&gt; menu or a keyboard shortcut).&lt;/li&gt;
&lt;li&gt;Many newcomers enjoy &lt;a href=&#34;https://www.rstudio.com/products/rstudio/&#34;&gt;Rstudio&lt;/a&gt; an application that provides tons of tools for R. Rstudio has many advanced features as well, so it isn’t only for newcomers.&lt;/li&gt;
&lt;li&gt;You can also use third-party editors, but you will need to figure out how to send commands to the R console. I use &lt;a href=&#34;https://www.sublimetext.com/&#34;&gt;Sublime Text&lt;/a&gt; with the &lt;a href=&#34;https://packagecontrol.io/packages/R-Box&#34;&gt;R-Box package&lt;/a&gt; to send commands to R.&lt;/li&gt;
&lt;li&gt;Windows users may find Notepad++ or TextMate to be useful text editors.&lt;/li&gt;
&lt;li&gt;Advanced programmers may use Emacs or Vim with some package (such as ESS for Emacs) to speak to an R console.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I would recommend any external editor that can send commands to the R console and, as you become more comfortable with R, that contains some keyboard shortcuts for writing code quickly. Rstudio, it so happens, comes standard with many such shortcuts.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-goes-in-an-r-file-code-and-comments&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What goes in an R file (code and comments)&lt;/h1&gt;
&lt;p&gt;Script files should begin with some description of the script’s purpose. You can include comments (text that will not be executed as R commands) after the &lt;code&gt;#&lt;/code&gt; symbol. For example, your script file for this lesson might contain some comments at the top like…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ------------------------------------------------------------
#  PS 811: statistical computing for political science
#  Lesson 1: Basics of R
# ------------------------------------------------------------&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Comments are great for describing what code is doing, planning an analysis, writing notes to yourself, and so on. Comments are also great for &lt;em&gt;pseudocode&lt;/em&gt;, which are notes to yourself that “translate” what code is doing into English. We will see some examples of this as the course progresses.&lt;/p&gt;
&lt;p&gt;An R script file may begin with some common operations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setting a working directory (see the next lesson)&lt;/li&gt;
&lt;li&gt;setting up a log file (if desired… I don’t do this though!)&lt;/li&gt;
&lt;li&gt;Loading packages for extra functionality&lt;/li&gt;
&lt;li&gt;Setting other project-wide options (e.g. graphics options)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although a script file can be imperfect while a project is being developed, a well-written script file for a finished project should be organized, easy to read, and run from top to bottom without any errors. This is important for ensuring that you can retrace the steps of your analysis.&lt;/p&gt;
&lt;p&gt;We should save this file in a designated location for this course. Navigate to your &lt;code&gt;ps811&lt;/code&gt; folder on your computer (which you should already have…), create a subfolder called &lt;code&gt;R&lt;/code&gt;, and then within the R folder, create another &lt;code&gt;lessons&lt;/code&gt; folder. Save this document in the &lt;code&gt;ps811/R/lessons/&lt;/code&gt; folder. (This syntax represents folder pathways in your computer’s file system. We’ll be seeing more of this later.)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;executing-commands&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Executing commands&lt;/h1&gt;
&lt;p&gt;Just like Stata, R processes commands one at a time. Commands are compiled while they are executed, so if something is wrong with your code, you may not realize it until you try to run it.&lt;/p&gt;
&lt;p&gt;Just to demonstrate some basic R behavior, let’s run a few commands.&lt;/p&gt;
&lt;p&gt;First, R works as a calculator. It can handle mathematical expressions. Paste or type the following lines of code DIRECTLY into the console.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1 + 1
2 + 2
100 * 2
500 / 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ignore the &lt;code&gt;[1]&lt;/code&gt; that prints in the results for now. We will explain it later.&lt;/p&gt;
&lt;p&gt;Now take the above block of code and paste the commands into your script file. Try to run the commands from the script file using the appropriate keyboard shortcut. Most computers and interfaces use &lt;code&gt;super + enter&lt;/code&gt;, where &lt;code&gt;super&lt;/code&gt; refers to &lt;code&gt;Ctrl&lt;/code&gt; on PCs or &lt;code&gt;Cmd&lt;/code&gt; on Macs. Windows machines may use a different shortcut, such as &lt;code&gt;Ctrl + R&lt;/code&gt;. Take this opportunity to look up the appropriate keyboard shortcut on your own, &lt;em&gt;before coming to lecture!&lt;/em&gt; :-)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;variables-and-assignment&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Variables and assignment&lt;/h1&gt;
&lt;p&gt;Most of your R code will work with variables rather than raw numbers. Variables generally work the same way they do with math. The expression &lt;span class=&#34;math inline&#34;&gt;\(x + 4\)&lt;/span&gt; can take different values, depending on the value of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Data must be “assigned” to a variable using the assignment operator &lt;code&gt;&amp;lt;-&lt;/code&gt;. The &lt;code&gt;&amp;lt;-&lt;/code&gt; is a combination of a less-than sign &lt;code&gt;&amp;lt;&lt;/code&gt; and a hyphen &lt;code&gt;-&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example, assign the value of &lt;code&gt;5&lt;/code&gt; to a variable called &lt;code&gt;x&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After this variable has been created, &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;5&lt;/code&gt; mean the same thing as far as R is concerned.&lt;/p&gt;
&lt;p&gt;You can read the &lt;code&gt;&amp;lt;-&lt;/code&gt; operator as “gets.” A left-hand side object name “gets” the results of whatever operation is on the right-hand side. So in the above example, &lt;code&gt;x&lt;/code&gt; “gets” the value of 5.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;printing-the-contents-of-an-object&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Printing the contents of an object&lt;/h1&gt;
&lt;p&gt;We can display the contents of any object in R by simply typing the object name.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That is to say, R “evaluated” the statement &lt;code&gt;x&lt;/code&gt;, and the result is 5. We could have written some more complex statement for R to evaluate, like a mathematical expression using &lt;code&gt;x&lt;/code&gt;…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x + 4&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;vectors-multi-element-variables&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Vectors: multi-element variables&lt;/h1&gt;
&lt;p&gt;Most of the variables you will work with in R (such as the variables in a data set) have multiple values. That is, they are &lt;em&gt;vectors&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We can create our own vectors with &lt;code&gt;c()&lt;/code&gt;, which assigns a series of values to one variable. It can be helpful to think of &lt;code&gt;c()&lt;/code&gt; as “combine.”&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y &amp;lt;- c(2, 4, 6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;y&lt;/code&gt; object now contains 2, 4, and 6.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2 4 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you wrap an assignment statement inside of parentheses, R will assign the values &lt;em&gt;and&lt;/em&gt; print the result.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(y &amp;lt;- c(2, 4, 6))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2 4 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vectors are useful for performing operations on every element in the vector. Just as we could do math with a vector…&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\begin{align} 2 \cdot \begin{bmatrix} 2 \\ 4 \\ 6 \end{bmatrix} = \begin{bmatrix} 4 \\ 8 \\ 12 \end{bmatrix} \end{align}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;we can also do similar things in R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;2 * y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  4  8 12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A note about multiplying vectors: by default, R does element-wise multiplication (the “Hadamard product”). To do matrix-style multiplication (dot product/inner product) with vectors, we have a different operator.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# element-wise product:
y * y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  4 16 36&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# dot product
y %*% y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]
## [1,]   56&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;everything-is-an-object&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Everything is an Object&lt;/h1&gt;
&lt;p&gt;In R, everything is an object. I can store any value as a variable, which is an object. A text string is an object. A dataset. A variable within a dataset is an object within an object. It’s objects all the way down. This makes R very flexible.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;indexing&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Indexing&lt;/h1&gt;
&lt;p&gt;You can access individual elements in a vector using &lt;em&gt;indexing&lt;/em&gt; notation with square brackets. Using the variable &lt;code&gt;y&lt;/code&gt; from above, what are the first, second, and third elements?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# entire y vector
y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2 4 6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# first element of y
y[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# second element of y
y[2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# third element of y
y[3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is akin to indexing in math, where we could write &lt;span class=&#34;math inline&#34;&gt;\(y_{1} = 2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(y_{2} = 4\)&lt;/span&gt;, and so on.&lt;/p&gt;
&lt;p&gt;This is why the console prints a little &lt;code&gt;[1]&lt;/code&gt; next to all results. The &lt;code&gt;[1]&lt;/code&gt; indicates that the adjacent element is the first element of the results. If we print a longer object, this becomes clearer. For example, 30 repetitions of the word &lt;code&gt;&amp;quot;hello&amp;quot;&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# repeat &amp;quot;hello&amp;quot; 30 times
rep(&amp;quot;hello&amp;quot;, 30)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot;
##  [9] &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot;
## [17] &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot;
## [25] &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot; &amp;quot;hello&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Indexing works with higher-dimensional data as well. Here is a two-dimensional array of numbers.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# row-bind separate vectors
m &amp;lt;- rbind(c(1, 2), 
           c(3, 4), 
           c(5, 6))
m&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    1    2
## [2,]    3    4
## [3,]    5    6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(Notice how &lt;code&gt;rbind()&lt;/code&gt; binds vectors together as rows. The &lt;code&gt;cbind()&lt;/code&gt; function would bind vectors as columns.)&lt;/p&gt;
&lt;p&gt;To index a multi-dimensional object, use commas to separate the dimensions. The notation &lt;code&gt;object[a, b]&lt;/code&gt; would reference the value in row &lt;code&gt;a&lt;/code&gt; and column &lt;code&gt;b&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m[2, 2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we specify a row but don’t specify a column, R returns every column from the specified row.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m[1, ]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we specify a column but don’t specify a row, R returns every row from the specified column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m[ , 2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2 4 6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even though &lt;code&gt;m[ , 2]&lt;/code&gt; is the second &lt;em&gt;column&lt;/em&gt; of &lt;code&gt;m&lt;/code&gt;, the results don’t print as a vertical column. Why? Because once R evaluates &lt;code&gt;m[ , 2]&lt;/code&gt;, it simply returns an object. R no longer remembers that it comes from &lt;code&gt;m&lt;/code&gt;. The result is nothing more than a vector floating there. As far as R is concerned, &lt;code&gt;m[ , 2]&lt;/code&gt; is exactly equivalent to a vector &lt;code&gt;c(2, 4, 6)&lt;/code&gt;. &lt;em&gt;This is actually good&lt;/em&gt;; it’s exactly the kind of flexibility that will be valuable in the future.&lt;/p&gt;
&lt;div id=&#34;r-is-one-indexed&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;R is one-indexed&lt;/h2&gt;
&lt;p&gt;R is one-indexed, meaning the first element of a vector is element &lt;code&gt;1&lt;/code&gt;. Some languages (like &lt;code&gt;C&lt;/code&gt;) are zero-indexed. Even though R is one-indexed, calling the 0’th element of a variable does not throw an error, so be careful.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;indexing-in-practice&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Indexing in practice&lt;/h2&gt;
&lt;p&gt;The code we use in this course (heavily derived from the &lt;code&gt;tidyverse&lt;/code&gt; suite of packages) does not require much explicit indexing. However, you should understand the intuition of indexing for a few reasons.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It has useful mathematical parallels, where &lt;span class=&#34;math inline&#34;&gt;\(y_{i}\)&lt;/span&gt; is analogous to &lt;code&gt;y[i]&lt;/code&gt;. This sometimes comes in handy for dealing with the results from statistical models.&lt;/li&gt;
&lt;li&gt;You will encounter it when searching through message boards for R help.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;logic&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Logic&lt;/h1&gt;
&lt;p&gt;Logic as a concept in programming is less daunting than it sounds. At it’s core, we’re working with statements that evaluate to either &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Example: is 1 greater than 0?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1 &amp;gt; 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s make a new vector, a sequence of values from 1 to 10.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(g &amp;lt;- 1:10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have this vector, we can derive logical statements about it. Which elements are greater than 5?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;g &amp;gt; 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The statement &lt;code&gt;g &amp;gt; 5&lt;/code&gt; is a “logical vector,” meaning that its a vector whose values are either &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;. &lt;code&gt;TRUE&lt;/code&gt; and &lt;code&gt;FALSE&lt;/code&gt; are keywords in R (and must be capital). R asks if &lt;code&gt;g&lt;/code&gt; is greater than 5, and since &lt;code&gt;g&lt;/code&gt; is a vector, R returns a vector of logicals with each element corresponding to the original elements in &lt;code&gt;g&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There are many logical operators. Here are some:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# g &amp;quot;is equal to&amp;quot; 5 (DOUBLE EQUALS)
g == 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# g &amp;quot;is greater than&amp;quot; 5
g &amp;gt; 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# g &amp;quot;is less than&amp;quot; 5
g &amp;lt; 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# g &amp;quot;is greater than or equal to&amp;quot; 5
g &amp;gt;= 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# g &amp;quot;is less than or equal to&amp;quot; 5
g &amp;lt;= 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This seems a little abstract right now, but here’s how you may see others use logic for indexing. Let’s say that I have some data from countries around the world, and I want to look only at the European data. You might see someone online limit the data like so.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;world_data[region == &amp;quot;Europe&amp;quot;, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Translated: retrieve the &lt;code&gt;world_data&lt;/code&gt; object, but only the rows (notice the comma in the indexing) where &lt;code&gt;region&lt;/code&gt; is equal to &lt;code&gt;&amp;quot;Europe&amp;quot;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;More literally, the statement &lt;code&gt;region == &amp;quot;Europe&amp;quot;&lt;/code&gt; is either &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt; for every observation in the data. The above statement returns the rows from &lt;code&gt;world_data&lt;/code&gt; where &lt;code&gt;region == &amp;quot;Europe&amp;quot;&lt;/code&gt; evaluates to &lt;code&gt;TRUE&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;As mentioned above, we will perform this kind of case selection with a more intuitive syntax that is easier to wrap your brain around.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-types&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data types&lt;/h1&gt;
&lt;p&gt;There are a few different types of data in R.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Logical: &lt;code&gt;TRUE&lt;/code&gt;s and &lt;code&gt;FALSE&lt;/code&gt;s.&lt;/li&gt;
&lt;li&gt;Numeric: including integers and doubles&lt;/li&gt;
&lt;li&gt;Strings: text strings that are contained in &lt;code&gt;&amp;quot;quotes&amp;quot;&lt;/code&gt;. R calls these “character” type variables.&lt;/li&gt;
&lt;li&gt;Factors: ordered categories with text labels&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Factors are akin to labelled variables in Stata. They are somewhat like numbers, somewhat like text strings. They are like strings because they havea text label, and you can’t do math with them. They are like numbers because you can put them in order. Put another way, factors are &lt;em&gt;ordered categories&lt;/em&gt; that have textual metadata.&lt;/p&gt;
&lt;p&gt;It is possible to coerce data from type to another. We cover this in our final lesson.&lt;/p&gt;
&lt;p&gt;Note: data types are different from &lt;em&gt;object classes&lt;/em&gt;. Data type describes the values, but object classes describes the organization of values. Classes include vectors, matrices, data frames, tables, lists, and so on.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;missing-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Missing data&lt;/h1&gt;
&lt;p&gt;Vectors might contain missing data. The missing data code in R is capital &lt;code&gt;NA&lt;/code&gt;, without quotes.&lt;/p&gt;
&lt;p&gt;Missing data take the same data type as the vector in which they are located. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;h &amp;lt;- c(1, 2, NA, 4)
# what data type is h?
str(h)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  num [1:4] 1 2 NA 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By placing &lt;code&gt;NA&lt;/code&gt; inside a numeric vector, what we’ve told R is that we know that the missing data is numeric, we just don’t know what the number is. If some function requires that we know every value, it will probably fail. Try the following.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(h)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This doesn’t cause an &lt;em&gt;error&lt;/em&gt;. Instead, the result is a missing value. What this means is, we know that there &lt;em&gt;should&lt;/em&gt; be a numeric mean (which is why there is no error), we just don’t know what the mean is because we don’t know what all of &lt;code&gt;h&lt;/code&gt; is. When we want to calculate this value irrespective of the missing values, we often need to tell R to skip over missing values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(h, na.rm = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.333333&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Many functions have &lt;code&gt;na.rm&lt;/code&gt; (“remove &lt;code&gt;NA&lt;/code&gt;”) arguments that can be flipped on, such as &lt;code&gt;sum()&lt;/code&gt;, &lt;code&gt;sd()&lt;/code&gt;, and so on.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;functions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Functions&lt;/h1&gt;
&lt;p&gt;In math, you can manipulate a variable with a function, &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt;. There are tons of functions that you can use in R.&lt;/p&gt;
&lt;p&gt;There are three things you need to use a function.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The function name itself. Self-explanatory.&lt;/li&gt;
&lt;li&gt;Parentheses. This tells R that the object name is meant to be a function.&lt;/li&gt;
&lt;li&gt;Arguments inside the parentheses. These may be optional, depending on the function and its default behaviors. Arguments can be data that you pass to the function (as inputs), settings that you modify, and so on.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Some easy, common functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 10 thousand random samples from a normal distribution
x &amp;lt;- rnorm(n = 10000, mean = 0, sd = 1)

# sum
sum(x) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -13.81984&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# number of elements in an object
length(x) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# mean
mean(x) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.001381984&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# variance
var(x) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9781618&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# standard deviation
sd(x) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9890206&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is easy to write your own functions in R. We will cover this in the final lesson.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;help-files&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Help files&lt;/h1&gt;
&lt;p&gt;Get help on any function using &lt;code&gt;?function_name&lt;/code&gt; or &lt;code&gt;help(function_name)&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;external-packages-for-non-base-functions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;External Packages (for non-base functions)&lt;/h1&gt;
&lt;p&gt;Base R only contains a small number of functions. Most analyses require more complicated tools that are not standard with R. For these tasks, there are hundreds of packages available for download.&lt;/p&gt;
&lt;p&gt;Official R packages are hosted on CRAN and can be installed with code. For example, the following code will install the &lt;code&gt;tidyverse&lt;/code&gt; package. Because the package depends on other packages, all required packages will be downloaded if not already on your system. As a result, this command would take a while to execute (but you should execute it…we will use this package in class).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;tidyverse&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Install multiple packages using &lt;code&gt;c()&lt;/code&gt; to combine package names. Run this command as well. We will use all of these packages throughout our lessons.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(c(&amp;quot;magrittr&amp;quot;, &amp;quot;haven&amp;quot;, &amp;quot;labelled&amp;quot;, &amp;quot;broom&amp;quot;, &amp;quot;ggplot2&amp;quot;, &amp;quot;stargazer&amp;quot;, &amp;quot;texreg&amp;quot;, &amp;quot;xtable&amp;quot;, &amp;quot;Rmisc&amp;quot;, &amp;quot;mvtnorm&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;moving-on&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Moving on&lt;/h1&gt;
&lt;p&gt;If you have made it this far, take a break!&lt;/p&gt;
&lt;p&gt;I want to remind you that future lessons will be far less abstract than this one. Many concepts in this lesson are &lt;em&gt;important&lt;/em&gt; in the sense that you will see them again during your R career, but they are not all &lt;em&gt;essential&lt;/em&gt; for surviving this course. Future lessons will be far more concrete and dataset-driven.&lt;/p&gt;
&lt;p&gt;Continue with the next lesson: &lt;a href=&#34;811/811-data&#34;&gt;Data Manipulation&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>PoliSci 811: R Introduction</title>
      <link>/811/811-intro/</link>
      <pubDate>Wed, 07 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/811/811-intro/</guid>
      <description>&lt;p&gt;Welcome to the online lessons for PS 811: Introduction to Statistical Computing for Political Science. This series of blog posts contain instructional notes for using R for political science research.&lt;/p&gt;
&lt;p&gt;This current post contains a few introductory remarks about R, how I intend to teach R, and the structure of our coming lessons.&lt;/p&gt;
&lt;div id=&#34;schedule&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Schedule:&lt;/h1&gt;
&lt;p&gt;Read this before our first in-class R lesson!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-little-about-r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A little about R&lt;/h1&gt;
&lt;p&gt;R is not the only program out there for doing statistical programming, so let’s begin by talking about what makes it unique.&lt;/p&gt;
&lt;p&gt;Compared to other popular statistical software for the social scientists (such as Stata), R stands out as a more general programming language. It isn’t just a set of off-the-shelf &lt;em&gt;commands&lt;/em&gt; that are punched into a program. It is a collection of functions and routines that can be used to build more complex and powerful tools for a broader set of computational uses. This has some trade-offs; it’s more complicated and tougher to learn, but you can do a lot more with it.&lt;/p&gt;
&lt;p&gt;R is an “object-oriented” language, which essentially means that everything you interact with—datasets, variables, variable &lt;em&gt;names&lt;/em&gt;, functions, etc.—is an “object” that contains either data or code to manipulate data. This makes R extremely flexible for use in statistics, as we will see throughout these lessons.&lt;/p&gt;
&lt;p&gt;Where other statistical software constraints you to work out of one data table, R allows you to manipulate multiple data tables. This will allow more flexibility in your work flow, but it requires you to manage more data tables.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;r-and-stata&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R and Stata&lt;/h1&gt;
&lt;p&gt;All softwares are better suited to certain tasks than others. For example, Stata has historically been a stronger program than R for time series analysis (though time series analysis in R has seen dramatic improvement in recent years). However, R has much more flexibility than Stata to modify what your analysis is doing, allowing more explicit control over data manipulation, modeling, graphics, and workflow integration across programs.&lt;/p&gt;
&lt;p&gt;More specifically, Stata will make stricter assumptions about what your analysis will look like than R will. This makes it easier to perform &lt;em&gt;typical routines&lt;/em&gt; using Stata than using R. On the other hand, should you ever want to extend your analysis beyond typical routines, R provides more infrastructure for making that possible, but the user has to know what they want R to do. Said slightly differently: anything you can do in Stata, you can also do in R, but things that seem simple in Stata may seem complicated in R because R will make fewer assumptions for you.&lt;/p&gt;
&lt;p&gt;Here is a common example that many users encounter. &lt;a href=&#34;https://en.wikipedia.org/wiki/Heteroscedasticity&#34;&gt;Robust standard errors&lt;/a&gt;. In Stata, they are easy: &lt;code&gt;reg y x, robust&lt;/code&gt;. In R, they are hard, because R will make you confront the fact that there are &lt;a href=&#34;https://www.rdocumentation.org/packages/sandwich/versions/2.4-0/topics/vcovHC&#34;&gt;many types of robust standard errors&lt;/a&gt;. Stata picks an estimator by default and hides this decision from you. R forces you to make the decision for yourself. As a result, political science is full of robust standard errors that reflect Stata’s automatic choice.&lt;/p&gt;
&lt;p&gt;The difference between Stata and R is kind of like the corny quote that you recognize from Spiderman: with great power comes great responsibility. R lets you &lt;em&gt;go farther&lt;/em&gt;, but you need to know how not to break everything. This &lt;em&gt;can be a good thing&lt;/em&gt;, depending on your style of analysis. I like it, personally, but not every body does, and loads of brilliant social scientists use Stata to enormous success. As you learn more about statistics, about the research you intend to do, and about the tools available to you, (and perhaps about yourself), you will have to make these software decisions for yourself—or &lt;a href=&#34;https://twitter.com/drob/status/954056331979259904&#34;&gt;someone else will make the choice for you&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bottom-up-theory&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Bottom-up theory&lt;/h1&gt;
&lt;p&gt;Using R sometimes requires some familiarity with general programming concepts. This course will touch on some of these concepts as we go, but rather than hammering them to death, I will instead aim to provide resources for further learning along the way.&lt;/p&gt;
&lt;p&gt;Some of these concepts may seem tedious at first, e.g. variables and functions. We discuss these not because you cannot be trusted to understand these concepts &lt;em&gt;in general&lt;/em&gt;, but because these concepts relate to programming in not-always-obvious ways. (For example, what is the difference between a “global” and “local” variable? Or, how can a function return “random” results even if you keep the inputs the same?) The mathematical world and the programming world exhibit many similarities, and understanding how these realms relate will help you become a more skilled programmer, a stronger mathematical thinker, and a better statistical analyst.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pedagogical-note&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Pedagogical note&lt;/h1&gt;
&lt;p&gt;Because R is open-source and very flexible, there are often many different ways to accomplish the same task. Instructors, being experienced R users, see the diversity of options as an inherit benefit of R and its open-source origins, so they are often tempted to teach about the diversity. But for new R users, the diversity of R tools can be daunting and confusing. When you’re learning a new language, sometimes you just want to be told what works.&lt;/p&gt;
&lt;p&gt;We have a short time to cover as much quality R as we can, so we have to make some choices about what material to emphasize. Here is the approach we will take. (I confess that my thinking is heaviliy influenced by some blog posts by David Robinson about teaching R, including but not limited to &lt;a href=&#34;http://varianceexplained.org/r/teach-tidyverse/&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rather than give you abstract exercises to demonstrate concepts in a vacuum, we’ll create realistic scenarios using real data as much as we can.&lt;/li&gt;
&lt;li&gt;I won’t force you to slog through difficult problems using underpowered tools for the gratuitous purpose of “getting you to appreciate the finer points of the language” or whatever. Nor will we contrast old and new tools or painstakingly catalog how multiple approaches lead to the same end result. Instead, we will jump quickly into tools that I believe you will actually use in the future.&lt;/li&gt;
&lt;li&gt;Relatedly, this means we’ll be following a philosophy of &lt;em&gt;doing as much as we can with as few powerful tools as possible&lt;/em&gt;. Let’s define a “powerful” tool as one that performs a complicated task with a simple interface. That’s the sweet spot.&lt;/li&gt;
&lt;li&gt;Hopefully this &lt;em&gt;makes R exciting to learn&lt;/em&gt; because we can do real heavy lifting with it &lt;em&gt;soon&lt;/em&gt;, rather than “graduating” to fun stuff after boring you with annoying stuff.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To help us achieve these goals together, I have made the strategic decision to focus this course on the &lt;code&gt;tidyverse&lt;/code&gt; suite of data manipulation packages, including &lt;code&gt;ggplot2&lt;/code&gt; for graphics. There are several other “families” of data manipulation and graphics approaches, including “base R,” which is where most R courses begin. Those courses then shift to other approaches after students have been beaten into submission by the inefficiency of base R. My attitude is that you are highly unlikely to use weak tools once you discover powerful tools, so I don’t want to exhaust you with exercises for weak tools. Put simply, the Tidyverse is the fastest route to accomplish my goals for this course—to teach you R that is useful, realistic, simple, powerful, and fun.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;course-structure&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Course structure&lt;/h1&gt;
&lt;p&gt;We will work through this course using three tools: online notes, in-class lectures, and take-home exercises.&lt;/p&gt;
&lt;p&gt;Online notes will be the “most complete” accounting of useful R concepts, functions, and lessons. I hope that these will be a permanent resource that you can always come back to. Online notes will be easiest to read on this website, but source code for all lessons will also be available on my &lt;a href=&#34;https://www.github.com/mikedecr&#34;&gt;Github page&lt;/a&gt; as &lt;code&gt;.Rmd&lt;/code&gt; files. I would recommend you download the source files should they ever disappear from the web in the future. We’ll divide the material for this course across three lessons but using four documents (&lt;em&gt;not including&lt;/em&gt; this page). You should review each lesson &lt;strong&gt;&lt;em&gt;before&lt;/em&gt;&lt;/strong&gt; its corresponding lecture day.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For the first week of R lecture, read this &lt;a href=&#34;811/811-basics&#34;&gt;overview of some basic R material&lt;/a&gt; and &lt;a href=&#34;811/811-data&#34;&gt;this lesson on data manipulation&lt;/a&gt;. The first document covers the absolute basics—installing R, simple commands—and the second document covers data manipulation using &lt;code&gt;tidyverse&lt;/code&gt; routines.&lt;/li&gt;
&lt;li&gt;For the second week, we will cover &lt;a href=&#34;811/811-graphics&#34;&gt;graphics&lt;/a&gt;, with a particular focus on &lt;code&gt;ggplot2&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Week 3 covers &lt;a href=&#34;811/811-analysis&#34;&gt;statistical analysis&lt;/a&gt;, including model estimation, generating model summaries and post-estimation analysis, and discussing how to incorporate your results into your written work using workflow tools. This lesson will also contain some material on advanced R tools and routines.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lecture will be a guided walk-through of each week’s material. They will cover &lt;em&gt;incomplete selections&lt;/em&gt; from the online notes, so it is important to preview the notes before class. We will try to leave as much in-class time to work on take-home exercises as possible.&lt;/p&gt;
&lt;p&gt;The take-home exercises will reinforce each week’s material using an extended analysis of one dataset. These exercises are required and should be submitted on the &lt;em&gt;Thursday&lt;/em&gt; following each lesson. Solutions will be made available the following day, so your work should be completed on time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;datasets&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Datasets&lt;/h1&gt;
&lt;p&gt;The dataset we will use for online notes and in-class lectures is the American National Election Study, which is a long-running academic survey of U.S. voting and public opinion. Specifically, we will work with the “&lt;a href=&#34;http://electionstudies.org/studypages/anes_timeseries_cdf/anes_timeseries_cdf.htm&#34;&gt;cumulative data file&lt;/a&gt;,” which contains interviews from survey respondents for presidential and midterm campaign seasons since 1948. To obtain the data, make an account on &lt;a href=&#34;http://electionstudies.org/&#34;&gt;electionstudies.org&lt;/a&gt; and download the cumulative data file before the first in-class lesson. Make sure your download includes the codebook. You should take care of this &lt;em&gt;well in advance&lt;/em&gt; of our first R lecture. If you encounter difficulties, get in touch with me &lt;em&gt;after&lt;/em&gt; trying to troubleshoot your problem using the website’s instructions ;-) .&lt;/p&gt;
&lt;p&gt;Take-home exercises will use the &lt;a href=&#34;https://data.stanford.edu/dime#download-data&#34;&gt;Database on Ideology, Money in Politics, and Elections&lt;/a&gt;, which contains information on campaign contributions for U.S. elections organized at by candidate-cycles. There are many data files in the DIME, but you should only download the “recipients” data file (and the codebook, of course).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;seeking-help-or-my-role-as-instructor&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Seeking help, or, My role as instructor&lt;/h1&gt;
&lt;p&gt;My goal is to get you started with R, but I cannot make you an expert. You learn R mostly by doing it, and over the long run, you will learn far more from the internet than you will from me. This is as it should be—the internet is your friend. Being “good at R” means (to a certain extent) knowing what to do when you mess up, learning how to Google the error message, and learning to avoid past mistakes. To that end, when you encounter problems with R, I encourage you to start by seeking your own help online. Training yourself to find online solutions is an invaluable skill for R (and any software), so you should practice while you can. Of course, you can contact me if you find online resources to be confusing.&lt;/p&gt;
&lt;p&gt;Sources like Stack Overflow are great for working through R problems. So is Twitter. The most prominent R developers are active on both.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/research/</link>
      <pubDate>Mon, 04 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/research/</guid>
      <description>&lt;div id=&#34;dissertation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Dissertation&lt;/h1&gt;
&lt;div id=&#34;do-primaries-work-nomination-politics-and-the-representation-of-local-partisan-preferences.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Do Primaries Work? Nomination Politics and the Representation of Local Partisan Preferences.&lt;/h2&gt;
&lt;p&gt;For decades, primary elections have been widely believed to polarize candidates for office away from median-converging policy platforms. The fear of primary challenges may bolster the ideological consistency of incumbent officeholders, but does this function of primaries improve the representation of local constituencies? Do candidates take polarized positions because that is what their nominating constituencies prefer? Or is it simply the case that safe majorities in the general election allow candidates to take polarized positions.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/research/cces-self-id.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I argue that key predictions from the prevailing theory of primaries lack direct empirical support. Are primary candidate positions meaningfully related to the preferences of district co-partisans? Are polarized primary constituencies more likely to nominate polarized primary candidates? I develop Bayesian measurement methods for estimating local partisan preferences, allowing us to assess these claims more directly than ever before. I explore whether the dominant theory about primaries—and it turn, about the nature of divergent candidate positioning in the U.S.—is empirically supported.&lt;/p&gt;
&lt;p&gt;More info coming soon.&lt;/p&gt;
&lt;!-- &lt;center&gt;
  &lt;img src=&#34;/images/research/cces-self-id.png&#34; alt=&#34;The non-relationship between district voting and self-reported partisan ideology&#34; style=&#34;width: 90%;&#34;/&gt;
&lt;/center&gt; --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;published&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Published&lt;/h1&gt;
&lt;div id=&#34;the-unexceptional-gender-gap-of-2016-with-barry-c.-burden-and-evan-crawford.-the-forum-144425432-2016.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Unexceptional Gender Gap of 2016 (with Barry C. Burden and Evan Crawford). &lt;em&gt;The Forum&lt;/em&gt; 14(4):425–432 (2016).&lt;/h2&gt;
&lt;p&gt;[View &lt;a href=&#34;https://www.degruyter.com/downloadpdf/j/for.2016.14.issue-4/for-2016-0039/for-2016-0039.pdf&#34;&gt;PDF&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;The 2016 presidential campaign was defined by gender to a remarkable degree, which led many observers to expect a historically large gender gap in voting. In reality, the difference between men and women’s votes in 2016 was only slightly larger than in other recent elections. We argue that an immense gender divide did not emerge because it was constrained by high levels of partisanship in the electorate, especially “negative partisanship” toward the opposing party that leaves little room for gender to make a difference on the margins. In addition, we challenge two common assumptions: that the gender gap helps Democratic candidates and that women were more persuadable than men over the course of the campaign. Both men and women vacillated in their views of Clinton’s honesty during the campaign, with men shifting away from her and toward Trump just before election day.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/research/forum-teaser.png&#34; width=&#34;80%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;in-progress&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;In Progress&lt;/h1&gt;
&lt;div id=&#34;mobilization-persuasion-and-the-partisan-fallout-of-the-gender-gap-in-u.s.-voting-with-barry-c.-burden&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mobilization, Persuasion, and the Partisan Fallout of the Gender Gap in U.S. Voting (with Barry C. Burden)&lt;/h2&gt;
&lt;p&gt;[View &lt;a href=&#34;https://www.dropbox.com/s/y69t6x89gj8fvkt/gender-gap-public.pdf?dl=0&#34;&gt;PDF&lt;/a&gt; and &lt;a href=&#34;https://www.dropbox.com/s/0piklipw954t8zg/gap-appendix-public.pdf?dl=0&#34;&gt;supplemental info&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;Does the gender gap help the Democrats? Do Republicans win more votes when the gender gap is smaller? To answer this question, we develop a generalizable theoretical framework to understand the link between group differences in voting and party vote shares, with an application to the gender gap.&lt;/p&gt;
&lt;p&gt;Theoretically, our approach views both the gender gap and partisan election outcomes as underlying partisan predispositions in the electorate that are transformed through partisan mobilization, partisan defection, and the choices of unaffiliated voters. We argue that the size of the gender gap has no &lt;em&gt;necessary&lt;/em&gt; bearing on the partisan vote outcome. Rather, the relationship is contingent on the changing numerical impact of partisanship, mobilization, and persuasion over time.&lt;/p&gt;
&lt;p&gt;Empirically, both the gender gap and the Democratic vote in presidential elections have increased over time, but this relationship is almost entirely spurious. The primary cause of the gender gap (partisan change among men) was harmful to the Democrats. Meanwhile, the forces that increased the Democratic vote (greater mobilization and less defection among Democratic partisans) were relatively gender neutral.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/research/gap-teaser.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Our framework can be extended to understand how other group cleavages such as race, formal education, and urban/rural divides affect election outcomes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;voter-identification-and-nonvoting-in-wisconsinevidence-from-the-2016-election-with-kenneth-r.-mayer&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Voter Identification and Nonvoting in Wisconsin—Evidence from the 2016 Election (with Kenneth R. Mayer)&lt;/h2&gt;
&lt;p&gt;[View &lt;a href=&#34;https://www.dropbox.com/s/w44vf1lp90dd9uf/voter-id-public.pdf?dl=0&#34;&gt;PDF&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;How much did Wisconsin’s voter identification requirement matter in 2016? Who is affected by voter ID requirements?&lt;/p&gt;
&lt;p&gt;We conducted a survey of registered Wisconsin nonvoters in the counties surrounding Milwaukee and Madison to estimate the number of registered voters who were affected by the voter ID requirement in 2016. Using a conservative Bayesian estimate, we find that roughly 10 percent of nonvoters in these counties lacked a qualifying voter ID or reported that voter ID was at least a &lt;em&gt;partial&lt;/em&gt; reason why they did not vote in 2016, and 6 percent of nonvoters lacked a voter ID or cited voter ID as their &lt;em&gt;primary&lt;/em&gt; reason for not voting.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/images/research/nonvoters-teaser.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We argue that voter ID requirements affect a larger share of the public than those who lack a qualifying ID. Voter ID requirements contain technical details surrounding outdated addresses, expiration dates, and name changes that are likely to confuse and deter citizens who possess qualifying forms of ID as well. We find evidence of this confusion effect: many respondents mistakenly believe that they did not have the necessary ID to vote when they actually did, and individuals who were less knowledgeable about qualifying forms of ID were more likely to report being affected by the law. These “indirect effects” of voter ID reveal that record-linkage approaches to studying ID possession may underestimate the population affected by voter ID laws.&lt;/p&gt;
&lt;p&gt;While we do not estimate the causal effect of voter ID on turnout, we do perform a simulation to demonstrate a range of plausible turnout effects under various assumptions.&lt;/p&gt;
&lt;!-- ## How Should We Employ MRP Estimates as Predictors? Issues with Uncertainty and Pooling

More info coming soon. --&gt;
&lt;!-- Images and Words: How Citizens Understand Uncertain Election Polls (with Benjamin Toff and Zachary Warner) --&gt;
&lt;!-- Identity and Ideology in the Parties&#39; Campaign Finance Networks (with Jordan Hsu) --&gt;
&lt;!-- Bureaucratic &#39;Competence&#39; or Bureaucratic Access? Voter ID and Turnout in Alabama --&gt;
&lt;!-- &#39;One of the Good Ones&#39;: Economic Racism and Black Conservative Candidates (with Micah C.R. Dillard) --&gt;
&lt;!-- - Uncertainty and Causality in Multilevel Regression and Poststratification --&gt;
&lt;!-- Do Primaries Work? Constituency Preferences and Candidate Positioning in Legislative Primary Elections --&gt;
&lt;!-- Nomination Systems and Ideology in Legislative Elections --&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Teaching</title>
      <link>/teaching/</link>
      <pubDate>Mon, 04 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/teaching/</guid>
      <description>&lt;div id=&#34;as-instructor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;As Instructor&lt;/h2&gt;
&lt;p&gt;Courses at UW–Madison&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Political Science 811: Introduction to Statistical Computing in Political Science, Spring 2018. &lt;a href=&#34;/811/&#34;&gt;(2018 Materials)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Graduate Workshops at UW–Madison&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Political Science Ph.D. Math Camp, 2017 and 2018. &lt;a href=&#34;https://github.com/mikedecr/math-camp-2018&#34;&gt;(2018 Materials)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Political Science &lt;span class=&#34;math inline&#34;&gt;\(\mathrm{\LaTeX}\)&lt;/span&gt; Workshop, 2015–2018. &lt;a href=&#34;https://github.com/mikedecr/latex-workshop-2018&#34;&gt;(2018 Materials)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;as-teaching-assistant&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;As Teaching Assistant&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Political Science 305: Elections and Voting Behavior (UW–Madison, Fall 2018)&lt;/li&gt;
&lt;li&gt;Political Science 544: Introduction to Survey Research Methods (UW–Madison, Spring 2017)&lt;/li&gt;
&lt;li&gt;Political Science 218: Understanding Political Numbers (UW–Madison, Fall 2015 and Fall 2016)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>About Mike</title>
      <link>/about/</link>
      <pubDate>Thu, 05 May 2016 21:48:51 -0700</pubDate>
      
      <guid>/about/</guid>
      <description>&lt;div id=&#34;im-michael-decrescenzo&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I’m Michael DeCrescenzo,&lt;/h2&gt;
&lt;center&gt;
&lt;p&gt;a political science Ph.D. candidate at the University of Wisconsin–Madison.&lt;/p&gt;
I study American politics and statistical methodology.
&lt;/center&gt;
&lt;p&gt;&lt;img src=&#34;/images/me/nelson.png&#34; width=&#34;40%&#34; style = &#34;display: inline-block; float:left; padding-right:15px; padding-bottom:10px; border-radius: 50%;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;/research/&#34;&gt;My research&lt;/a&gt; focuses on electoral politics in the United States,&lt;/strong&gt; broadly construed. I study issues surrounding ideological representation, public opinion, vote choice and turnout, and election administration. My dissertation explores primary elections and the representation of local partisan preferences.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;/teaching/&#34;&gt;My teaching experience&lt;/a&gt; focuses on research methods, computing, and American elections.&lt;/strong&gt; The bulk of my teaching focuses on the mathematical, statistical, and software foundations for social science research. I teach these subjects for undergraduate and graduate students.&lt;/p&gt;
&lt;p&gt;I am an affiliate of the &lt;a href=&#34;https://elections.wisc.edu/&#34;&gt;Elections Research Center&lt;/a&gt;, where I also serve as the graduate student assistant.&lt;/p&gt;
&lt;p&gt;You can find my cv &lt;a href=&#34;https://uwmadison.box.com/s/sdl1gj7jsmg3qqc841gv641pfj8c449n&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;!-- Mathjax test --&gt;
&lt;!-- \begin{align}
  p(y_{ij} = 1) &amp;= \Phi\left( \frac{\theta_{i} - \alpha_{j}}{\sigma_{j}} \right)
\end{align}
 --&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/contact/</guid>
      <description>&lt;!-- ## How to reach me --&gt;

&lt;p&gt;&lt;strong&gt;By email:&lt;/strong&gt; decrescenzo [asperand] wisc [period] edu&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;During office hours:&lt;/strong&gt; North Hall 101A (appointment only during Spring 2018)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Twitter:&lt;/strong&gt; &lt;a href=&#34;https://twitter.com/mikedecr&#34; target = &#34;_blank&#34;&gt;@mikedecr&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;My UW Political Science &lt;a href=&#34;https://polisci.wisc.edu/people/graduate-students/michael-decrescenzo&#34; rel=&#34;nofollow noreferrer&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Department Page&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;By mail:&lt;/strong&gt; &lt;br&gt;
Department of Political Science &lt;br&gt;
101A North Hall (Elections Research Center) &lt;br&gt;
1050 Bascom Mall &lt;br&gt;
University of Wisconsin&amp;ndash;Madison &lt;br&gt;
Madison, WI 53706&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>